<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>dlnd_language_translation</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Language-Translation">Language Translation<a class="anchor-link" href="#Language-Translation">&#182;</a></h1><p>In this project, you’re going to take a peek into the realm of neural network machine translation.  You’ll be training a sequence to sequence model on a dataset of English and French sentences that can translate new sentences from English to French.</p>
<h2 id="Get-the-Data">Get the Data<a class="anchor-link" href="#Get-the-Data">&#182;</a></h2><p>Since translating the whole language of English to French will take lots of time to train, we have provided you with a small portion of the English corpus.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">source_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_en&#39;</span>
<span class="n">target_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_fr&#39;</span>
<span class="n">source_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">)</span>
<span class="n">target_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">target_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Explore-the-Data">Explore the Data<a class="anchor-link" href="#Explore-the-Data">&#182;</a></h2><p>Play around with view_sentence_range to view different parts of the data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">view_sentence_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Dataset Stats&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Roughly the number of unique words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">({</span><span class="n">word</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">()})))</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">word_counts</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of sentences: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average number of words in a sentence: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">word_counts</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;English sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;French sentences </span><span class="si">{}</span><span class="s1"> to </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Dataset Stats
Roughly the number of unique words: 227
Number of sentences: 137861
Average number of words in a sentence: 13.225277634719028

English sentences 0 to 10:
new jersey is sometimes quiet during autumn , and it is snowy in april .
the united states is usually chilly during july , and it is usually freezing in november .
california is usually quiet during march , and it is usually hot in june .
the united states is sometimes mild during june , and it is cold in september .
your least liked fruit is the grape , but my least liked is the apple .
his favorite fruit is the orange , but my favorite is the grape .
paris is relaxing during december , but it is usually chilly in july .
new jersey is busy during spring , and it is never hot in march .
our least liked fruit is the lemon , but my least liked is the grape .
the united states is sometimes busy during january , and it is sometimes warm in november .

French sentences 0 to 10:
new jersey est parfois calme pendant l&#39; automne , et il est neigeux en avril .
les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .
california est généralement calme en mars , et il est généralement chaud en juin .
les états-unis est parfois légère en juin , et il fait froid en septembre .
votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .
son fruit préféré est l&#39;orange , mais mon préféré est le raisin .
paris est relaxant en décembre , mais il est généralement froid en juillet .
new jersey est occupé au printemps , et il est jamais chaude en mars .
notre fruit est moins aimé le citron , mais mon moins aimé est le raisin .
les états-unis est parfois occupé en janvier , et il est parfois chaud en novembre .
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implement-Preprocessing-Function">Implement Preprocessing Function<a class="anchor-link" href="#Implement-Preprocessing-Function">&#182;</a></h2><h3 id="Text-to-Word-Ids">Text to Word Ids<a class="anchor-link" href="#Text-to-Word-Ids">&#182;</a></h3><p>As you did with other RNNs, you must turn the text into a number so the computer can understand it. In the function <code>text_to_ids()</code>, you'll turn <code>source_text</code> and <code>target_text</code> from words to ids.  However, you need to add the <code>&lt;EOS&gt;</code> word id at the end of <code>target_text</code>.  This will help the neural network predict when the sentence should end.</p>
<p>You can get the <code>&lt;EOS&gt;</code> word id by doing:</p>
<div class="highlight"><pre><span></span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">]</span>
</pre></div>
<p>You can get other word ids using <code>source_vocab_to_int</code> and <code>target_vocab_to_int</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">text_to_ids</span><span class="p">(</span><span class="n">source_text</span><span class="p">,</span> <span class="n">target_text</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert source and target text to proper word ids</span>
<span class="sd">    :param source_text: String that contains all the source text.</span>
<span class="sd">    :param target_text: String that contains all the target text.</span>
<span class="sd">    :param source_vocab_to_int: Dictionary to go from the source words to an id</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: A tuple of lists (source_id_text, target_id_text)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">source_id_text</span> <span class="o">=</span> <span class="p">[[</span><span class="n">source_vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)]</span>
    
    <span class="n">target_id_text</span> <span class="o">=</span> <span class="p">[[</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span><span class="o">+</span><span class="p">[</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">]]</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)]</span>
    
    <span class="k">return</span> <span class="n">source_id_text</span><span class="p">,</span> <span class="n">target_id_text</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_text_to_ids</span><span class="p">(</span><span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Preprocess-all-the-data-and-save-it">Preprocess all the data and save it<a class="anchor-link" href="#Preprocess-all-the-data-and-save-it">&#182;</a></h3><p>Running the code cell below will preprocess all the data and save it to file.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">helper</span><span class="o">.</span><span class="n">preprocess_and_save_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">,</span> <span class="n">target_path</span><span class="p">,</span> <span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Check-Point">Check Point<a class="anchor-link" href="#Check-Point">&#182;</a></h1><p>This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>

<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Check-the-Version-of-TensorFlow-and-Access-to-GPU">Check the Version of TensorFlow and Access to GPU<a class="anchor-link" href="#Check-the-Version-of-TensorFlow-and-Access-to-GPU">&#182;</a></h3><p>This will check to make sure you have the correct version of TensorFlow and access to a GPU</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">distutils.version</span> <span class="k">import</span> <span class="n">LooseVersion</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.layers.core</span> <span class="k">import</span> <span class="n">Dense</span>

<span class="c1"># Check TensorFlow Version</span>
<span class="k">assert</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s1">&#39;1.1&#39;</span><span class="p">),</span> <span class="s1">&#39;Please use TensorFlow version 1.1 or newer&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TensorFlow Version: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>

<span class="c1"># Check for a GPU</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;No GPU found. Please use a GPU to train your neural network.&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Default GPU Device: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">()))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>TensorFlow Version: 1.3.0
Default GPU Device: /gpu:0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h2><p>You'll build the components necessary to build a Sequence-to-Sequence model by implementing the following functions below:</p>
<ul>
<li><code>model_inputs</code></li>
<li><code>process_decoder_input</code></li>
<li><code>encoding_layer</code></li>
<li><code>decoding_layer_train</code></li>
<li><code>decoding_layer_infer</code></li>
<li><code>decoding_layer</code></li>
<li><code>seq2seq_model</code></li>
</ul>
<h3 id="Input">Input<a class="anchor-link" href="#Input">&#182;</a></h3><p>Implement the <code>model_inputs()</code> function to create TF Placeholders for the Neural Network. It should create the following placeholders:</p>
<ul>
<li>Input text placeholder named "input" using the TF Placeholder name parameter with rank 2.</li>
<li>Targets placeholder with rank 2.</li>
<li>Learning rate placeholder with rank 0.</li>
<li>Keep probability placeholder named "keep_prob" using the TF Placeholder name parameter with rank 0.</li>
<li>Target sequence length placeholder named "target_sequence_length" with rank 1</li>
<li>Max target sequence length tensor named "max_target_len" getting its value from applying tf.reduce_max on the target_sequence_length placeholder. Rank 0.</li>
<li>Source sequence length placeholder named "source_sequence_length" with rank 1</li>
</ul>
<p>Return the placeholders in the following the tuple (input, targets, learning rate, keep probability, target sequence length, max target sequence length, source sequence length)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">model_inputs</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create TF Placeholders for input, targets, learning rate, and lengths of source and target sequences.</span>
<span class="sd">    :return: Tuple (input, targets, learning rate, keep probability, target sequence length,</span>
<span class="sd">    max target sequence length, source sequence length)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;input&quot;</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
    
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;keep_prob&quot;</span><span class="p">)</span>
    
    <span class="n">target_sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;target_sequence_length&quot;</span><span class="p">)</span>
    <span class="n">max_target_sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;max_target_len&quot;</span><span class="p">)</span>
    
    <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;source_sequence_length&quot;</span><span class="p">)</span>
    
    
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">source_sequence_length</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_model_inputs</span><span class="p">(</span><span class="n">model_inputs</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>ERROR:tensorflow:==================================
Object was never used (type &lt;class &#39;tensorflow.python.framework.ops.Operation&#39;&gt;):
&lt;tf.Operation &#39;assert_rank_2/Assert/Assert&#39; type=Assert&gt;
If you want to mark it as used call its &#34;mark_used()&#34; method.
It was originally created here:
[&#39;File &#34;/usr/lib/python3.5/runpy.py&#34;, line 184, in _run_module_as_main\n    &#34;__main__&#34;, mod_spec)&#39;, &#39;File &#34;/usr/lib/python3.5/runpy.py&#34;, line 85, in _run_code\n    exec(code, run_globals)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py&#34;, line 16, in &lt;module&gt;\n    app.launch_new_instance()&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py&#34;, line 658, in launch_instance\n    app.start()&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py&#34;, line 477, in start\n    ioloop.IOLoop.instance().start()&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py&#34;, line 177, in start\n    super(ZMQIOLoop, self).start()&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py&#34;, line 888, in start\n    handler_func(fd_obj, events)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py&#34;, line 277, in null_wrapper\n    return fn(*args, **kwargs)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py&#34;, line 440, in _handle_events\n    self._handle_recv()&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py&#34;, line 472, in _handle_recv\n    self._run_callback(callback, msg)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py&#34;, line 414, in _run_callback\n    callback(*args, **kwargs)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py&#34;, line 277, in null_wrapper\n    return fn(*args, **kwargs)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py&#34;, line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py&#34;, line 235, in dispatch_shell\n    handler(stream, idents, msg)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py&#34;, line 399, in execute_request\n    user_expressions, allow_stdin)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py&#34;, line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py&#34;, line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py&#34;, line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py&#34;, line 2856, in run_ast_nodes\n    if self.run_code(code, result):&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py&#34;, line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)&#39;, &#39;File &#34;&lt;ipython-input-7-82f0f446e906&gt;&#34;, line 26, in &lt;module&gt;\n    tests.test_model_inputs(model_inputs)&#39;, &#39;File &#34;/home/ubuntu/deep-learning/language-translation/problem_unittests.py&#34;, line 106, in test_model_inputs\n    assert tf.assert_rank(lr, 0, message=\&#39;Learning Rate has wrong rank\&#39;)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/check_ops.py&#34;, line 617, in assert_rank\n    dynamic_condition, data, summarize)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/check_ops.py&#34;, line 571, in _assert_rank_condition\n    return control_flow_ops.Assert(condition, data, summarize=summarize)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_should_use.py&#34;, line 175, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_should_use.py&#34;, line 144, in _add_should_use_warning\n    wrapped = TFShouldUseWarningWrapper(x)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_should_use.py&#34;, line 101, in __init__\n    stack = [s.strip() for s in traceback.format_stack()]&#39;]
==================================
ERROR:tensorflow:==================================
Object was never used (type &lt;class &#39;tensorflow.python.framework.ops.Operation&#39;&gt;):
&lt;tf.Operation &#39;assert_rank_3/Assert/Assert&#39; type=Assert&gt;
If you want to mark it as used call its &#34;mark_used()&#34; method.
It was originally created here:
[&#39;File &#34;/usr/lib/python3.5/runpy.py&#34;, line 184, in _run_module_as_main\n    &#34;__main__&#34;, mod_spec)&#39;, &#39;File &#34;/usr/lib/python3.5/runpy.py&#34;, line 85, in _run_code\n    exec(code, run_globals)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py&#34;, line 16, in &lt;module&gt;\n    app.launch_new_instance()&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py&#34;, line 658, in launch_instance\n    app.start()&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py&#34;, line 477, in start\n    ioloop.IOLoop.instance().start()&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py&#34;, line 177, in start\n    super(ZMQIOLoop, self).start()&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py&#34;, line 888, in start\n    handler_func(fd_obj, events)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py&#34;, line 277, in null_wrapper\n    return fn(*args, **kwargs)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py&#34;, line 440, in _handle_events\n    self._handle_recv()&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py&#34;, line 472, in _handle_recv\n    self._run_callback(callback, msg)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py&#34;, line 414, in _run_callback\n    callback(*args, **kwargs)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py&#34;, line 277, in null_wrapper\n    return fn(*args, **kwargs)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py&#34;, line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py&#34;, line 235, in dispatch_shell\n    handler(stream, idents, msg)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py&#34;, line 399, in execute_request\n    user_expressions, allow_stdin)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py&#34;, line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py&#34;, line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py&#34;, line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py&#34;, line 2856, in run_ast_nodes\n    if self.run_code(code, result):&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py&#34;, line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)&#39;, &#39;File &#34;&lt;ipython-input-7-82f0f446e906&gt;&#34;, line 26, in &lt;module&gt;\n    tests.test_model_inputs(model_inputs)&#39;, &#39;File &#34;/home/ubuntu/deep-learning/language-translation/problem_unittests.py&#34;, line 107, in test_model_inputs\n    assert tf.assert_rank(keep_prob, 0, message=\&#39;Keep Probability has wrong rank\&#39;)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/check_ops.py&#34;, line 617, in assert_rank\n    dynamic_condition, data, summarize)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/check_ops.py&#34;, line 571, in _assert_rank_condition\n    return control_flow_ops.Assert(condition, data, summarize=summarize)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_should_use.py&#34;, line 175, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_should_use.py&#34;, line 144, in _add_should_use_warning\n    wrapped = TFShouldUseWarningWrapper(x)&#39;, &#39;File &#34;/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_should_use.py&#34;, line 101, in __init__\n    stack = [s.strip() for s in traceback.format_stack()]&#39;]
==================================
Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Process-Decoder-Input">Process Decoder Input<a class="anchor-link" href="#Process-Decoder-Input">&#182;</a></h3><p>Implement <code>process_decoder_input</code> by removing the last word id from each batch in <code>target_data</code> and concat the GO ID to the begining of each batch.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">process_decoder_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Preprocess target data for encoding</span>
<span class="sd">    :param target_data: Target Placehoder</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :return: Preprocessed target data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">ending</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strided_slice</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">dec_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">]),</span> <span class="n">ending</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">dec_input</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_process_encoding_input</span><span class="p">(</span><span class="n">process_decoder_input</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Encoding">Encoding<a class="anchor-link" href="#Encoding">&#182;</a></h3><p>Implement <code>encoding_layer()</code> to create a Encoder RNN layer:</p>
<ul>
<li>Embed the encoder input using <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/embed_sequence"><code>tf.contrib.layers.embed_sequence</code></a></li>
<li>Construct a <a href="https://github.com/tensorflow/tensorflow/blob/6947f65a374ebf29e74bb71e36fd82760056d82c/tensorflow/docs_src/tutorials/recurrent.md#stacking-multiple-lstms">stacked</a> <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/LSTMCell"><code>tf.contrib.rnn.LSTMCell</code></a> wrapped in a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/DropoutWrapper"><code>tf.contrib.rnn.DropoutWrapper</code></a></li>
<li>Pass cell and embedded input to <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"><code>tf.nn.dynamic_rnn()</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">imp</span> <span class="k">import</span> <span class="n">reload</span>
<span class="n">reload</span><span class="p">(</span><span class="n">tests</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">encoding_layer</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> 
                   <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> 
                   <span class="n">encoding_embedding_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create encoding layer</span>
<span class="sd">    :param rnn_inputs: Inputs for the RNN</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :param source_sequence_length: a list of the lengths of each sequence in the batch</span>
<span class="sd">    :param source_vocab_size: vocabulary size of source data</span>
<span class="sd">    :param encoding_embedding_size: embedding size of source data</span>
<span class="sd">    :return: tuple (RNN output, RNN state)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">enc_embed_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">embed_sequence</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">encoding_embedding_size</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">make_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
        <span class="n">lstm_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span>
                                           <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform_initializer</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">drop_cell</span> <span class="o">=</span> <span class="n">drop_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">lstm_cell</span><span class="p">,</span> <span class="n">output_keep_prob</span> <span class="o">=</span> <span class="n">keep_prob</span><span class="p">)</span>
    
        <span class="k">return</span> <span class="n">drop_cell</span>

    <span class="n">enc_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">make_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)])</span>
    
    <span class="n">enc_output</span><span class="p">,</span> <span class="n">enc_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">enc_cell</span><span class="p">,</span> <span class="n">enc_embed_input</span><span class="p">,</span>
                                             <span class="n">sequence_length</span> <span class="o">=</span> <span class="n">source_sequence_length</span><span class="p">,</span>
                                             <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">enc_state</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_encoding_layer</span><span class="p">(</span><span class="n">encoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Training">Decoding - Training<a class="anchor-link" href="#Decoding---Training">&#182;</a></h3><p>Create a training decoding layer:</p>
<ul>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/TrainingHelper"><code>tf.contrib.seq2seq.TrainingHelper</code></a> </li>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder"><code>tf.contrib.seq2seq.BasicDecoder</code></a></li>
<li>Obtain the decoder outputs from <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode"><code>tf.contrib.seq2seq.dynamic_decode</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embed_input</span><span class="p">,</span> 
                         <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_summary_length</span><span class="p">,</span> 
                         <span class="n">output_layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a decoding layer for training</span>
<span class="sd">    :param encoder_state: Encoder State</span>
<span class="sd">    :param dec_cell: Decoder RNN Cell</span>
<span class="sd">    :param dec_embed_input: Decoder embedded input</span>
<span class="sd">    :param target_sequence_length: The lengths of each sequence in the target batch</span>
<span class="sd">    :param max_summary_length: The length of the longest sequence in the batch</span>
<span class="sd">    :param output_layer: Function to apply the output layer</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: BasicDecoderOutput containing training logits and sample_id</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">training_helper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">TrainingHelper</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">dec_embed_input</span><span class="p">,</span>
                                                        <span class="n">sequence_length</span><span class="o">=</span><span class="n">target_sequence_length</span><span class="p">,</span>
                                                        <span class="n">time_major</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
        
        <span class="c1"># Basic decoder</span>
    <span class="n">training_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span> 
                                                       <span class="n">training_helper</span><span class="p">,</span>
                                                       <span class="n">encoder_state</span><span class="p">,</span>
                                                       <span class="n">output_layer</span><span class="p">)</span> 
        
        <span class="c1"># Perform dynamic decoding using the decoder</span>
    <span class="n">training_decoder_output</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span><span class="n">training_decoder</span><span class="p">,</span>
                                                                   <span class="n">impute_finished</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                                                                   <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_summary_length</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">training_decoder_output</span>



<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_train</span><span class="p">(</span><span class="n">decoding_layer_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Inference">Decoding - Inference<a class="anchor-link" href="#Decoding---Inference">&#182;</a></h3><p>Create inference decoder:</p>
<ul>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/GreedyEmbeddingHelper"><code>tf.contrib.seq2seq.GreedyEmbeddingHelper</code></a></li>
<li>Create a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder"><code>tf.contrib.seq2seq.BasicDecoder</code></a></li>
<li>Obtain the decoder outputs from <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode"><code>tf.contrib.seq2seq.dynamic_decode</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_infer</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">start_of_sequence_id</span><span class="p">,</span>
                         <span class="n">end_of_sequence_id</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                         <span class="n">vocab_size</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a decoding layer for inference</span>
<span class="sd">    :param encoder_state: Encoder state</span>
<span class="sd">    :param dec_cell: Decoder RNN Cell</span>
<span class="sd">    :param dec_embeddings: Decoder embeddings</span>
<span class="sd">    :param start_of_sequence_id: GO ID</span>
<span class="sd">    :param end_of_sequence_id: EOS Id</span>
<span class="sd">    :param max_target_sequence_length: Maximum length of target sequences</span>
<span class="sd">    :param vocab_size: Size of decoder/target vocabulary</span>
<span class="sd">    :param decoding_scope: TenorFlow Variable Scope for decoding</span>
<span class="sd">    :param output_layer: Function to apply the output layer</span>
<span class="sd">    :param batch_size: Batch size</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :return: BasicDecoderOutput containing inference logits and sample_id</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">start_tokens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="n">start_of_sequence_id</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;start_tokens&#39;</span><span class="p">)</span>
    <span class="n">inference_helper</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">GreedyEmbeddingHelper</span><span class="p">(</span><span class="n">dec_embeddings</span><span class="p">,</span>
                                                                <span class="n">start_tokens</span><span class="p">,</span>
                                                                <span class="n">end_of_sequence_id</span><span class="p">)</span>

        <span class="c1"># Basic decoder</span>
    <span class="n">inference_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span>
                                                        <span class="n">inference_helper</span><span class="p">,</span>
                                                        <span class="n">encoder_state</span><span class="p">,</span>
                                                        <span class="n">output_layer</span><span class="p">)</span>
        
        <span class="c1"># Perform dynamic decoding using the decoder</span>
    <span class="n">inference_decoder_output</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span><span class="n">inference_decoder</span><span class="p">,</span>
                                                                    <span class="n">impute_finished</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                                    <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_target_sequence_length</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">inference_decoder_output</span>



<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_infer</span><span class="p">(</span><span class="n">decoding_layer_infer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Decoding-Layer">Build the Decoding Layer<a class="anchor-link" href="#Build-the-Decoding-Layer">&#182;</a></h3><p>Implement <code>decoding_layer()</code> to create a Decoder RNN layer.</p>
<ul>
<li>Embed the target sequences</li>
<li>Construct the decoder LSTM cell (just like you constructed the encoder cell above)</li>
<li>Create an output layer to map the outputs of the decoder to the elements of our vocabulary</li>
<li>Use the your <code>decoding_layer_train(encoder_state, dec_cell, dec_embed_input, target_sequence_length, max_target_sequence_length, output_layer, keep_prob)</code> function to get the training logits.</li>
<li>Use your <code>decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id, end_of_sequence_id, max_target_sequence_length, vocab_size, output_layer, batch_size, keep_prob)</code> function to get the inference logits.</li>
</ul>
<p>Note: You'll need to use <a href="https://www.tensorflow.org/api_docs/python/tf/variable_scope">tf.variable_scope</a> to share variables between training and inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer</span><span class="p">(</span><span class="n">dec_input</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span>
                   <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                   <span class="n">rnn_size</span><span class="p">,</span>
                   <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                   <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create decoding layer</span>
<span class="sd">    :param dec_input: Decoder input</span>
<span class="sd">    :param encoder_state: Encoder state</span>
<span class="sd">    :param target_sequence_length: The lengths of each sequence in the target batch</span>
<span class="sd">    :param max_target_sequence_length: Maximum length of target sequences</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param target_vocab_size: Size of target vocabulary</span>
<span class="sd">    :param batch_size: The size of the batch</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :param decoding_embedding_size: Decoding embedding size</span>
<span class="sd">    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="c1"># 1. Decoder Embedding</span>
    <span class="n">dec_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">]))</span>
    <span class="n">dec_embed_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">dec_input</span><span class="p">)</span>

    <span class="c1"># 2. Construct the decoder cell</span>
    <span class="k">def</span> <span class="nf">make_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">):</span>
        <span class="n">dec_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span>
                                           <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform_initializer</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">dec_cell</span>

    <span class="n">dec_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">make_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)])</span>
     
    <span class="c1"># 3. Dense layer to translate the decoder&#39;s output at each time </span>
    <span class="c1"># step into a choice from the target vocabulary</span>
    <span class="n">output_layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">,</span>
                         <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal_initializer</span><span class="p">(</span><span class="n">mean</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
    
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;decode&quot;</span><span class="p">):</span>
        <span class="n">training_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embed_input</span><span class="p">,</span>
                                                       <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                                                       <span class="n">output_layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;decode&quot;</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">inference_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer_infer</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">],</span>
                                                        <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">],</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                                                        <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">training_decoder_output</span><span class="p">,</span> <span class="n">inference_decoder_output</span>



<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer</span><span class="p">(</span><span class="n">decoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Neural-Network">Build the Neural Network<a class="anchor-link" href="#Build-the-Neural-Network">&#182;</a></h3><p>Apply the functions you implemented above to:</p>
<ul>
<li>Encode the input using your <code>encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob,  source_sequence_length, source_vocab_size, encoding_embedding_size)</code>.</li>
<li>Process target data using your <code>process_decoder_input(target_data, target_vocab_to_int, batch_size)</code> function.</li>
<li>Decode the encoded input using your <code>decoding_layer(dec_input, enc_state, target_sequence_length, max_target_sentence_length, rnn_size, num_layers, target_vocab_to_int, target_vocab_size, batch_size, keep_prob, dec_embedding_size)</code> function.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">seq2seq_model</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">target_data</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                  <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span>
                  <span class="n">max_target_sentence_length</span><span class="p">,</span>
                  <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                  <span class="n">enc_embedding_size</span><span class="p">,</span> <span class="n">dec_embedding_size</span><span class="p">,</span>
                  <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build the Sequence-to-Sequence part of the neural network</span>
<span class="sd">    :param input_data: Input placeholder</span>
<span class="sd">    :param target_data: Target placeholder</span>
<span class="sd">    :param keep_prob: Dropout keep probability placeholder</span>
<span class="sd">    :param batch_size: Batch Size</span>
<span class="sd">    :param source_sequence_length: Sequence Lengths of source sequences in the batch</span>
<span class="sd">    :param target_sequence_length: Sequence Lengths of target sequences in the batch</span>
<span class="sd">    :param source_vocab_size: Source vocabulary size</span>
<span class="sd">    :param target_vocab_size: Target vocabulary size</span>
<span class="sd">    :param enc_embedding_size: Decoder embedding size</span>
<span class="sd">    :param dec_embedding_size: Encoder embedding size</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">enc_state</span> <span class="o">=</span> <span class="n">encoding_layer</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">source_sequence_length</span><span class="p">,</span>
                                 <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">enc_embedding_size</span><span class="p">)</span>
    
    <span class="n">dec_input</span> <span class="o">=</span> <span class="n">process_decoder_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    
    <span class="n">training_decoder_output</span><span class="p">,</span> <span class="n">inference_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer</span><span class="p">(</span><span class="n">dec_input</span><span class="p">,</span> <span class="n">enc_state</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span>
                                                                       <span class="n">max_target_sentence_length</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> 
                                                                       <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> 
                                                                       <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> 
                                                                       <span class="n">dec_embedding_size</span><span class="p">)</span> 
    
    <span class="k">return</span> <span class="n">training_decoder_output</span><span class="p">,</span> <span class="n">inference_decoder_output</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_seq2seq_model</span><span class="p">(</span><span class="n">seq2seq_model</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Neural-Network-Training">Neural Network Training<a class="anchor-link" href="#Neural-Network-Training">&#182;</a></h2><h3 id="Hyperparameters">Hyperparameters<a class="anchor-link" href="#Hyperparameters">&#182;</a></h3><p>Tune the following parameters:</p>
<ul>
<li>Set <code>epochs</code> to the number of epochs.</li>
<li>Set <code>batch_size</code> to the batch size.</li>
<li>Set <code>rnn_size</code> to the size of the RNNs.</li>
<li>Set <code>num_layers</code> to the number of layers.</li>
<li>Set <code>encoding_embedding_size</code> to the size of the embedding for the encoder.</li>
<li>Set <code>decoding_embedding_size</code> to the size of the embedding for the decoder.</li>
<li>Set <code>learning_rate</code> to the learning rate.</li>
<li>Set <code>keep_probability</code> to the Dropout keep probability</li>
<li>Set <code>display_step</code> to state how many steps between each debug output statement</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Number of Epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">7</span>
<span class="c1"># Batch Size</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">256</span>
<span class="c1"># RNN Size</span>
<span class="n">rnn_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="c1"># Number of Layers</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># Embedding Size</span>
<span class="n">encoding_embedding_size</span> <span class="o">=</span> <span class="mi">150</span>
<span class="n">decoding_embedding_size</span> <span class="o">=</span> <span class="mi">150</span>
<span class="c1"># Learning Rate</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.005</span>
<span class="c1"># Dropout Keep Probability</span>
<span class="n">keep_probability</span> <span class="o">=</span> <span class="mf">0.8</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Build-the-Graph">Build the Graph<a class="anchor-link" href="#Build-the-Graph">&#182;</a></h3><p>Build the graph using the neural network you implemented.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="s1">&#39;checkpoints/dev&#39;</span>
<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">max_target_sentence_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">source_int_text</span><span class="p">])</span>

<span class="n">train_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">train_graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">input_data</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">model_inputs</span><span class="p">()</span>

    <span class="c1">#sequence_length = tf.placeholder_with_default(max_target_sentence_length, None, name=&#39;sequence_length&#39;)</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>

    <span class="n">train_logits</span><span class="p">,</span> <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">seq2seq_model</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
                                                   <span class="n">targets</span><span class="p">,</span>
                                                   <span class="n">keep_prob</span><span class="p">,</span>
                                                   <span class="n">batch_size</span><span class="p">,</span>
                                                   <span class="n">source_sequence_length</span><span class="p">,</span>
                                                   <span class="n">target_sequence_length</span><span class="p">,</span>
                                                   <span class="n">max_target_sequence_length</span><span class="p">,</span>
                                                   <span class="nb">len</span><span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">),</span>
                                                   <span class="nb">len</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">),</span>
                                                   <span class="n">encoding_embedding_size</span><span class="p">,</span>
                                                   <span class="n">decoding_embedding_size</span><span class="p">,</span>
                                                   <span class="n">rnn_size</span><span class="p">,</span>
                                                   <span class="n">num_layers</span><span class="p">,</span>
                                                   <span class="n">target_vocab_to_int</span><span class="p">)</span>


    <span class="n">training_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">train_logits</span><span class="o">.</span><span class="n">rnn_output</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;logits&#39;</span><span class="p">)</span>
    <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">inference_logits</span><span class="o">.</span><span class="n">sample_id</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;predictions&#39;</span><span class="p">)</span>

    <span class="n">masks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sequence_mask</span><span class="p">(</span><span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;masks&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;optimization&quot;</span><span class="p">):</span>
        <span class="c1"># Loss function</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">sequence_loss</span><span class="p">(</span>
            <span class="n">training_logits</span><span class="p">,</span>
            <span class="n">targets</span><span class="p">,</span>
            <span class="n">masks</span><span class="p">)</span>

        <span class="c1"># Optimizer</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>

        <span class="c1"># Gradient Clipping</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
        <span class="n">capped_gradients</span> <span class="o">=</span> <span class="p">[(</span><span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">grad</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">gradients</span> <span class="k">if</span> <span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">capped_gradients</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Batch and pad the source and target sequences</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">pad_sentence_batch</span><span class="p">(</span><span class="n">sentence_batch</span><span class="p">,</span> <span class="n">pad_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Pad sentences with &lt;PAD&gt; so that each sentence of a batch has the same length&quot;&quot;&quot;</span>
    <span class="n">max_sentence</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_batch</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">+</span> <span class="p">[</span><span class="n">pad_int</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_sentence</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">))</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_batch</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">get_batches</span><span class="p">(</span><span class="n">sources</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">source_pad_int</span><span class="p">,</span> <span class="n">target_pad_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Batch targets, sources, and the lengths of their sentences together&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">batch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sources</span><span class="p">)</span><span class="o">//</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">start_i</span> <span class="o">=</span> <span class="n">batch_i</span> <span class="o">*</span> <span class="n">batch_size</span>

        <span class="c1"># Slice the right amount for the batch</span>
        <span class="n">sources_batch</span> <span class="o">=</span> <span class="n">sources</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">start_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="n">targets_batch</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">start_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>

        <span class="c1"># Pad</span>
        <span class="n">pad_sources_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">sources_batch</span><span class="p">,</span> <span class="n">source_pad_int</span><span class="p">))</span>
        <span class="n">pad_targets_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">targets_batch</span><span class="p">,</span> <span class="n">target_pad_int</span><span class="p">))</span>

        <span class="c1"># Need the lengths for the _lengths parameters</span>
        <span class="n">pad_targets_lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">pad_targets_batch</span><span class="p">:</span>
            <span class="n">pad_targets_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="p">))</span>

        <span class="n">pad_source_lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">pad_sources_batch</span><span class="p">:</span>
            <span class="n">pad_source_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">source</span><span class="p">))</span>

        <span class="k">yield</span> <span class="n">pad_sources_batch</span><span class="p">,</span> <span class="n">pad_targets_batch</span><span class="p">,</span> <span class="n">pad_source_lengths</span><span class="p">,</span> <span class="n">pad_targets_lengths</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train">Train<a class="anchor-link" href="#Train">&#182;</a></h3><p>Train the neural network on the preprocessed data. If you have a hard time getting a good loss, check the forms to see if anyone is having the same problem.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">get_accuracy</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate accuracy</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">max_seq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">logits</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">))</span>

<span class="c1"># Split data to training and validation sets</span>
<span class="n">train_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">train_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">valid_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="n">valid_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="p">(</span><span class="n">valid_sources_batch</span><span class="p">,</span> <span class="n">valid_targets_batch</span><span class="p">,</span> <span class="n">valid_sources_lengths</span><span class="p">,</span> <span class="n">valid_targets_lengths</span> <span class="p">)</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">get_batches</span><span class="p">(</span><span class="n">valid_source</span><span class="p">,</span>
                                                                                                             <span class="n">valid_target</span><span class="p">,</span>
                                                                                                             <span class="n">batch_size</span><span class="p">,</span>
                                                                                                             <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">],</span>
                                                                                                             <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">]))</span>                                                                                                  
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">train_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_i</span><span class="p">,</span> <span class="p">(</span><span class="n">source_batch</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">,</span> <span class="n">sources_lengths</span><span class="p">,</span> <span class="n">targets_lengths</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="n">get_batches</span><span class="p">(</span><span class="n">train_source</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                            <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">],</span>
                            <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">])):</span>

            <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="p">[</span><span class="n">train_op</span><span class="p">,</span> <span class="n">cost</span><span class="p">],</span>
                <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                 <span class="n">targets</span><span class="p">:</span> <span class="n">target_batch</span><span class="p">,</span>
                 <span class="n">lr</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
                 <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">targets_lengths</span><span class="p">,</span>
                 <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">sources_lengths</span><span class="p">,</span>
                 <span class="n">keep_prob</span><span class="p">:</span> <span class="n">keep_probability</span><span class="p">})</span>

            <span class="n">batch_train_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="n">inference_logits</span><span class="p">,</span>
                    <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                     <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">sources_lengths</span><span class="p">,</span>
                     <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">targets_lengths</span><span class="p">,</span>
                     <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>


            <span class="n">batch_valid_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="n">inference_logits</span><span class="p">,</span>
                    <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">valid_sources_batch</span><span class="p">,</span>
                     <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">valid_sources_lengths</span><span class="p">,</span>
                     <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">valid_targets_lengths</span><span class="p">,</span>
                     <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>

            <span class="n">train_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">target_batch</span><span class="p">,</span> <span class="n">batch_train_logits</span><span class="p">)</span>

            <span class="n">valid_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">valid_targets_batch</span><span class="p">,</span> <span class="n">batch_valid_logits</span><span class="p">)</span>

            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{:&gt;3}</span><span class="s1"> Batch </span><span class="si">{:&gt;4}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> - Train Accuracy: </span><span class="si">{:&gt;6.4f}</span><span class="s1">, Validation Accuracy: </span><span class="si">{:&gt;6.4f}</span><span class="s1">, Loss: </span><span class="si">{:&gt;6.4f}</span><span class="s1">&#39;</span>
                  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch_i</span><span class="p">,</span> <span class="n">batch_i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_int_text</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">valid_acc</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>

    <span class="c1"># Save Model</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
    <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model Trained and Saved&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch   0 Batch    0/538 - Train Accuracy: 0.2408, Validation Accuracy: 0.3194, Loss: 5.9407
Epoch   0 Batch    1/538 - Train Accuracy: 0.2316, Validation Accuracy: 0.3159, Loss: 5.3708
Epoch   0 Batch    2/538 - Train Accuracy: 0.2766, Validation Accuracy: 0.3384, Loss: 4.6883
Epoch   0 Batch    3/538 - Train Accuracy: 0.2641, Validation Accuracy: 0.3462, Loss: 4.2341
Epoch   0 Batch    4/538 - Train Accuracy: 0.2760, Validation Accuracy: 0.3469, Loss: 3.8594
Epoch   0 Batch    5/538 - Train Accuracy: 0.2984, Validation Accuracy: 0.3473, Loss: 3.5441
Epoch   0 Batch    6/538 - Train Accuracy: 0.3138, Validation Accuracy: 0.3548, Loss: 3.4506
Epoch   0 Batch    7/538 - Train Accuracy: 0.2988, Validation Accuracy: 0.3633, Loss: 3.4590
Epoch   0 Batch    8/538 - Train Accuracy: 0.3143, Validation Accuracy: 0.3778, Loss: 3.3998
Epoch   0 Batch    9/538 - Train Accuracy: 0.3057, Validation Accuracy: 0.3688, Loss: 3.3110
Epoch   0 Batch   10/538 - Train Accuracy: 0.2973, Validation Accuracy: 0.3736, Loss: 3.3435
Epoch   0 Batch   11/538 - Train Accuracy: 0.3029, Validation Accuracy: 0.3727, Loss: 3.2918
Epoch   0 Batch   12/538 - Train Accuracy: 0.2930, Validation Accuracy: 0.3707, Loss: 3.2957
Epoch   0 Batch   13/538 - Train Accuracy: 0.3570, Validation Accuracy: 0.3841, Loss: 3.0211
Epoch   0 Batch   14/538 - Train Accuracy: 0.3223, Validation Accuracy: 0.3887, Loss: 3.1275
Epoch   0 Batch   15/538 - Train Accuracy: 0.3637, Validation Accuracy: 0.3922, Loss: 2.9826
Epoch   0 Batch   16/538 - Train Accuracy: 0.3752, Validation Accuracy: 0.4094, Loss: 2.9463
Epoch   0 Batch   17/538 - Train Accuracy: 0.3598, Validation Accuracy: 0.4144, Loss: 3.0326
Epoch   0 Batch   18/538 - Train Accuracy: 0.3480, Validation Accuracy: 0.4141, Loss: 3.0186
Epoch   0 Batch   19/538 - Train Accuracy: 0.3287, Validation Accuracy: 0.3997, Loss: 3.0025
Epoch   0 Batch   20/538 - Train Accuracy: 0.3651, Validation Accuracy: 0.4048, Loss: 2.8572
Epoch   0 Batch   21/538 - Train Accuracy: 0.2903, Validation Accuracy: 0.3990, Loss: 3.0316
Epoch   0 Batch   22/538 - Train Accuracy: 0.3617, Validation Accuracy: 0.4224, Loss: 2.8769
Epoch   0 Batch   23/538 - Train Accuracy: 0.3646, Validation Accuracy: 0.4187, Loss: 2.8663
Epoch   0 Batch   24/538 - Train Accuracy: 0.3798, Validation Accuracy: 0.4247, Loss: 2.7813
Epoch   0 Batch   25/538 - Train Accuracy: 0.3686, Validation Accuracy: 0.4251, Loss: 2.8130
Epoch   0 Batch   26/538 - Train Accuracy: 0.3729, Validation Accuracy: 0.4334, Loss: 2.8063
Epoch   0 Batch   27/538 - Train Accuracy: 0.3889, Validation Accuracy: 0.4435, Loss: 2.7578
Epoch   0 Batch   28/538 - Train Accuracy: 0.4503, Validation Accuracy: 0.4496, Loss: 2.4986
Epoch   0 Batch   29/538 - Train Accuracy: 0.4040, Validation Accuracy: 0.4453, Loss: 2.6356
Epoch   0 Batch   30/538 - Train Accuracy: 0.3854, Validation Accuracy: 0.4480, Loss: 2.7196
Epoch   0 Batch   31/538 - Train Accuracy: 0.4133, Validation Accuracy: 0.4453, Loss: 2.5522
Epoch   0 Batch   32/538 - Train Accuracy: 0.4025, Validation Accuracy: 0.4538, Loss: 2.6081
Epoch   0 Batch   33/538 - Train Accuracy: 0.4161, Validation Accuracy: 0.4538, Loss: 2.5618
Epoch   0 Batch   34/538 - Train Accuracy: 0.3986, Validation Accuracy: 0.4513, Loss: 2.5959
Epoch   0 Batch   35/538 - Train Accuracy: 0.3836, Validation Accuracy: 0.4462, Loss: 2.5918
Epoch   0 Batch   36/538 - Train Accuracy: 0.4310, Validation Accuracy: 0.4680, Loss: 2.4809
Epoch   0 Batch   37/538 - Train Accuracy: 0.3971, Validation Accuracy: 0.4529, Loss: 2.4978
Epoch   0 Batch   38/538 - Train Accuracy: 0.3984, Validation Accuracy: 0.4664, Loss: 2.5637
Epoch   0 Batch   39/538 - Train Accuracy: 0.4266, Validation Accuracy: 0.4730, Loss: 2.5294
Epoch   0 Batch   40/538 - Train Accuracy: 0.4563, Validation Accuracy: 0.4631, Loss: 2.2714
Epoch   0 Batch   41/538 - Train Accuracy: 0.4338, Validation Accuracy: 0.4822, Loss: 2.4690
Epoch   0 Batch   42/538 - Train Accuracy: 0.4160, Validation Accuracy: 0.4657, Loss: 2.3941
Epoch   0 Batch   43/538 - Train Accuracy: 0.4275, Validation Accuracy: 0.4805, Loss: 2.4292
Epoch   0 Batch   44/538 - Train Accuracy: 0.4283, Validation Accuracy: 0.4851, Loss: 2.4416
Epoch   0 Batch   45/538 - Train Accuracy: 0.4466, Validation Accuracy: 0.4688, Loss: 2.2622
Epoch   0 Batch   46/538 - Train Accuracy: 0.4326, Validation Accuracy: 0.4872, Loss: 2.3637
Epoch   0 Batch   47/538 - Train Accuracy: 0.4576, Validation Accuracy: 0.4842, Loss: 2.2246
Epoch   0 Batch   48/538 - Train Accuracy: 0.4663, Validation Accuracy: 0.4817, Loss: 2.1920
Epoch   0 Batch   49/538 - Train Accuracy: 0.4209, Validation Accuracy: 0.4867, Loss: 2.3500
Epoch   0 Batch   50/538 - Train Accuracy: 0.4406, Validation Accuracy: 0.4899, Loss: 2.2298
Epoch   0 Batch   51/538 - Train Accuracy: 0.3820, Validation Accuracy: 0.4918, Loss: 2.4288
Epoch   0 Batch   52/538 - Train Accuracy: 0.4459, Validation Accuracy: 0.4906, Loss: 2.2194
Epoch   0 Batch   53/538 - Train Accuracy: 0.4750, Validation Accuracy: 0.4886, Loss: 2.0268
Epoch   0 Batch   54/538 - Train Accuracy: 0.4584, Validation Accuracy: 0.4957, Loss: 2.1682
Epoch   0 Batch   55/538 - Train Accuracy: 0.4354, Validation Accuracy: 0.4975, Loss: 2.2023
Epoch   0 Batch   56/538 - Train Accuracy: 0.4501, Validation Accuracy: 0.4853, Loss: 2.1012
Epoch   0 Batch   57/538 - Train Accuracy: 0.4131, Validation Accuracy: 0.4936, Loss: 2.2085
Epoch   0 Batch   58/538 - Train Accuracy: 0.4252, Validation Accuracy: 0.5012, Loss: 2.1877
Epoch   0 Batch   59/538 - Train Accuracy: 0.4271, Validation Accuracy: 0.4867, Loss: 2.1349
Epoch   0 Batch   60/538 - Train Accuracy: 0.4516, Validation Accuracy: 0.5034, Loss: 2.1050
Epoch   0 Batch   61/538 - Train Accuracy: 0.4459, Validation Accuracy: 0.4982, Loss: 2.0490
Epoch   0 Batch   62/538 - Train Accuracy: 0.4435, Validation Accuracy: 0.4915, Loss: 2.0177
Epoch   0 Batch   63/538 - Train Accuracy: 0.4751, Validation Accuracy: 0.5005, Loss: 1.9252
Epoch   0 Batch   64/538 - Train Accuracy: 0.4777, Validation Accuracy: 0.5078, Loss: 1.9231
Epoch   0 Batch   65/538 - Train Accuracy: 0.4289, Validation Accuracy: 0.5021, Loss: 2.0439
Epoch   0 Batch   66/538 - Train Accuracy: 0.4736, Validation Accuracy: 0.5064, Loss: 1.8734
Epoch   0 Batch   67/538 - Train Accuracy: 0.4371, Validation Accuracy: 0.4909, Loss: 1.9293
Epoch   0 Batch   68/538 - Train Accuracy: 0.4728, Validation Accuracy: 0.4982, Loss: 1.8095
Epoch   0 Batch   69/538 - Train Accuracy: 0.4207, Validation Accuracy: 0.4815, Loss: 1.9297
Epoch   0 Batch   70/538 - Train Accuracy: 0.4695, Validation Accuracy: 0.5050, Loss: 1.8729
Epoch   0 Batch   71/538 - Train Accuracy: 0.4566, Validation Accuracy: 0.5085, Loss: 1.8710
Epoch   0 Batch   72/538 - Train Accuracy: 0.4565, Validation Accuracy: 0.4858, Loss: 1.7681
Epoch   0 Batch   73/538 - Train Accuracy: 0.4604, Validation Accuracy: 0.5119, Loss: 1.8499
Epoch   0 Batch   74/538 - Train Accuracy: 0.4805, Validation Accuracy: 0.5055, Loss: 1.7441
Epoch   0 Batch   75/538 - Train Accuracy: 0.4615, Validation Accuracy: 0.4966, Loss: 1.7233
Epoch   0 Batch   76/538 - Train Accuracy: 0.4287, Validation Accuracy: 0.4970, Loss: 1.8215
Epoch   0 Batch   77/538 - Train Accuracy: 0.4473, Validation Accuracy: 0.4913, Loss: 1.7406
Epoch   0 Batch   78/538 - Train Accuracy: 0.4829, Validation Accuracy: 0.5073, Loss: 1.7071
Epoch   0 Batch   79/538 - Train Accuracy: 0.4673, Validation Accuracy: 0.4949, Loss: 1.6091
Epoch   0 Batch   80/538 - Train Accuracy: 0.4623, Validation Accuracy: 0.5051, Loss: 1.7264
Epoch   0 Batch   81/538 - Train Accuracy: 0.4779, Validation Accuracy: 0.5167, Loss: 1.6703
Epoch   0 Batch   82/538 - Train Accuracy: 0.4533, Validation Accuracy: 0.4922, Loss: 1.6168
Epoch   0 Batch   83/538 - Train Accuracy: 0.4404, Validation Accuracy: 0.4988, Loss: 1.6427
Epoch   0 Batch   84/538 - Train Accuracy: 0.4857, Validation Accuracy: 0.5241, Loss: 1.5515
Epoch   0 Batch   85/538 - Train Accuracy: 0.4897, Validation Accuracy: 0.5032, Loss: 1.4867
Epoch   0 Batch   86/538 - Train Accuracy: 0.4371, Validation Accuracy: 0.4920, Loss: 1.5792
Epoch   0 Batch   87/538 - Train Accuracy: 0.4750, Validation Accuracy: 0.5188, Loss: 1.5340
Epoch   0 Batch   88/538 - Train Accuracy: 0.4699, Validation Accuracy: 0.5160, Loss: 1.5271
Epoch   0 Batch   89/538 - Train Accuracy: 0.4561, Validation Accuracy: 0.4970, Loss: 1.4894
Epoch   0 Batch   90/538 - Train Accuracy: 0.4944, Validation Accuracy: 0.5130, Loss: 1.4535
Epoch   0 Batch   91/538 - Train Accuracy: 0.4781, Validation Accuracy: 0.5217, Loss: 1.4826
Epoch   0 Batch   92/538 - Train Accuracy: 0.4645, Validation Accuracy: 0.5094, Loss: 1.4423
Epoch   0 Batch   93/538 - Train Accuracy: 0.4408, Validation Accuracy: 0.5000, Loss: 1.4424
Epoch   0 Batch   94/538 - Train Accuracy: 0.4676, Validation Accuracy: 0.5071, Loss: 1.4433
Epoch   0 Batch   95/538 - Train Accuracy: 0.5208, Validation Accuracy: 0.5098, Loss: 1.2930
Epoch   0 Batch   96/538 - Train Accuracy: 0.5041, Validation Accuracy: 0.5295, Loss: 1.2928
Epoch   0 Batch   97/538 - Train Accuracy: 0.4697, Validation Accuracy: 0.5304, Loss: 1.3626
Epoch   0 Batch   98/538 - Train Accuracy: 0.5033, Validation Accuracy: 0.5259, Loss: 1.2630
Epoch   0 Batch   99/538 - Train Accuracy: 0.4588, Validation Accuracy: 0.5144, Loss: 1.3632
Epoch   0 Batch  100/538 - Train Accuracy: 0.4756, Validation Accuracy: 0.5249, Loss: 1.2984
Epoch   0 Batch  101/538 - Train Accuracy: 0.4826, Validation Accuracy: 0.5289, Loss: 1.3040
Epoch   0 Batch  102/538 - Train Accuracy: 0.4867, Validation Accuracy: 0.5256, Loss: 1.3263
Epoch   0 Batch  103/538 - Train Accuracy: 0.4773, Validation Accuracy: 0.5133, Loss: 1.2851
Epoch   0 Batch  104/538 - Train Accuracy: 0.4632, Validation Accuracy: 0.4961, Loss: 1.2377
Epoch   0 Batch  105/538 - Train Accuracy: 0.4799, Validation Accuracy: 0.5021, Loss: 1.2117
Epoch   0 Batch  106/538 - Train Accuracy: 0.4742, Validation Accuracy: 0.5252, Loss: 1.2249
Epoch   0 Batch  107/538 - Train Accuracy: 0.4777, Validation Accuracy: 0.5380, Loss: 1.2671
Epoch   0 Batch  108/538 - Train Accuracy: 0.4717, Validation Accuracy: 0.5083, Loss: 1.2239
Epoch   0 Batch  109/538 - Train Accuracy: 0.4680, Validation Accuracy: 0.5025, Loss: 1.1884
Epoch   0 Batch  110/538 - Train Accuracy: 0.4670, Validation Accuracy: 0.5206, Loss: 1.2244
Epoch   0 Batch  111/538 - Train Accuracy: 0.5147, Validation Accuracy: 0.5236, Loss: 1.1291
Epoch   0 Batch  112/538 - Train Accuracy: 0.4521, Validation Accuracy: 0.5087, Loss: 1.1845
Epoch   0 Batch  113/538 - Train Accuracy: 0.4846, Validation Accuracy: 0.5282, Loss: 1.1840
Epoch   0 Batch  114/538 - Train Accuracy: 0.5400, Validation Accuracy: 0.5371, Loss: 1.1017
Epoch   0 Batch  115/538 - Train Accuracy: 0.4842, Validation Accuracy: 0.5197, Loss: 1.1236
Epoch   0 Batch  116/538 - Train Accuracy: 0.5201, Validation Accuracy: 0.5368, Loss: 1.1314
Epoch   0 Batch  117/538 - Train Accuracy: 0.5406, Validation Accuracy: 0.5517, Loss: 1.0723
Epoch   0 Batch  118/538 - Train Accuracy: 0.5435, Validation Accuracy: 0.5593, Loss: 1.0615
Epoch   0 Batch  119/538 - Train Accuracy: 0.5272, Validation Accuracy: 0.5453, Loss: 1.0277
Epoch   0 Batch  120/538 - Train Accuracy: 0.5150, Validation Accuracy: 0.5485, Loss: 1.0559
Epoch   0 Batch  121/538 - Train Accuracy: 0.5348, Validation Accuracy: 0.5497, Loss: 1.0136
Epoch   0 Batch  122/538 - Train Accuracy: 0.5212, Validation Accuracy: 0.5417, Loss: 1.0175
Epoch   0 Batch  123/538 - Train Accuracy: 0.5560, Validation Accuracy: 0.5440, Loss: 0.9912
Epoch   0 Batch  124/538 - Train Accuracy: 0.5471, Validation Accuracy: 0.5321, Loss: 0.9570
Epoch   0 Batch  125/538 - Train Accuracy: 0.5205, Validation Accuracy: 0.5275, Loss: 0.9969
Epoch   0 Batch  126/538 - Train Accuracy: 0.5328, Validation Accuracy: 0.5309, Loss: 0.9739
Epoch   0 Batch  127/538 - Train Accuracy: 0.4930, Validation Accuracy: 0.5311, Loss: 1.0397
Epoch   0 Batch  128/538 - Train Accuracy: 0.5158, Validation Accuracy: 0.5352, Loss: 0.9629
Epoch   0 Batch  129/538 - Train Accuracy: 0.5009, Validation Accuracy: 0.5183, Loss: 0.9553
Epoch   0 Batch  130/538 - Train Accuracy: 0.5140, Validation Accuracy: 0.5279, Loss: 0.9570
Epoch   0 Batch  131/538 - Train Accuracy: 0.5062, Validation Accuracy: 0.5259, Loss: 0.9770
Epoch   0 Batch  132/538 - Train Accuracy: 0.5019, Validation Accuracy: 0.5240, Loss: 0.9249
Epoch   0 Batch  133/538 - Train Accuracy: 0.5229, Validation Accuracy: 0.5328, Loss: 0.8935
Epoch   0 Batch  134/538 - Train Accuracy: 0.4869, Validation Accuracy: 0.5304, Loss: 1.0000
Epoch   0 Batch  135/538 - Train Accuracy: 0.5089, Validation Accuracy: 0.5199, Loss: 0.9335
Epoch   0 Batch  136/538 - Train Accuracy: 0.4831, Validation Accuracy: 0.5055, Loss: 0.9175
Epoch   0 Batch  137/538 - Train Accuracy: 0.4946, Validation Accuracy: 0.5188, Loss: 0.9200
Epoch   0 Batch  138/538 - Train Accuracy: 0.5184, Validation Accuracy: 0.5337, Loss: 0.9164
Epoch   0 Batch  139/538 - Train Accuracy: 0.4748, Validation Accuracy: 0.5195, Loss: 0.9771
Epoch   0 Batch  140/538 - Train Accuracy: 0.4990, Validation Accuracy: 0.5321, Loss: 0.9788
Epoch   0 Batch  141/538 - Train Accuracy: 0.4957, Validation Accuracy: 0.5321, Loss: 0.9437
Epoch   0 Batch  142/538 - Train Accuracy: 0.5242, Validation Accuracy: 0.5252, Loss: 0.8612
Epoch   0 Batch  143/538 - Train Accuracy: 0.4795, Validation Accuracy: 0.5188, Loss: 0.9112
Epoch   0 Batch  144/538 - Train Accuracy: 0.5334, Validation Accuracy: 0.5352, Loss: 0.8988
Epoch   0 Batch  145/538 - Train Accuracy: 0.5383, Validation Accuracy: 0.5428, Loss: 0.8891
Epoch   0 Batch  146/538 - Train Accuracy: 0.5357, Validation Accuracy: 0.5396, Loss: 0.8237
Epoch   0 Batch  147/538 - Train Accuracy: 0.5448, Validation Accuracy: 0.5423, Loss: 0.8391
Epoch   0 Batch  148/538 - Train Accuracy: 0.4953, Validation Accuracy: 0.5408, Loss: 0.9229
Epoch   0 Batch  149/538 - Train Accuracy: 0.5160, Validation Accuracy: 0.5494, Loss: 0.8400
Epoch   0 Batch  150/538 - Train Accuracy: 0.5498, Validation Accuracy: 0.5597, Loss: 0.8530
Epoch   0 Batch  151/538 - Train Accuracy: 0.5407, Validation Accuracy: 0.5623, Loss: 0.8241
Epoch   0 Batch  152/538 - Train Accuracy: 0.5446, Validation Accuracy: 0.5623, Loss: 0.8092
Epoch   0 Batch  153/538 - Train Accuracy: 0.5102, Validation Accuracy: 0.5524, Loss: 0.8616
Epoch   0 Batch  154/538 - Train Accuracy: 0.5299, Validation Accuracy: 0.5639, Loss: 0.8065
Epoch   0 Batch  155/538 - Train Accuracy: 0.5673, Validation Accuracy: 0.5607, Loss: 0.8195
Epoch   0 Batch  156/538 - Train Accuracy: 0.5322, Validation Accuracy: 0.5558, Loss: 0.8177
Epoch   0 Batch  157/538 - Train Accuracy: 0.5469, Validation Accuracy: 0.5691, Loss: 0.7843
Epoch   0 Batch  158/538 - Train Accuracy: 0.5393, Validation Accuracy: 0.5732, Loss: 0.8394
Epoch   0 Batch  159/538 - Train Accuracy: 0.5219, Validation Accuracy: 0.5613, Loss: 0.8192
Epoch   0 Batch  160/538 - Train Accuracy: 0.5558, Validation Accuracy: 0.5614, Loss: 0.7714
Epoch   0 Batch  161/538 - Train Accuracy: 0.5645, Validation Accuracy: 0.5861, Loss: 0.8031
Epoch   0 Batch  162/538 - Train Accuracy: 0.5711, Validation Accuracy: 0.5813, Loss: 0.7722
Epoch   0 Batch  163/538 - Train Accuracy: 0.5664, Validation Accuracy: 0.5763, Loss: 0.7956
Epoch   0 Batch  164/538 - Train Accuracy: 0.5570, Validation Accuracy: 0.5717, Loss: 0.8091
Epoch   0 Batch  165/538 - Train Accuracy: 0.5644, Validation Accuracy: 0.5769, Loss: 0.7249
Epoch   0 Batch  166/538 - Train Accuracy: 0.5633, Validation Accuracy: 0.5707, Loss: 0.7733
Epoch   0 Batch  167/538 - Train Accuracy: 0.5889, Validation Accuracy: 0.5701, Loss: 0.7426
Epoch   0 Batch  168/538 - Train Accuracy: 0.5473, Validation Accuracy: 0.5803, Loss: 0.8028
Epoch   0 Batch  169/538 - Train Accuracy: 0.5494, Validation Accuracy: 0.5781, Loss: 0.7513
Epoch   0 Batch  170/538 - Train Accuracy: 0.5454, Validation Accuracy: 0.5778, Loss: 0.7537
Epoch   0 Batch  171/538 - Train Accuracy: 0.5432, Validation Accuracy: 0.5767, Loss: 0.7832
Epoch   0 Batch  172/538 - Train Accuracy: 0.5670, Validation Accuracy: 0.5886, Loss: 0.7387
Epoch   0 Batch  173/538 - Train Accuracy: 0.5688, Validation Accuracy: 0.5772, Loss: 0.7261
Epoch   0 Batch  174/538 - Train Accuracy: 0.5375, Validation Accuracy: 0.5961, Loss: 0.7750
Epoch   0 Batch  175/538 - Train Accuracy: 0.5564, Validation Accuracy: 0.6044, Loss: 0.7694
Epoch   0 Batch  176/538 - Train Accuracy: 0.5748, Validation Accuracy: 0.5994, Loss: 0.7804
Epoch   0 Batch  177/538 - Train Accuracy: 0.5649, Validation Accuracy: 0.5925, Loss: 0.7350
Epoch   0 Batch  178/538 - Train Accuracy: 0.5854, Validation Accuracy: 0.5916, Loss: 0.7052
Epoch   0 Batch  179/538 - Train Accuracy: 0.5627, Validation Accuracy: 0.5874, Loss: 0.7453
Epoch   0 Batch  180/538 - Train Accuracy: 0.5954, Validation Accuracy: 0.5847, Loss: 0.7164
Epoch   0 Batch  181/538 - Train Accuracy: 0.5402, Validation Accuracy: 0.5829, Loss: 0.7592
Epoch   0 Batch  182/538 - Train Accuracy: 0.5391, Validation Accuracy: 0.5803, Loss: 0.7476
Epoch   0 Batch  183/538 - Train Accuracy: 0.6008, Validation Accuracy: 0.5950, Loss: 0.6799
Epoch   0 Batch  184/538 - Train Accuracy: 0.5938, Validation Accuracy: 0.5968, Loss: 0.6862
Epoch   0 Batch  185/538 - Train Accuracy: 0.5783, Validation Accuracy: 0.6117, Loss: 0.7075
Epoch   0 Batch  186/538 - Train Accuracy: 0.5880, Validation Accuracy: 0.6195, Loss: 0.7113
Epoch   0 Batch  187/538 - Train Accuracy: 0.6186, Validation Accuracy: 0.6143, Loss: 0.6699
Epoch   0 Batch  188/538 - Train Accuracy: 0.5924, Validation Accuracy: 0.6163, Loss: 0.7039
Epoch   0 Batch  189/538 - Train Accuracy: 0.6078, Validation Accuracy: 0.6129, Loss: 0.7107
Epoch   0 Batch  190/538 - Train Accuracy: 0.5971, Validation Accuracy: 0.6126, Loss: 0.7078
Epoch   0 Batch  191/538 - Train Accuracy: 0.6257, Validation Accuracy: 0.6126, Loss: 0.6677
Epoch   0 Batch  192/538 - Train Accuracy: 0.5900, Validation Accuracy: 0.6167, Loss: 0.6816
Epoch   0 Batch  193/538 - Train Accuracy: 0.6155, Validation Accuracy: 0.6202, Loss: 0.6609
Epoch   0 Batch  194/538 - Train Accuracy: 0.5893, Validation Accuracy: 0.6273, Loss: 0.7097
Epoch   0 Batch  195/538 - Train Accuracy: 0.6116, Validation Accuracy: 0.6245, Loss: 0.6578
Epoch   0 Batch  196/538 - Train Accuracy: 0.6146, Validation Accuracy: 0.6222, Loss: 0.6600
Epoch   0 Batch  197/538 - Train Accuracy: 0.6101, Validation Accuracy: 0.6248, Loss: 0.6542
Epoch   0 Batch  198/538 - Train Accuracy: 0.6349, Validation Accuracy: 0.6284, Loss: 0.6602
Epoch   0 Batch  199/538 - Train Accuracy: 0.6105, Validation Accuracy: 0.6222, Loss: 0.6845
Epoch   0 Batch  200/538 - Train Accuracy: 0.6232, Validation Accuracy: 0.6151, Loss: 0.6541
Epoch   0 Batch  201/538 - Train Accuracy: 0.5997, Validation Accuracy: 0.6104, Loss: 0.6486
Epoch   0 Batch  202/538 - Train Accuracy: 0.6225, Validation Accuracy: 0.6254, Loss: 0.6842
Epoch   0 Batch  203/538 - Train Accuracy: 0.5764, Validation Accuracy: 0.6310, Loss: 0.6861
Epoch   0 Batch  204/538 - Train Accuracy: 0.6000, Validation Accuracy: 0.6286, Loss: 0.6605
Epoch   0 Batch  205/538 - Train Accuracy: 0.6401, Validation Accuracy: 0.6373, Loss: 0.6273
Epoch   0 Batch  206/538 - Train Accuracy: 0.5840, Validation Accuracy: 0.6346, Loss: 0.6726
Epoch   0 Batch  207/538 - Train Accuracy: 0.6194, Validation Accuracy: 0.6238, Loss: 0.6173
Epoch   0 Batch  208/538 - Train Accuracy: 0.6250, Validation Accuracy: 0.6161, Loss: 0.6524
Epoch   0 Batch  209/538 - Train Accuracy: 0.6285, Validation Accuracy: 0.6135, Loss: 0.6500
Epoch   0 Batch  210/538 - Train Accuracy: 0.6211, Validation Accuracy: 0.6255, Loss: 0.6211
Epoch   0 Batch  211/538 - Train Accuracy: 0.5982, Validation Accuracy: 0.6278, Loss: 0.6594
Epoch   0 Batch  212/538 - Train Accuracy: 0.6213, Validation Accuracy: 0.6374, Loss: 0.6263
Epoch   0 Batch  213/538 - Train Accuracy: 0.6090, Validation Accuracy: 0.6410, Loss: 0.6227
Epoch   0 Batch  214/538 - Train Accuracy: 0.5979, Validation Accuracy: 0.6238, Loss: 0.6254
Epoch   0 Batch  215/538 - Train Accuracy: 0.6248, Validation Accuracy: 0.6378, Loss: 0.6371
Epoch   0 Batch  216/538 - Train Accuracy: 0.6012, Validation Accuracy: 0.6200, Loss: 0.6491
Epoch   0 Batch  217/538 - Train Accuracy: 0.6239, Validation Accuracy: 0.6163, Loss: 0.6020
Epoch   0 Batch  218/538 - Train Accuracy: 0.5922, Validation Accuracy: 0.6064, Loss: 0.6421
Epoch   0 Batch  219/538 - Train Accuracy: 0.6170, Validation Accuracy: 0.6207, Loss: 0.6506
Epoch   0 Batch  220/538 - Train Accuracy: 0.6032, Validation Accuracy: 0.6222, Loss: 0.5958
Epoch   0 Batch  221/538 - Train Accuracy: 0.6414, Validation Accuracy: 0.6341, Loss: 0.5955
Epoch   0 Batch  222/538 - Train Accuracy: 0.6475, Validation Accuracy: 0.6238, Loss: 0.5733
Epoch   0 Batch  223/538 - Train Accuracy: 0.6094, Validation Accuracy: 0.6092, Loss: 0.6233
Epoch   0 Batch  224/538 - Train Accuracy: 0.6172, Validation Accuracy: 0.6246, Loss: 0.6219
Epoch   0 Batch  225/538 - Train Accuracy: 0.6557, Validation Accuracy: 0.6307, Loss: 0.5914
Epoch   0 Batch  226/538 - Train Accuracy: 0.6499, Validation Accuracy: 0.6332, Loss: 0.5783
Epoch   0 Batch  227/538 - Train Accuracy: 0.6461, Validation Accuracy: 0.6225, Loss: 0.5702
Epoch   0 Batch  228/538 - Train Accuracy: 0.6350, Validation Accuracy: 0.6259, Loss: 0.5763
Epoch   0 Batch  229/538 - Train Accuracy: 0.6544, Validation Accuracy: 0.6424, Loss: 0.5842
Epoch   0 Batch  230/538 - Train Accuracy: 0.6107, Validation Accuracy: 0.6523, Loss: 0.5912
Epoch   0 Batch  231/538 - Train Accuracy: 0.6434, Validation Accuracy: 0.6580, Loss: 0.5995
Epoch   0 Batch  232/538 - Train Accuracy: 0.6348, Validation Accuracy: 0.6547, Loss: 0.6008
Epoch   0 Batch  233/538 - Train Accuracy: 0.6689, Validation Accuracy: 0.6481, Loss: 0.5890
Epoch   0 Batch  234/538 - Train Accuracy: 0.6246, Validation Accuracy: 0.6451, Loss: 0.6031
Epoch   0 Batch  235/538 - Train Accuracy: 0.6579, Validation Accuracy: 0.6520, Loss: 0.5573
Epoch   0 Batch  236/538 - Train Accuracy: 0.6332, Validation Accuracy: 0.6475, Loss: 0.5998
Epoch   0 Batch  237/538 - Train Accuracy: 0.6615, Validation Accuracy: 0.6474, Loss: 0.5636
Epoch   0 Batch  238/538 - Train Accuracy: 0.6639, Validation Accuracy: 0.6424, Loss: 0.5634
Epoch   0 Batch  239/538 - Train Accuracy: 0.6395, Validation Accuracy: 0.6474, Loss: 0.5831
Epoch   0 Batch  240/538 - Train Accuracy: 0.6307, Validation Accuracy: 0.6438, Loss: 0.5864
Epoch   0 Batch  241/538 - Train Accuracy: 0.6201, Validation Accuracy: 0.6360, Loss: 0.5772
Epoch   0 Batch  242/538 - Train Accuracy: 0.6580, Validation Accuracy: 0.6236, Loss: 0.5685
Epoch   0 Batch  243/538 - Train Accuracy: 0.6164, Validation Accuracy: 0.6376, Loss: 0.5929
Epoch   0 Batch  244/538 - Train Accuracy: 0.6490, Validation Accuracy: 0.6278, Loss: 0.5534
Epoch   0 Batch  245/538 - Train Accuracy: 0.6334, Validation Accuracy: 0.6477, Loss: 0.5831
Epoch   0 Batch  246/538 - Train Accuracy: 0.6637, Validation Accuracy: 0.6461, Loss: 0.5269
Epoch   0 Batch  247/538 - Train Accuracy: 0.6527, Validation Accuracy: 0.6424, Loss: 0.5688
Epoch   0 Batch  248/538 - Train Accuracy: 0.6471, Validation Accuracy: 0.6449, Loss: 0.5734
Epoch   0 Batch  249/538 - Train Accuracy: 0.6371, Validation Accuracy: 0.6467, Loss: 0.5464
Epoch   0 Batch  250/538 - Train Accuracy: 0.6295, Validation Accuracy: 0.6316, Loss: 0.5571
Epoch   0 Batch  251/538 - Train Accuracy: 0.6230, Validation Accuracy: 0.6072, Loss: 0.5698
Epoch   0 Batch  252/538 - Train Accuracy: 0.6553, Validation Accuracy: 0.6335, Loss: 0.5297
Epoch   0 Batch  253/538 - Train Accuracy: 0.6669, Validation Accuracy: 0.6401, Loss: 0.5334
Epoch   0 Batch  254/538 - Train Accuracy: 0.6570, Validation Accuracy: 0.6394, Loss: 0.5558
Epoch   0 Batch  255/538 - Train Accuracy: 0.6580, Validation Accuracy: 0.6449, Loss: 0.5427
Epoch   0 Batch  256/538 - Train Accuracy: 0.6354, Validation Accuracy: 0.6420, Loss: 0.5592
Epoch   0 Batch  257/538 - Train Accuracy: 0.6797, Validation Accuracy: 0.6484, Loss: 0.5300
Epoch   0 Batch  258/538 - Train Accuracy: 0.6683, Validation Accuracy: 0.6332, Loss: 0.5359
Epoch   0 Batch  259/538 - Train Accuracy: 0.6685, Validation Accuracy: 0.6390, Loss: 0.5108
Epoch   0 Batch  260/538 - Train Accuracy: 0.6222, Validation Accuracy: 0.6422, Loss: 0.5328
Epoch   0 Batch  261/538 - Train Accuracy: 0.6219, Validation Accuracy: 0.6387, Loss: 0.5546
Epoch   0 Batch  262/538 - Train Accuracy: 0.6350, Validation Accuracy: 0.6214, Loss: 0.5314
Epoch   0 Batch  263/538 - Train Accuracy: 0.6436, Validation Accuracy: 0.6257, Loss: 0.5297
Epoch   0 Batch  264/538 - Train Accuracy: 0.6439, Validation Accuracy: 0.6261, Loss: 0.5486
Epoch   0 Batch  265/538 - Train Accuracy: 0.6285, Validation Accuracy: 0.6355, Loss: 0.5551
Epoch   0 Batch  266/538 - Train Accuracy: 0.6730, Validation Accuracy: 0.6387, Loss: 0.5272
Epoch   0 Batch  267/538 - Train Accuracy: 0.6732, Validation Accuracy: 0.6426, Loss: 0.5234
Epoch   0 Batch  268/538 - Train Accuracy: 0.6760, Validation Accuracy: 0.6525, Loss: 0.4927
Epoch   0 Batch  269/538 - Train Accuracy: 0.6662, Validation Accuracy: 0.6575, Loss: 0.5155
Epoch   0 Batch  270/538 - Train Accuracy: 0.6623, Validation Accuracy: 0.6507, Loss: 0.5239
Epoch   0 Batch  271/538 - Train Accuracy: 0.6453, Validation Accuracy: 0.6454, Loss: 0.5263
Epoch   0 Batch  272/538 - Train Accuracy: 0.6498, Validation Accuracy: 0.6497, Loss: 0.5527
Epoch   0 Batch  273/538 - Train Accuracy: 0.6775, Validation Accuracy: 0.6671, Loss: 0.5263
Epoch   0 Batch  274/538 - Train Accuracy: 0.6279, Validation Accuracy: 0.6669, Loss: 0.5514
Epoch   0 Batch  275/538 - Train Accuracy: 0.6633, Validation Accuracy: 0.6575, Loss: 0.5333
Epoch   0 Batch  276/538 - Train Accuracy: 0.6566, Validation Accuracy: 0.6566, Loss: 0.5217
Epoch   0 Batch  277/538 - Train Accuracy: 0.6596, Validation Accuracy: 0.6564, Loss: 0.5116
Epoch   0 Batch  278/538 - Train Accuracy: 0.6717, Validation Accuracy: 0.6683, Loss: 0.5151
Epoch   0 Batch  279/538 - Train Accuracy: 0.6809, Validation Accuracy: 0.6706, Loss: 0.4992
Epoch   0 Batch  280/538 - Train Accuracy: 0.6892, Validation Accuracy: 0.6701, Loss: 0.4822
Epoch   0 Batch  281/538 - Train Accuracy: 0.6395, Validation Accuracy: 0.6602, Loss: 0.5174
Epoch   0 Batch  282/538 - Train Accuracy: 0.6739, Validation Accuracy: 0.6564, Loss: 0.5069
Epoch   0 Batch  283/538 - Train Accuracy: 0.6826, Validation Accuracy: 0.6602, Loss: 0.4986
Epoch   0 Batch  284/538 - Train Accuracy: 0.6902, Validation Accuracy: 0.6614, Loss: 0.4959
Epoch   0 Batch  285/538 - Train Accuracy: 0.6672, Validation Accuracy: 0.6555, Loss: 0.4682
Epoch   0 Batch  286/538 - Train Accuracy: 0.6768, Validation Accuracy: 0.6547, Loss: 0.4997
Epoch   0 Batch  287/538 - Train Accuracy: 0.6765, Validation Accuracy: 0.6520, Loss: 0.4808
Epoch   0 Batch  288/538 - Train Accuracy: 0.6906, Validation Accuracy: 0.6648, Loss: 0.4951
Epoch   0 Batch  289/538 - Train Accuracy: 0.6981, Validation Accuracy: 0.6768, Loss: 0.4576
Epoch   0 Batch  290/538 - Train Accuracy: 0.6715, Validation Accuracy: 0.6788, Loss: 0.4806
Epoch   0 Batch  291/538 - Train Accuracy: 0.6955, Validation Accuracy: 0.6713, Loss: 0.4727
Epoch   0 Batch  292/538 - Train Accuracy: 0.6838, Validation Accuracy: 0.6674, Loss: 0.4619
Epoch   0 Batch  293/538 - Train Accuracy: 0.6914, Validation Accuracy: 0.6674, Loss: 0.4672
Epoch   0 Batch  294/538 - Train Accuracy: 0.6525, Validation Accuracy: 0.6598, Loss: 0.5029
Epoch   0 Batch  295/538 - Train Accuracy: 0.6962, Validation Accuracy: 0.6575, Loss: 0.4430
Epoch   0 Batch  296/538 - Train Accuracy: 0.6851, Validation Accuracy: 0.6561, Loss: 0.4703
Epoch   0 Batch  297/538 - Train Accuracy: 0.6631, Validation Accuracy: 0.6472, Loss: 0.4801
Epoch   0 Batch  298/538 - Train Accuracy: 0.6603, Validation Accuracy: 0.6381, Loss: 0.4670
Epoch   0 Batch  299/538 - Train Accuracy: 0.6868, Validation Accuracy: 0.6561, Loss: 0.4763
Epoch   0 Batch  300/538 - Train Accuracy: 0.6903, Validation Accuracy: 0.6634, Loss: 0.4538
Epoch   0 Batch  301/538 - Train Accuracy: 0.7011, Validation Accuracy: 0.6681, Loss: 0.4637
Epoch   0 Batch  302/538 - Train Accuracy: 0.7059, Validation Accuracy: 0.6632, Loss: 0.4444
Epoch   0 Batch  303/538 - Train Accuracy: 0.6976, Validation Accuracy: 0.6756, Loss: 0.4372
Epoch   0 Batch  304/538 - Train Accuracy: 0.6617, Validation Accuracy: 0.6918, Loss: 0.4642
Epoch   0 Batch  305/538 - Train Accuracy: 0.6886, Validation Accuracy: 0.6795, Loss: 0.4440
Epoch   0 Batch  306/538 - Train Accuracy: 0.6840, Validation Accuracy: 0.6673, Loss: 0.4438
Epoch   0 Batch  307/538 - Train Accuracy: 0.6855, Validation Accuracy: 0.6745, Loss: 0.4516
Epoch   0 Batch  308/538 - Train Accuracy: 0.7106, Validation Accuracy: 0.6765, Loss: 0.4390
Epoch   0 Batch  309/538 - Train Accuracy: 0.6818, Validation Accuracy: 0.6616, Loss: 0.4463
Epoch   0 Batch  310/538 - Train Accuracy: 0.7088, Validation Accuracy: 0.6637, Loss: 0.4558
Epoch   0 Batch  311/538 - Train Accuracy: 0.6756, Validation Accuracy: 0.6703, Loss: 0.4292
Epoch   0 Batch  312/538 - Train Accuracy: 0.7182, Validation Accuracy: 0.6884, Loss: 0.4126
Epoch   0 Batch  313/538 - Train Accuracy: 0.6813, Validation Accuracy: 0.6957, Loss: 0.4614
Epoch   0 Batch  314/538 - Train Accuracy: 0.6891, Validation Accuracy: 0.6891, Loss: 0.4484
Epoch   0 Batch  315/538 - Train Accuracy: 0.6964, Validation Accuracy: 0.6800, Loss: 0.4305
Epoch   0 Batch  316/538 - Train Accuracy: 0.7115, Validation Accuracy: 0.6777, Loss: 0.4210
Epoch   0 Batch  317/538 - Train Accuracy: 0.6865, Validation Accuracy: 0.6847, Loss: 0.4387
Epoch   0 Batch  318/538 - Train Accuracy: 0.7059, Validation Accuracy: 0.7076, Loss: 0.4356
Epoch   0 Batch  319/538 - Train Accuracy: 0.7167, Validation Accuracy: 0.6974, Loss: 0.4271
Epoch   0 Batch  320/538 - Train Accuracy: 0.6739, Validation Accuracy: 0.7021, Loss: 0.4249
Epoch   0 Batch  321/538 - Train Accuracy: 0.7055, Validation Accuracy: 0.6983, Loss: 0.4147
Epoch   0 Batch  322/538 - Train Accuracy: 0.7154, Validation Accuracy: 0.6824, Loss: 0.4092
Epoch   0 Batch  323/538 - Train Accuracy: 0.7130, Validation Accuracy: 0.6818, Loss: 0.4095
Epoch   0 Batch  324/538 - Train Accuracy: 0.6521, Validation Accuracy: 0.6900, Loss: 0.4491
Epoch   0 Batch  325/538 - Train Accuracy: 0.7223, Validation Accuracy: 0.6825, Loss: 0.4143
Epoch   0 Batch  326/538 - Train Accuracy: 0.6932, Validation Accuracy: 0.6847, Loss: 0.4330
Epoch   0 Batch  327/538 - Train Accuracy: 0.6922, Validation Accuracy: 0.6903, Loss: 0.4348
Epoch   0 Batch  328/538 - Train Accuracy: 0.7266, Validation Accuracy: 0.6898, Loss: 0.4031
Epoch   0 Batch  329/538 - Train Accuracy: 0.7262, Validation Accuracy: 0.6946, Loss: 0.4113
Epoch   0 Batch  330/538 - Train Accuracy: 0.7163, Validation Accuracy: 0.7118, Loss: 0.3995
Epoch   0 Batch  331/538 - Train Accuracy: 0.7061, Validation Accuracy: 0.7065, Loss: 0.4060
Epoch   0 Batch  332/538 - Train Accuracy: 0.7006, Validation Accuracy: 0.7095, Loss: 0.4216
Epoch   0 Batch  333/538 - Train Accuracy: 0.7085, Validation Accuracy: 0.7019, Loss: 0.3986
Epoch   0 Batch  334/538 - Train Accuracy: 0.7360, Validation Accuracy: 0.6926, Loss: 0.3801
Epoch   0 Batch  335/538 - Train Accuracy: 0.7139, Validation Accuracy: 0.6946, Loss: 0.3974
Epoch   0 Batch  336/538 - Train Accuracy: 0.7275, Validation Accuracy: 0.7013, Loss: 0.3907
Epoch   0 Batch  337/538 - Train Accuracy: 0.7217, Validation Accuracy: 0.7111, Loss: 0.3943
Epoch   0 Batch  338/538 - Train Accuracy: 0.6853, Validation Accuracy: 0.7184, Loss: 0.3996
Epoch   0 Batch  339/538 - Train Accuracy: 0.7070, Validation Accuracy: 0.7182, Loss: 0.3854
Epoch   0 Batch  340/538 - Train Accuracy: 0.7115, Validation Accuracy: 0.7033, Loss: 0.4082
Epoch   0 Batch  341/538 - Train Accuracy: 0.7135, Validation Accuracy: 0.6896, Loss: 0.3978
Epoch   0 Batch  342/538 - Train Accuracy: 0.6912, Validation Accuracy: 0.6955, Loss: 0.3806
Epoch   0 Batch  343/538 - Train Accuracy: 0.7248, Validation Accuracy: 0.7003, Loss: 0.4025
Epoch   0 Batch  344/538 - Train Accuracy: 0.7104, Validation Accuracy: 0.7191, Loss: 0.3869
Epoch   0 Batch  345/538 - Train Accuracy: 0.7457, Validation Accuracy: 0.7255, Loss: 0.3851
Epoch   0 Batch  346/538 - Train Accuracy: 0.7422, Validation Accuracy: 0.7116, Loss: 0.3897
Epoch   0 Batch  347/538 - Train Accuracy: 0.7195, Validation Accuracy: 0.7127, Loss: 0.3910
Epoch   0 Batch  348/538 - Train Accuracy: 0.7169, Validation Accuracy: 0.7102, Loss: 0.3692
Epoch   0 Batch  349/538 - Train Accuracy: 0.7234, Validation Accuracy: 0.7132, Loss: 0.3782
Epoch   0 Batch  350/538 - Train Accuracy: 0.7400, Validation Accuracy: 0.7239, Loss: 0.3836
Epoch   0 Batch  351/538 - Train Accuracy: 0.7096, Validation Accuracy: 0.7262, Loss: 0.4018
Epoch   0 Batch  352/538 - Train Accuracy: 0.7349, Validation Accuracy: 0.7246, Loss: 0.3990
Epoch   0 Batch  353/538 - Train Accuracy: 0.7387, Validation Accuracy: 0.7266, Loss: 0.3921
Epoch   0 Batch  354/538 - Train Accuracy: 0.7127, Validation Accuracy: 0.7065, Loss: 0.3845
Epoch   0 Batch  355/538 - Train Accuracy: 0.7342, Validation Accuracy: 0.7001, Loss: 0.3845
Epoch   0 Batch  356/538 - Train Accuracy: 0.7383, Validation Accuracy: 0.7047, Loss: 0.3406
Epoch   0 Batch  357/538 - Train Accuracy: 0.7514, Validation Accuracy: 0.7138, Loss: 0.3702
Epoch   0 Batch  358/538 - Train Accuracy: 0.7400, Validation Accuracy: 0.7196, Loss: 0.3695
Epoch   0 Batch  359/538 - Train Accuracy: 0.7346, Validation Accuracy: 0.7129, Loss: 0.3660
Epoch   0 Batch  360/538 - Train Accuracy: 0.7236, Validation Accuracy: 0.7251, Loss: 0.3742
Epoch   0 Batch  361/538 - Train Accuracy: 0.7602, Validation Accuracy: 0.7488, Loss: 0.3597
Epoch   0 Batch  362/538 - Train Accuracy: 0.7593, Validation Accuracy: 0.7493, Loss: 0.3470
Epoch   0 Batch  363/538 - Train Accuracy: 0.7411, Validation Accuracy: 0.7438, Loss: 0.3479
Epoch   0 Batch  364/538 - Train Accuracy: 0.7125, Validation Accuracy: 0.7113, Loss: 0.3840
Epoch   0 Batch  365/538 - Train Accuracy: 0.7254, Validation Accuracy: 0.7136, Loss: 0.3569
Epoch   0 Batch  366/538 - Train Accuracy: 0.7459, Validation Accuracy: 0.7223, Loss: 0.3690
Epoch   0 Batch  367/538 - Train Accuracy: 0.7648, Validation Accuracy: 0.7246, Loss: 0.3494
Epoch   0 Batch  368/538 - Train Accuracy: 0.7624, Validation Accuracy: 0.7294, Loss: 0.3162
Epoch   0 Batch  369/538 - Train Accuracy: 0.7312, Validation Accuracy: 0.7386, Loss: 0.3472
Epoch   0 Batch  370/538 - Train Accuracy: 0.7549, Validation Accuracy: 0.7377, Loss: 0.3606
Epoch   0 Batch  371/538 - Train Accuracy: 0.7684, Validation Accuracy: 0.7456, Loss: 0.3340
Epoch   0 Batch  372/538 - Train Accuracy: 0.7656, Validation Accuracy: 0.7425, Loss: 0.3470
Epoch   0 Batch  373/538 - Train Accuracy: 0.7701, Validation Accuracy: 0.7493, Loss: 0.3363
Epoch   0 Batch  374/538 - Train Accuracy: 0.7672, Validation Accuracy: 0.7543, Loss: 0.3522
Epoch   0 Batch  375/538 - Train Accuracy: 0.7829, Validation Accuracy: 0.7576, Loss: 0.3151
Epoch   0 Batch  376/538 - Train Accuracy: 0.7807, Validation Accuracy: 0.7496, Loss: 0.3471
Epoch   0 Batch  377/538 - Train Accuracy: 0.7564, Validation Accuracy: 0.7495, Loss: 0.3384
Epoch   0 Batch  378/538 - Train Accuracy: 0.7790, Validation Accuracy: 0.7518, Loss: 0.3256
Epoch   0 Batch  379/538 - Train Accuracy: 0.7855, Validation Accuracy: 0.7518, Loss: 0.3182
Epoch   0 Batch  380/538 - Train Accuracy: 0.7656, Validation Accuracy: 0.7461, Loss: 0.3245
Epoch   0 Batch  381/538 - Train Accuracy: 0.7812, Validation Accuracy: 0.7463, Loss: 0.3114
Epoch   0 Batch  382/538 - Train Accuracy: 0.7428, Validation Accuracy: 0.7440, Loss: 0.3318
Epoch   0 Batch  383/538 - Train Accuracy: 0.7795, Validation Accuracy: 0.7555, Loss: 0.3328
Epoch   0 Batch  384/538 - Train Accuracy: 0.7796, Validation Accuracy: 0.7626, Loss: 0.3203
Epoch   0 Batch  385/538 - Train Accuracy: 0.7667, Validation Accuracy: 0.7674, Loss: 0.3210
Epoch   0 Batch  386/538 - Train Accuracy: 0.7832, Validation Accuracy: 0.7686, Loss: 0.3391
Epoch   0 Batch  387/538 - Train Accuracy: 0.7937, Validation Accuracy: 0.7802, Loss: 0.3244
Epoch   0 Batch  388/538 - Train Accuracy: 0.8095, Validation Accuracy: 0.7717, Loss: 0.3191
Epoch   0 Batch  389/538 - Train Accuracy: 0.7590, Validation Accuracy: 0.7541, Loss: 0.3428
Epoch   0 Batch  390/538 - Train Accuracy: 0.8060, Validation Accuracy: 0.7640, Loss: 0.3096
Epoch   0 Batch  391/538 - Train Accuracy: 0.7837, Validation Accuracy: 0.7765, Loss: 0.3105
Epoch   0 Batch  392/538 - Train Accuracy: 0.7985, Validation Accuracy: 0.7690, Loss: 0.3079
Epoch   0 Batch  393/538 - Train Accuracy: 0.7935, Validation Accuracy: 0.7640, Loss: 0.3028
Epoch   0 Batch  394/538 - Train Accuracy: 0.7244, Validation Accuracy: 0.7573, Loss: 0.3353
Epoch   0 Batch  395/538 - Train Accuracy: 0.7592, Validation Accuracy: 0.7631, Loss: 0.3235
Epoch   0 Batch  396/538 - Train Accuracy: 0.7994, Validation Accuracy: 0.7713, Loss: 0.3170
Epoch   0 Batch  397/538 - Train Accuracy: 0.7701, Validation Accuracy: 0.7740, Loss: 0.3200
Epoch   0 Batch  398/538 - Train Accuracy: 0.7789, Validation Accuracy: 0.7741, Loss: 0.3196
Epoch   0 Batch  399/538 - Train Accuracy: 0.7527, Validation Accuracy: 0.7805, Loss: 0.3340
Epoch   0 Batch  400/538 - Train Accuracy: 0.7978, Validation Accuracy: 0.7631, Loss: 0.3156
Epoch   0 Batch  401/538 - Train Accuracy: 0.7773, Validation Accuracy: 0.7718, Loss: 0.3179
Epoch   0 Batch  402/538 - Train Accuracy: 0.7881, Validation Accuracy: 0.7672, Loss: 0.3064
Epoch   0 Batch  403/538 - Train Accuracy: 0.7916, Validation Accuracy: 0.7745, Loss: 0.3142
Epoch   0 Batch  404/538 - Train Accuracy: 0.7818, Validation Accuracy: 0.7674, Loss: 0.2952
Epoch   0 Batch  405/538 - Train Accuracy: 0.7896, Validation Accuracy: 0.7678, Loss: 0.2960
Epoch   0 Batch  406/538 - Train Accuracy: 0.7664, Validation Accuracy: 0.7459, Loss: 0.2901
Epoch   0 Batch  407/538 - Train Accuracy: 0.7912, Validation Accuracy: 0.7692, Loss: 0.3088
Epoch   0 Batch  408/538 - Train Accuracy: 0.7783, Validation Accuracy: 0.7887, Loss: 0.3191
Epoch   0 Batch  409/538 - Train Accuracy: 0.7820, Validation Accuracy: 0.7896, Loss: 0.3047
Epoch   0 Batch  410/538 - Train Accuracy: 0.8033, Validation Accuracy: 0.7834, Loss: 0.2976
Epoch   0 Batch  411/538 - Train Accuracy: 0.8233, Validation Accuracy: 0.7864, Loss: 0.2852
Epoch   0 Batch  412/538 - Train Accuracy: 0.8116, Validation Accuracy: 0.7914, Loss: 0.2770
Epoch   0 Batch  413/538 - Train Accuracy: 0.8203, Validation Accuracy: 0.7962, Loss: 0.2902
Epoch   0 Batch  414/538 - Train Accuracy: 0.7863, Validation Accuracy: 0.7811, Loss: 0.2983
Epoch   0 Batch  415/538 - Train Accuracy: 0.8031, Validation Accuracy: 0.7793, Loss: 0.2966
Epoch   0 Batch  416/538 - Train Accuracy: 0.8061, Validation Accuracy: 0.7891, Loss: 0.2841
Epoch   0 Batch  417/538 - Train Accuracy: 0.8084, Validation Accuracy: 0.7894, Loss: 0.2852
Epoch   0 Batch  418/538 - Train Accuracy: 0.8035, Validation Accuracy: 0.7868, Loss: 0.2935
Epoch   0 Batch  419/538 - Train Accuracy: 0.8021, Validation Accuracy: 0.7821, Loss: 0.2764
Epoch   0 Batch  420/538 - Train Accuracy: 0.8271, Validation Accuracy: 0.7884, Loss: 0.2804
Epoch   0 Batch  421/538 - Train Accuracy: 0.8218, Validation Accuracy: 0.7978, Loss: 0.2699
Epoch   0 Batch  422/538 - Train Accuracy: 0.8145, Validation Accuracy: 0.8068, Loss: 0.2794
Epoch   0 Batch  423/538 - Train Accuracy: 0.8268, Validation Accuracy: 0.8061, Loss: 0.2816
Epoch   0 Batch  424/538 - Train Accuracy: 0.7933, Validation Accuracy: 0.8036, Loss: 0.2737
Epoch   0 Batch  425/538 - Train Accuracy: 0.8114, Validation Accuracy: 0.8066, Loss: 0.2790
Epoch   0 Batch  426/538 - Train Accuracy: 0.8074, Validation Accuracy: 0.8189, Loss: 0.2666
Epoch   0 Batch  427/538 - Train Accuracy: 0.7994, Validation Accuracy: 0.8063, Loss: 0.2742
Epoch   0 Batch  428/538 - Train Accuracy: 0.8343, Validation Accuracy: 0.8065, Loss: 0.2563
Epoch   0 Batch  429/538 - Train Accuracy: 0.8253, Validation Accuracy: 0.8287, Loss: 0.2695
Epoch   0 Batch  430/538 - Train Accuracy: 0.8268, Validation Accuracy: 0.8265, Loss: 0.2667
Epoch   0 Batch  431/538 - Train Accuracy: 0.8242, Validation Accuracy: 0.8184, Loss: 0.2663
Epoch   0 Batch  432/538 - Train Accuracy: 0.8260, Validation Accuracy: 0.8066, Loss: 0.2537
Epoch   0 Batch  433/538 - Train Accuracy: 0.8066, Validation Accuracy: 0.7935, Loss: 0.2901
Epoch   0 Batch  434/538 - Train Accuracy: 0.7764, Validation Accuracy: 0.8059, Loss: 0.2723
Epoch   0 Batch  435/538 - Train Accuracy: 0.8203, Validation Accuracy: 0.8141, Loss: 0.2557
Epoch   0 Batch  436/538 - Train Accuracy: 0.8016, Validation Accuracy: 0.8033, Loss: 0.2803
Epoch   0 Batch  437/538 - Train Accuracy: 0.8189, Validation Accuracy: 0.8127, Loss: 0.2701
Epoch   0 Batch  438/538 - Train Accuracy: 0.8221, Validation Accuracy: 0.8176, Loss: 0.2553
Epoch   0 Batch  439/538 - Train Accuracy: 0.8248, Validation Accuracy: 0.7978, Loss: 0.2513
Epoch   0 Batch  440/538 - Train Accuracy: 0.8164, Validation Accuracy: 0.8072, Loss: 0.2826
Epoch   0 Batch  441/538 - Train Accuracy: 0.8094, Validation Accuracy: 0.8129, Loss: 0.2708
Epoch   0 Batch  442/538 - Train Accuracy: 0.8418, Validation Accuracy: 0.8024, Loss: 0.2243
Epoch   0 Batch  443/538 - Train Accuracy: 0.8311, Validation Accuracy: 0.8004, Loss: 0.2513
Epoch   0 Batch  444/538 - Train Accuracy: 0.8443, Validation Accuracy: 0.8081, Loss: 0.2468
Epoch   0 Batch  445/538 - Train Accuracy: 0.8492, Validation Accuracy: 0.8058, Loss: 0.2465
Epoch   0 Batch  446/538 - Train Accuracy: 0.8356, Validation Accuracy: 0.8033, Loss: 0.2367
Epoch   0 Batch  447/538 - Train Accuracy: 0.8211, Validation Accuracy: 0.8217, Loss: 0.2597
Epoch   0 Batch  448/538 - Train Accuracy: 0.8328, Validation Accuracy: 0.8178, Loss: 0.2246
Epoch   0 Batch  449/538 - Train Accuracy: 0.8387, Validation Accuracy: 0.8235, Loss: 0.2582
Epoch   0 Batch  450/538 - Train Accuracy: 0.8244, Validation Accuracy: 0.8145, Loss: 0.2573
Epoch   0 Batch  451/538 - Train Accuracy: 0.8160, Validation Accuracy: 0.8113, Loss: 0.2484
Epoch   0 Batch  452/538 - Train Accuracy: 0.8439, Validation Accuracy: 0.7985, Loss: 0.2224
Epoch   0 Batch  453/538 - Train Accuracy: 0.8285, Validation Accuracy: 0.8194, Loss: 0.2449
Epoch   0 Batch  454/538 - Train Accuracy: 0.8475, Validation Accuracy: 0.8084, Loss: 0.2431
Epoch   0 Batch  455/538 - Train Accuracy: 0.8411, Validation Accuracy: 0.8136, Loss: 0.2239
Epoch   0 Batch  456/538 - Train Accuracy: 0.8713, Validation Accuracy: 0.8175, Loss: 0.2226
Epoch   0 Batch  457/538 - Train Accuracy: 0.8203, Validation Accuracy: 0.8210, Loss: 0.2502
Epoch   0 Batch  458/538 - Train Accuracy: 0.8408, Validation Accuracy: 0.8295, Loss: 0.2209
Epoch   0 Batch  459/538 - Train Accuracy: 0.8535, Validation Accuracy: 0.8242, Loss: 0.2214
Epoch   0 Batch  460/538 - Train Accuracy: 0.8196, Validation Accuracy: 0.8185, Loss: 0.2314
Epoch   0 Batch  461/538 - Train Accuracy: 0.8292, Validation Accuracy: 0.8162, Loss: 0.2411
Epoch   0 Batch  462/538 - Train Accuracy: 0.8198, Validation Accuracy: 0.8232, Loss: 0.2215
Epoch   0 Batch  463/538 - Train Accuracy: 0.8203, Validation Accuracy: 0.8304, Loss: 0.2428
Epoch   0 Batch  464/538 - Train Accuracy: 0.8326, Validation Accuracy: 0.8276, Loss: 0.2306
Epoch   0 Batch  465/538 - Train Accuracy: 0.8387, Validation Accuracy: 0.8398, Loss: 0.2234
Epoch   0 Batch  466/538 - Train Accuracy: 0.8525, Validation Accuracy: 0.8432, Loss: 0.2239
Epoch   0 Batch  467/538 - Train Accuracy: 0.8512, Validation Accuracy: 0.8425, Loss: 0.2272
Epoch   0 Batch  468/538 - Train Accuracy: 0.8596, Validation Accuracy: 0.8388, Loss: 0.2395
Epoch   0 Batch  469/538 - Train Accuracy: 0.8365, Validation Accuracy: 0.8361, Loss: 0.2206
Epoch   0 Batch  470/538 - Train Accuracy: 0.8491, Validation Accuracy: 0.8274, Loss: 0.2084
Epoch   0 Batch  471/538 - Train Accuracy: 0.8237, Validation Accuracy: 0.8212, Loss: 0.2115
Epoch   0 Batch  472/538 - Train Accuracy: 0.8701, Validation Accuracy: 0.8333, Loss: 0.2198
Epoch   0 Batch  473/538 - Train Accuracy: 0.8416, Validation Accuracy: 0.8317, Loss: 0.2188
Epoch   0 Batch  474/538 - Train Accuracy: 0.8594, Validation Accuracy: 0.8379, Loss: 0.2032
Epoch   0 Batch  475/538 - Train Accuracy: 0.8560, Validation Accuracy: 0.8374, Loss: 0.2065
Epoch   0 Batch  476/538 - Train Accuracy: 0.8389, Validation Accuracy: 0.8489, Loss: 0.2204
Epoch   0 Batch  477/538 - Train Accuracy: 0.8313, Validation Accuracy: 0.8235, Loss: 0.2194
Epoch   0 Batch  478/538 - Train Accuracy: 0.8542, Validation Accuracy: 0.8271, Loss: 0.2023
Epoch   0 Batch  479/538 - Train Accuracy: 0.8445, Validation Accuracy: 0.8285, Loss: 0.1989
Epoch   0 Batch  480/538 - Train Accuracy: 0.8575, Validation Accuracy: 0.8482, Loss: 0.2059
Epoch   0 Batch  481/538 - Train Accuracy: 0.8653, Validation Accuracy: 0.8448, Loss: 0.2028
Epoch   0 Batch  482/538 - Train Accuracy: 0.8602, Validation Accuracy: 0.8466, Loss: 0.1834
Epoch   0 Batch  483/538 - Train Accuracy: 0.8182, Validation Accuracy: 0.8446, Loss: 0.2219
Epoch   0 Batch  484/538 - Train Accuracy: 0.8575, Validation Accuracy: 0.8450, Loss: 0.2170
Epoch   0 Batch  485/538 - Train Accuracy: 0.8744, Validation Accuracy: 0.8384, Loss: 0.1946
Epoch   0 Batch  486/538 - Train Accuracy: 0.8756, Validation Accuracy: 0.8407, Loss: 0.1819
Epoch   0 Batch  487/538 - Train Accuracy: 0.8588, Validation Accuracy: 0.8512, Loss: 0.1938
Epoch   0 Batch  488/538 - Train Accuracy: 0.8562, Validation Accuracy: 0.8503, Loss: 0.1960
Epoch   0 Batch  489/538 - Train Accuracy: 0.8453, Validation Accuracy: 0.8473, Loss: 0.2050
Epoch   0 Batch  490/538 - Train Accuracy: 0.8650, Validation Accuracy: 0.8416, Loss: 0.1896
Epoch   0 Batch  491/538 - Train Accuracy: 0.8322, Validation Accuracy: 0.8549, Loss: 0.2076
Epoch   0 Batch  492/538 - Train Accuracy: 0.8477, Validation Accuracy: 0.8700, Loss: 0.1964
Epoch   0 Batch  493/538 - Train Accuracy: 0.8590, Validation Accuracy: 0.8651, Loss: 0.1788
Epoch   0 Batch  494/538 - Train Accuracy: 0.8455, Validation Accuracy: 0.8725, Loss: 0.2062
Epoch   0 Batch  495/538 - Train Accuracy: 0.8520, Validation Accuracy: 0.8730, Loss: 0.1971
Epoch   0 Batch  496/538 - Train Accuracy: 0.8662, Validation Accuracy: 0.8720, Loss: 0.1853
Epoch   0 Batch  497/538 - Train Accuracy: 0.8767, Validation Accuracy: 0.8714, Loss: 0.1839
Epoch   0 Batch  498/538 - Train Accuracy: 0.8691, Validation Accuracy: 0.8675, Loss: 0.1895
Epoch   0 Batch  499/538 - Train Accuracy: 0.8783, Validation Accuracy: 0.8643, Loss: 0.1790
Epoch   0 Batch  500/538 - Train Accuracy: 0.8958, Validation Accuracy: 0.8612, Loss: 0.1614
Epoch   0 Batch  501/538 - Train Accuracy: 0.8895, Validation Accuracy: 0.8558, Loss: 0.1942
Epoch   0 Batch  502/538 - Train Accuracy: 0.8553, Validation Accuracy: 0.8603, Loss: 0.1826
Epoch   0 Batch  503/538 - Train Accuracy: 0.8878, Validation Accuracy: 0.8604, Loss: 0.1772
Epoch   0 Batch  504/538 - Train Accuracy: 0.8992, Validation Accuracy: 0.8654, Loss: 0.1697
Epoch   0 Batch  505/538 - Train Accuracy: 0.8730, Validation Accuracy: 0.8699, Loss: 0.1722
Epoch   0 Batch  506/538 - Train Accuracy: 0.8718, Validation Accuracy: 0.8697, Loss: 0.1717
Epoch   0 Batch  507/538 - Train Accuracy: 0.8410, Validation Accuracy: 0.8775, Loss: 0.1886
Epoch   0 Batch  508/538 - Train Accuracy: 0.8683, Validation Accuracy: 0.8764, Loss: 0.1718
Epoch   0 Batch  509/538 - Train Accuracy: 0.8623, Validation Accuracy: 0.8791, Loss: 0.1822
Epoch   0 Batch  510/538 - Train Accuracy: 0.8895, Validation Accuracy: 0.8780, Loss: 0.1680
Epoch   0 Batch  511/538 - Train Accuracy: 0.8633, Validation Accuracy: 0.8775, Loss: 0.1725
Epoch   0 Batch  512/538 - Train Accuracy: 0.8826, Validation Accuracy: 0.8775, Loss: 0.1787
Epoch   0 Batch  513/538 - Train Accuracy: 0.8424, Validation Accuracy: 0.8817, Loss: 0.1718
Epoch   0 Batch  514/538 - Train Accuracy: 0.8598, Validation Accuracy: 0.8636, Loss: 0.1762
Epoch   0 Batch  515/538 - Train Accuracy: 0.8769, Validation Accuracy: 0.8899, Loss: 0.1838
Epoch   0 Batch  516/538 - Train Accuracy: 0.8238, Validation Accuracy: 0.8793, Loss: 0.1723
Epoch   0 Batch  517/538 - Train Accuracy: 0.8906, Validation Accuracy: 0.8787, Loss: 0.1581
Epoch   0 Batch  518/538 - Train Accuracy: 0.8568, Validation Accuracy: 0.8803, Loss: 0.1820
Epoch   0 Batch  519/538 - Train Accuracy: 0.8746, Validation Accuracy: 0.8730, Loss: 0.1686
Epoch   0 Batch  520/538 - Train Accuracy: 0.8789, Validation Accuracy: 0.8796, Loss: 0.1777
Epoch   0 Batch  521/538 - Train Accuracy: 0.8715, Validation Accuracy: 0.8720, Loss: 0.1805
Epoch   0 Batch  522/538 - Train Accuracy: 0.8607, Validation Accuracy: 0.8675, Loss: 0.1587
Epoch   0 Batch  523/538 - Train Accuracy: 0.8854, Validation Accuracy: 0.8633, Loss: 0.1602
Epoch   0 Batch  524/538 - Train Accuracy: 0.8861, Validation Accuracy: 0.8755, Loss: 0.1653
Epoch   0 Batch  525/538 - Train Accuracy: 0.8778, Validation Accuracy: 0.8626, Loss: 0.1581
Epoch   0 Batch  526/538 - Train Accuracy: 0.8936, Validation Accuracy: 0.8699, Loss: 0.1593
Epoch   0 Batch  527/538 - Train Accuracy: 0.8920, Validation Accuracy: 0.8750, Loss: 0.1595
Epoch   0 Batch  528/538 - Train Accuracy: 0.8719, Validation Accuracy: 0.8752, Loss: 0.1741
Epoch   0 Batch  529/538 - Train Accuracy: 0.8545, Validation Accuracy: 0.8786, Loss: 0.1669
Epoch   0 Batch  530/538 - Train Accuracy: 0.8762, Validation Accuracy: 0.8858, Loss: 0.1645
Epoch   0 Batch  531/538 - Train Accuracy: 0.8752, Validation Accuracy: 0.8849, Loss: 0.1656
Epoch   0 Batch  532/538 - Train Accuracy: 0.8686, Validation Accuracy: 0.8805, Loss: 0.1515
Epoch   0 Batch  533/538 - Train Accuracy: 0.8820, Validation Accuracy: 0.8707, Loss: 0.1528
Epoch   0 Batch  534/538 - Train Accuracy: 0.9061, Validation Accuracy: 0.8773, Loss: 0.1433
Epoch   0 Batch  535/538 - Train Accuracy: 0.8863, Validation Accuracy: 0.8755, Loss: 0.1489
Epoch   0 Batch  536/538 - Train Accuracy: 0.9061, Validation Accuracy: 0.8745, Loss: 0.1660
Epoch   1 Batch    0/538 - Train Accuracy: 0.8865, Validation Accuracy: 0.8709, Loss: 0.1449
Epoch   1 Batch    1/538 - Train Accuracy: 0.8889, Validation Accuracy: 0.8771, Loss: 0.1557
Epoch   1 Batch    2/538 - Train Accuracy: 0.8812, Validation Accuracy: 0.8775, Loss: 0.1626
Epoch   1 Batch    3/538 - Train Accuracy: 0.8994, Validation Accuracy: 0.8755, Loss: 0.1458
Epoch   1 Batch    4/538 - Train Accuracy: 0.8879, Validation Accuracy: 0.8750, Loss: 0.1519
Epoch   1 Batch    5/538 - Train Accuracy: 0.8901, Validation Accuracy: 0.8697, Loss: 0.1507
Epoch   1 Batch    6/538 - Train Accuracy: 0.8806, Validation Accuracy: 0.8725, Loss: 0.1412
Epoch   1 Batch    7/538 - Train Accuracy: 0.9043, Validation Accuracy: 0.8727, Loss: 0.1482
Epoch   1 Batch    8/538 - Train Accuracy: 0.8896, Validation Accuracy: 0.8716, Loss: 0.1450
Epoch   1 Batch    9/538 - Train Accuracy: 0.8922, Validation Accuracy: 0.8784, Loss: 0.1380
Epoch   1 Batch   10/538 - Train Accuracy: 0.8805, Validation Accuracy: 0.8716, Loss: 0.1495
Epoch   1 Batch   11/538 - Train Accuracy: 0.8828, Validation Accuracy: 0.8679, Loss: 0.1406
Epoch   1 Batch   12/538 - Train Accuracy: 0.8934, Validation Accuracy: 0.8919, Loss: 0.1450
Epoch   1 Batch   13/538 - Train Accuracy: 0.9092, Validation Accuracy: 0.8952, Loss: 0.1345
Epoch   1 Batch   14/538 - Train Accuracy: 0.8988, Validation Accuracy: 0.8897, Loss: 0.1396
Epoch   1 Batch   15/538 - Train Accuracy: 0.8956, Validation Accuracy: 0.8919, Loss: 0.1296
Epoch   1 Batch   16/538 - Train Accuracy: 0.8858, Validation Accuracy: 0.8903, Loss: 0.1338
Epoch   1 Batch   17/538 - Train Accuracy: 0.8992, Validation Accuracy: 0.8906, Loss: 0.1323
Epoch   1 Batch   18/538 - Train Accuracy: 0.8986, Validation Accuracy: 0.8917, Loss: 0.1571
Epoch   1 Batch   19/538 - Train Accuracy: 0.8836, Validation Accuracy: 0.8817, Loss: 0.1485
Epoch   1 Batch   20/538 - Train Accuracy: 0.8717, Validation Accuracy: 0.8906, Loss: 0.1395
Epoch   1 Batch   21/538 - Train Accuracy: 0.9079, Validation Accuracy: 0.8878, Loss: 0.1296
Epoch   1 Batch   22/538 - Train Accuracy: 0.8742, Validation Accuracy: 0.8858, Loss: 0.1374
Epoch   1 Batch   23/538 - Train Accuracy: 0.8863, Validation Accuracy: 0.8839, Loss: 0.1478
Epoch   1 Batch   24/538 - Train Accuracy: 0.9079, Validation Accuracy: 0.8897, Loss: 0.1290
Epoch   1 Batch   25/538 - Train Accuracy: 0.8938, Validation Accuracy: 0.8839, Loss: 0.1337
Epoch   1 Batch   26/538 - Train Accuracy: 0.8725, Validation Accuracy: 0.8938, Loss: 0.1545
Epoch   1 Batch   27/538 - Train Accuracy: 0.9014, Validation Accuracy: 0.8920, Loss: 0.1182
Epoch   1 Batch   28/538 - Train Accuracy: 0.8887, Validation Accuracy: 0.8839, Loss: 0.1182
Epoch   1 Batch   29/538 - Train Accuracy: 0.8862, Validation Accuracy: 0.8896, Loss: 0.1242
Epoch   1 Batch   30/538 - Train Accuracy: 0.8730, Validation Accuracy: 0.8741, Loss: 0.1379
Epoch   1 Batch   31/538 - Train Accuracy: 0.9068, Validation Accuracy: 0.8864, Loss: 0.1118
Epoch   1 Batch   32/538 - Train Accuracy: 0.9141, Validation Accuracy: 0.8988, Loss: 0.1069
Epoch   1 Batch   33/538 - Train Accuracy: 0.8901, Validation Accuracy: 0.8825, Loss: 0.1295
Epoch   1 Batch   34/538 - Train Accuracy: 0.8896, Validation Accuracy: 0.8904, Loss: 0.1369
Epoch   1 Batch   35/538 - Train Accuracy: 0.9035, Validation Accuracy: 0.9061, Loss: 0.1161
Epoch   1 Batch   36/538 - Train Accuracy: 0.9029, Validation Accuracy: 0.8908, Loss: 0.1100
Epoch   1 Batch   37/538 - Train Accuracy: 0.9023, Validation Accuracy: 0.8867, Loss: 0.1258
Epoch   1 Batch   38/538 - Train Accuracy: 0.8869, Validation Accuracy: 0.8904, Loss: 0.1264
Epoch   1 Batch   39/538 - Train Accuracy: 0.9062, Validation Accuracy: 0.8913, Loss: 0.1196
Epoch   1 Batch   40/538 - Train Accuracy: 0.8899, Validation Accuracy: 0.8908, Loss: 0.1071
Epoch   1 Batch   41/538 - Train Accuracy: 0.9127, Validation Accuracy: 0.8881, Loss: 0.1166
Epoch   1 Batch   42/538 - Train Accuracy: 0.8902, Validation Accuracy: 0.8954, Loss: 0.1195
Epoch   1 Batch   43/538 - Train Accuracy: 0.8871, Validation Accuracy: 0.9050, Loss: 0.1396
Epoch   1 Batch   44/538 - Train Accuracy: 0.8855, Validation Accuracy: 0.9087, Loss: 0.1274
Epoch   1 Batch   45/538 - Train Accuracy: 0.8917, Validation Accuracy: 0.8963, Loss: 0.1214
Epoch   1 Batch   46/538 - Train Accuracy: 0.9160, Validation Accuracy: 0.9020, Loss: 0.1206
Epoch   1 Batch   47/538 - Train Accuracy: 0.9115, Validation Accuracy: 0.9045, Loss: 0.1271
Epoch   1 Batch   48/538 - Train Accuracy: 0.8888, Validation Accuracy: 0.9004, Loss: 0.1198
Epoch   1 Batch   49/538 - Train Accuracy: 0.9135, Validation Accuracy: 0.9007, Loss: 0.1203
Epoch   1 Batch   50/538 - Train Accuracy: 0.8982, Validation Accuracy: 0.8931, Loss: 0.1095
Epoch   1 Batch   51/538 - Train Accuracy: 0.8820, Validation Accuracy: 0.8890, Loss: 0.1304
Epoch   1 Batch   52/538 - Train Accuracy: 0.9082, Validation Accuracy: 0.9020, Loss: 0.1225
Epoch   1 Batch   53/538 - Train Accuracy: 0.8817, Validation Accuracy: 0.8945, Loss: 0.1152
Epoch   1 Batch   54/538 - Train Accuracy: 0.9182, Validation Accuracy: 0.8862, Loss: 0.1061
Epoch   1 Batch   55/538 - Train Accuracy: 0.8814, Validation Accuracy: 0.8851, Loss: 0.1201
Epoch   1 Batch   56/538 - Train Accuracy: 0.9049, Validation Accuracy: 0.8983, Loss: 0.1060
Epoch   1 Batch   57/538 - Train Accuracy: 0.8801, Validation Accuracy: 0.8968, Loss: 0.1184
Epoch   1 Batch   58/538 - Train Accuracy: 0.8879, Validation Accuracy: 0.9018, Loss: 0.1121
Epoch   1 Batch   59/538 - Train Accuracy: 0.9070, Validation Accuracy: 0.9077, Loss: 0.1166
Epoch   1 Batch   60/538 - Train Accuracy: 0.9080, Validation Accuracy: 0.9084, Loss: 0.1170
Epoch   1 Batch   61/538 - Train Accuracy: 0.9229, Validation Accuracy: 0.9009, Loss: 0.1044
Epoch   1 Batch   62/538 - Train Accuracy: 0.9129, Validation Accuracy: 0.9078, Loss: 0.1088
Epoch   1 Batch   63/538 - Train Accuracy: 0.9191, Validation Accuracy: 0.9158, Loss: 0.1089
Epoch   1 Batch   64/538 - Train Accuracy: 0.9089, Validation Accuracy: 0.9102, Loss: 0.1087
Epoch   1 Batch   65/538 - Train Accuracy: 0.8996, Validation Accuracy: 0.9080, Loss: 0.1152
Epoch   1 Batch   66/538 - Train Accuracy: 0.9200, Validation Accuracy: 0.9077, Loss: 0.0987
Epoch   1 Batch   67/538 - Train Accuracy: 0.9170, Validation Accuracy: 0.9048, Loss: 0.1119
Epoch   1 Batch   68/538 - Train Accuracy: 0.9221, Validation Accuracy: 0.8961, Loss: 0.0932
Epoch   1 Batch   69/538 - Train Accuracy: 0.9172, Validation Accuracy: 0.8912, Loss: 0.1054
Epoch   1 Batch   70/538 - Train Accuracy: 0.9103, Validation Accuracy: 0.8920, Loss: 0.1030
Epoch   1 Batch   71/538 - Train Accuracy: 0.8857, Validation Accuracy: 0.8961, Loss: 0.1238
Epoch   1 Batch   72/538 - Train Accuracy: 0.9036, Validation Accuracy: 0.8913, Loss: 0.1128
Epoch   1 Batch   73/538 - Train Accuracy: 0.8945, Validation Accuracy: 0.8949, Loss: 0.1081
Epoch   1 Batch   74/538 - Train Accuracy: 0.9250, Validation Accuracy: 0.9071, Loss: 0.1004
Epoch   1 Batch   75/538 - Train Accuracy: 0.9085, Validation Accuracy: 0.9034, Loss: 0.1031
Epoch   1 Batch   76/538 - Train Accuracy: 0.8939, Validation Accuracy: 0.9114, Loss: 0.1071
Epoch   1 Batch   77/538 - Train Accuracy: 0.9088, Validation Accuracy: 0.9041, Loss: 0.0967
Epoch   1 Batch   78/538 - Train Accuracy: 0.9036, Validation Accuracy: 0.9068, Loss: 0.1057
Epoch   1 Batch   79/538 - Train Accuracy: 0.9172, Validation Accuracy: 0.9011, Loss: 0.0895
Epoch   1 Batch   80/538 - Train Accuracy: 0.9148, Validation Accuracy: 0.9022, Loss: 0.1074
Epoch   1 Batch   81/538 - Train Accuracy: 0.8900, Validation Accuracy: 0.9039, Loss: 0.1022
Epoch   1 Batch   82/538 - Train Accuracy: 0.8914, Validation Accuracy: 0.9041, Loss: 0.1003
Epoch   1 Batch   83/538 - Train Accuracy: 0.8941, Validation Accuracy: 0.9142, Loss: 0.1025
Epoch   1 Batch   84/538 - Train Accuracy: 0.9068, Validation Accuracy: 0.9050, Loss: 0.1003
Epoch   1 Batch   85/538 - Train Accuracy: 0.9167, Validation Accuracy: 0.9155, Loss: 0.0884
Epoch   1 Batch   86/538 - Train Accuracy: 0.9186, Validation Accuracy: 0.9038, Loss: 0.0976
Epoch   1 Batch   87/538 - Train Accuracy: 0.9193, Validation Accuracy: 0.9173, Loss: 0.0981
Epoch   1 Batch   88/538 - Train Accuracy: 0.9096, Validation Accuracy: 0.9173, Loss: 0.1013
Epoch   1 Batch   89/538 - Train Accuracy: 0.9150, Validation Accuracy: 0.9103, Loss: 0.0933
Epoch   1 Batch   90/538 - Train Accuracy: 0.9209, Validation Accuracy: 0.9121, Loss: 0.1131
Epoch   1 Batch   91/538 - Train Accuracy: 0.9186, Validation Accuracy: 0.9167, Loss: 0.0936
Epoch   1 Batch   92/538 - Train Accuracy: 0.9287, Validation Accuracy: 0.9203, Loss: 0.0960
Epoch   1 Batch   93/538 - Train Accuracy: 0.9090, Validation Accuracy: 0.9118, Loss: 0.0898
Epoch   1 Batch   94/538 - Train Accuracy: 0.9154, Validation Accuracy: 0.9128, Loss: 0.0897
Epoch   1 Batch   95/538 - Train Accuracy: 0.9196, Validation Accuracy: 0.9075, Loss: 0.0921
Epoch   1 Batch   96/538 - Train Accuracy: 0.9308, Validation Accuracy: 0.9118, Loss: 0.0802
Epoch   1 Batch   97/538 - Train Accuracy: 0.9254, Validation Accuracy: 0.9031, Loss: 0.0860
Epoch   1 Batch   98/538 - Train Accuracy: 0.9265, Validation Accuracy: 0.9135, Loss: 0.1001
Epoch   1 Batch   99/538 - Train Accuracy: 0.9127, Validation Accuracy: 0.9137, Loss: 0.0946
Epoch   1 Batch  100/538 - Train Accuracy: 0.9187, Validation Accuracy: 0.9105, Loss: 0.0857
Epoch   1 Batch  101/538 - Train Accuracy: 0.9059, Validation Accuracy: 0.9068, Loss: 0.1011
Epoch   1 Batch  102/538 - Train Accuracy: 0.8973, Validation Accuracy: 0.9118, Loss: 0.1029
Epoch   1 Batch  103/538 - Train Accuracy: 0.9267, Validation Accuracy: 0.9078, Loss: 0.0911
Epoch   1 Batch  104/538 - Train Accuracy: 0.9115, Validation Accuracy: 0.9066, Loss: 0.0864
Epoch   1 Batch  105/538 - Train Accuracy: 0.9167, Validation Accuracy: 0.9128, Loss: 0.0838
Epoch   1 Batch  106/538 - Train Accuracy: 0.8957, Validation Accuracy: 0.9151, Loss: 0.0864
Epoch   1 Batch  107/538 - Train Accuracy: 0.8971, Validation Accuracy: 0.9222, Loss: 0.1033
Epoch   1 Batch  108/538 - Train Accuracy: 0.9313, Validation Accuracy: 0.9245, Loss: 0.0952
Epoch   1 Batch  109/538 - Train Accuracy: 0.9256, Validation Accuracy: 0.9105, Loss: 0.0879
Epoch   1 Batch  110/538 - Train Accuracy: 0.9072, Validation Accuracy: 0.9068, Loss: 0.0920
Epoch   1 Batch  111/538 - Train Accuracy: 0.9167, Validation Accuracy: 0.9112, Loss: 0.0841
Epoch   1 Batch  112/538 - Train Accuracy: 0.9180, Validation Accuracy: 0.9116, Loss: 0.0932
Epoch   1 Batch  113/538 - Train Accuracy: 0.8988, Validation Accuracy: 0.9112, Loss: 0.0998
Epoch   1 Batch  114/538 - Train Accuracy: 0.9189, Validation Accuracy: 0.9132, Loss: 0.0932
Epoch   1 Batch  115/538 - Train Accuracy: 0.9313, Validation Accuracy: 0.9192, Loss: 0.0903
Epoch   1 Batch  116/538 - Train Accuracy: 0.9083, Validation Accuracy: 0.9070, Loss: 0.1036
Epoch   1 Batch  117/538 - Train Accuracy: 0.8884, Validation Accuracy: 0.9064, Loss: 0.0989
Epoch   1 Batch  118/538 - Train Accuracy: 0.9156, Validation Accuracy: 0.9173, Loss: 0.0815
Epoch   1 Batch  119/538 - Train Accuracy: 0.9379, Validation Accuracy: 0.9150, Loss: 0.0741
Epoch   1 Batch  120/538 - Train Accuracy: 0.9174, Validation Accuracy: 0.9082, Loss: 0.0733
Epoch   1 Batch  121/538 - Train Accuracy: 0.9235, Validation Accuracy: 0.9075, Loss: 0.0821
Epoch   1 Batch  122/538 - Train Accuracy: 0.9170, Validation Accuracy: 0.9183, Loss: 0.0793
Epoch   1 Batch  123/538 - Train Accuracy: 0.9079, Validation Accuracy: 0.9173, Loss: 0.0805
Epoch   1 Batch  124/538 - Train Accuracy: 0.9309, Validation Accuracy: 0.9160, Loss: 0.0800
Epoch   1 Batch  125/538 - Train Accuracy: 0.9167, Validation Accuracy: 0.9238, Loss: 0.0829
Epoch   1 Batch  126/538 - Train Accuracy: 0.8936, Validation Accuracy: 0.9265, Loss: 0.0917
Epoch   1 Batch  127/538 - Train Accuracy: 0.9127, Validation Accuracy: 0.9206, Loss: 0.0987
Epoch   1 Batch  128/538 - Train Accuracy: 0.9200, Validation Accuracy: 0.9247, Loss: 0.0878
Epoch   1 Batch  129/538 - Train Accuracy: 0.9351, Validation Accuracy: 0.9290, Loss: 0.0725
Epoch   1 Batch  130/538 - Train Accuracy: 0.9319, Validation Accuracy: 0.9324, Loss: 0.0784
Epoch   1 Batch  131/538 - Train Accuracy: 0.9424, Validation Accuracy: 0.9292, Loss: 0.0791
Epoch   1 Batch  132/538 - Train Accuracy: 0.9070, Validation Accuracy: 0.9221, Loss: 0.0818
Epoch   1 Batch  133/538 - Train Accuracy: 0.9109, Validation Accuracy: 0.9137, Loss: 0.0807
Epoch   1 Batch  134/538 - Train Accuracy: 0.9105, Validation Accuracy: 0.9157, Loss: 0.0911
Epoch   1 Batch  135/538 - Train Accuracy: 0.9247, Validation Accuracy: 0.9089, Loss: 0.0952
Epoch   1 Batch  136/538 - Train Accuracy: 0.9115, Validation Accuracy: 0.9032, Loss: 0.0778
Epoch   1 Batch  137/538 - Train Accuracy: 0.9200, Validation Accuracy: 0.9004, Loss: 0.0921
Epoch   1 Batch  138/538 - Train Accuracy: 0.9196, Validation Accuracy: 0.9087, Loss: 0.0834
Epoch   1 Batch  139/538 - Train Accuracy: 0.9209, Validation Accuracy: 0.9199, Loss: 0.0882
Epoch   1 Batch  140/538 - Train Accuracy: 0.9072, Validation Accuracy: 0.9196, Loss: 0.0913
Epoch   1 Batch  141/538 - Train Accuracy: 0.9287, Validation Accuracy: 0.9228, Loss: 0.0888
Epoch   1 Batch  142/538 - Train Accuracy: 0.9271, Validation Accuracy: 0.9229, Loss: 0.0812
Epoch   1 Batch  143/538 - Train Accuracy: 0.9191, Validation Accuracy: 0.9265, Loss: 0.0878
Epoch   1 Batch  144/538 - Train Accuracy: 0.9203, Validation Accuracy: 0.9292, Loss: 0.0884
Epoch   1 Batch  145/538 - Train Accuracy: 0.9055, Validation Accuracy: 0.9341, Loss: 0.0951
Epoch   1 Batch  146/538 - Train Accuracy: 0.9320, Validation Accuracy: 0.9274, Loss: 0.0785
Epoch   1 Batch  147/538 - Train Accuracy: 0.9221, Validation Accuracy: 0.9233, Loss: 0.0783
Epoch   1 Batch  148/538 - Train Accuracy: 0.9076, Validation Accuracy: 0.9212, Loss: 0.0928
Epoch   1 Batch  149/538 - Train Accuracy: 0.9207, Validation Accuracy: 0.9146, Loss: 0.0783
Epoch   1 Batch  150/538 - Train Accuracy: 0.9283, Validation Accuracy: 0.9190, Loss: 0.0748
Epoch   1 Batch  151/538 - Train Accuracy: 0.9356, Validation Accuracy: 0.9267, Loss: 0.0813
Epoch   1 Batch  152/538 - Train Accuracy: 0.9247, Validation Accuracy: 0.9270, Loss: 0.0767
Epoch   1 Batch  153/538 - Train Accuracy: 0.8981, Validation Accuracy: 0.9284, Loss: 0.0801
Epoch   1 Batch  154/538 - Train Accuracy: 0.9474, Validation Accuracy: 0.9222, Loss: 0.0682
Epoch   1 Batch  155/538 - Train Accuracy: 0.9124, Validation Accuracy: 0.9292, Loss: 0.0803
Epoch   1 Batch  156/538 - Train Accuracy: 0.9477, Validation Accuracy: 0.9256, Loss: 0.0688
Epoch   1 Batch  157/538 - Train Accuracy: 0.9353, Validation Accuracy: 0.9206, Loss: 0.0713
Epoch   1 Batch  158/538 - Train Accuracy: 0.9387, Validation Accuracy: 0.9174, Loss: 0.0822
Epoch   1 Batch  159/538 - Train Accuracy: 0.9363, Validation Accuracy: 0.9173, Loss: 0.0782
Epoch   1 Batch  160/538 - Train Accuracy: 0.9036, Validation Accuracy: 0.9233, Loss: 0.0700
Epoch   1 Batch  161/538 - Train Accuracy: 0.9402, Validation Accuracy: 0.9112, Loss: 0.0705
Epoch   1 Batch  162/538 - Train Accuracy: 0.9291, Validation Accuracy: 0.9221, Loss: 0.0741
Epoch   1 Batch  163/538 - Train Accuracy: 0.9089, Validation Accuracy: 0.9254, Loss: 0.0844
Epoch   1 Batch  164/538 - Train Accuracy: 0.9168, Validation Accuracy: 0.9308, Loss: 0.0770
Epoch   1 Batch  165/538 - Train Accuracy: 0.9265, Validation Accuracy: 0.9180, Loss: 0.0663
Epoch   1 Batch  166/538 - Train Accuracy: 0.9400, Validation Accuracy: 0.9146, Loss: 0.0726
Epoch   1 Batch  167/538 - Train Accuracy: 0.9228, Validation Accuracy: 0.9197, Loss: 0.0796
Epoch   1 Batch  168/538 - Train Accuracy: 0.9090, Validation Accuracy: 0.9178, Loss: 0.0842
Epoch   1 Batch  169/538 - Train Accuracy: 0.9309, Validation Accuracy: 0.9208, Loss: 0.0679
Epoch   1 Batch  170/538 - Train Accuracy: 0.9193, Validation Accuracy: 0.9229, Loss: 0.0753
Epoch   1 Batch  171/538 - Train Accuracy: 0.9318, Validation Accuracy: 0.9293, Loss: 0.0713
Epoch   1 Batch  172/538 - Train Accuracy: 0.9299, Validation Accuracy: 0.9292, Loss: 0.0698
Epoch   1 Batch  173/538 - Train Accuracy: 0.9416, Validation Accuracy: 0.9219, Loss: 0.0652
Epoch   1 Batch  174/538 - Train Accuracy: 0.9254, Validation Accuracy: 0.9197, Loss: 0.0726
Epoch   1 Batch  175/538 - Train Accuracy: 0.9092, Validation Accuracy: 0.9160, Loss: 0.0703
Epoch   1 Batch  176/538 - Train Accuracy: 0.9062, Validation Accuracy: 0.9165, Loss: 0.0762
Epoch   1 Batch  177/538 - Train Accuracy: 0.9394, Validation Accuracy: 0.9093, Loss: 0.0703
Epoch   1 Batch  178/538 - Train Accuracy: 0.9051, Validation Accuracy: 0.9068, Loss: 0.0724
Epoch   1 Batch  179/538 - Train Accuracy: 0.9291, Validation Accuracy: 0.9151, Loss: 0.0705
Epoch   1 Batch  180/538 - Train Accuracy: 0.9343, Validation Accuracy: 0.9121, Loss: 0.0702
Epoch   1 Batch  181/538 - Train Accuracy: 0.9150, Validation Accuracy: 0.9157, Loss: 0.0782
Epoch   1 Batch  182/538 - Train Accuracy: 0.9381, Validation Accuracy: 0.9123, Loss: 0.0654
Epoch   1 Batch  183/538 - Train Accuracy: 0.9535, Validation Accuracy: 0.9151, Loss: 0.0622
Epoch   1 Batch  184/538 - Train Accuracy: 0.9336, Validation Accuracy: 0.9208, Loss: 0.0671
Epoch   1 Batch  185/538 - Train Accuracy: 0.9459, Validation Accuracy: 0.9217, Loss: 0.0602
Epoch   1 Batch  186/538 - Train Accuracy: 0.9314, Validation Accuracy: 0.9306, Loss: 0.0694
Epoch   1 Batch  187/538 - Train Accuracy: 0.9418, Validation Accuracy: 0.9375, Loss: 0.0695
Epoch   1 Batch  188/538 - Train Accuracy: 0.9297, Validation Accuracy: 0.9380, Loss: 0.0635
Epoch   1 Batch  189/538 - Train Accuracy: 0.9375, Validation Accuracy: 0.9308, Loss: 0.0693
Epoch   1 Batch  190/538 - Train Accuracy: 0.9135, Validation Accuracy: 0.9311, Loss: 0.0854
Epoch   1 Batch  191/538 - Train Accuracy: 0.9377, Validation Accuracy: 0.9316, Loss: 0.0641
Epoch   1 Batch  192/538 - Train Accuracy: 0.9416, Validation Accuracy: 0.9341, Loss: 0.0633
Epoch   1 Batch  193/538 - Train Accuracy: 0.9312, Validation Accuracy: 0.9384, Loss: 0.0665
Epoch   1 Batch  194/538 - Train Accuracy: 0.9080, Validation Accuracy: 0.9386, Loss: 0.0749
Epoch   1 Batch  195/538 - Train Accuracy: 0.9362, Validation Accuracy: 0.9327, Loss: 0.0733
Epoch   1 Batch  196/538 - Train Accuracy: 0.9213, Validation Accuracy: 0.9324, Loss: 0.0655
Epoch   1 Batch  197/538 - Train Accuracy: 0.9252, Validation Accuracy: 0.9272, Loss: 0.0666
Epoch   1 Batch  198/538 - Train Accuracy: 0.9403, Validation Accuracy: 0.9295, Loss: 0.0659
Epoch   1 Batch  199/538 - Train Accuracy: 0.9182, Validation Accuracy: 0.9263, Loss: 0.0685
Epoch   1 Batch  200/538 - Train Accuracy: 0.9277, Validation Accuracy: 0.9318, Loss: 0.0579
Epoch   1 Batch  201/538 - Train Accuracy: 0.9224, Validation Accuracy: 0.9300, Loss: 0.0714
Epoch   1 Batch  202/538 - Train Accuracy: 0.9457, Validation Accuracy: 0.9189, Loss: 0.0646
Epoch   1 Batch  203/538 - Train Accuracy: 0.9336, Validation Accuracy: 0.9279, Loss: 0.0730
Epoch   1 Batch  204/538 - Train Accuracy: 0.9182, Validation Accuracy: 0.9196, Loss: 0.0756
Epoch   1 Batch  205/538 - Train Accuracy: 0.9461, Validation Accuracy: 0.9260, Loss: 0.0598
Epoch   1 Batch  206/538 - Train Accuracy: 0.9285, Validation Accuracy: 0.9338, Loss: 0.0604
Epoch   1 Batch  207/538 - Train Accuracy: 0.9405, Validation Accuracy: 0.9361, Loss: 0.0661
Epoch   1 Batch  208/538 - Train Accuracy: 0.9291, Validation Accuracy: 0.9419, Loss: 0.0773
Epoch   1 Batch  209/538 - Train Accuracy: 0.9537, Validation Accuracy: 0.9350, Loss: 0.0571
Epoch   1 Batch  210/538 - Train Accuracy: 0.9102, Validation Accuracy: 0.9405, Loss: 0.0693
Epoch   1 Batch  211/538 - Train Accuracy: 0.9129, Validation Accuracy: 0.9379, Loss: 0.0713
Epoch   1 Batch  212/538 - Train Accuracy: 0.9263, Validation Accuracy: 0.9361, Loss: 0.0609
Epoch   1 Batch  213/538 - Train Accuracy: 0.9435, Validation Accuracy: 0.9373, Loss: 0.0571
Epoch   1 Batch  214/538 - Train Accuracy: 0.9383, Validation Accuracy: 0.9446, Loss: 0.0594
Epoch   1 Batch  215/538 - Train Accuracy: 0.9385, Validation Accuracy: 0.9384, Loss: 0.0610
Epoch   1 Batch  216/538 - Train Accuracy: 0.9559, Validation Accuracy: 0.9389, Loss: 0.0658
Epoch   1 Batch  217/538 - Train Accuracy: 0.9410, Validation Accuracy: 0.9444, Loss: 0.0670
Epoch   1 Batch  218/538 - Train Accuracy: 0.9410, Validation Accuracy: 0.9300, Loss: 0.0554
Epoch   1 Batch  219/538 - Train Accuracy: 0.9211, Validation Accuracy: 0.9300, Loss: 0.0709
Epoch   1 Batch  220/538 - Train Accuracy: 0.9178, Validation Accuracy: 0.9313, Loss: 0.0643
Epoch   1 Batch  221/538 - Train Accuracy: 0.9578, Validation Accuracy: 0.9226, Loss: 0.0563
Epoch   1 Batch  222/538 - Train Accuracy: 0.9144, Validation Accuracy: 0.9114, Loss: 0.0600
Epoch   1 Batch  223/538 - Train Accuracy: 0.9205, Validation Accuracy: 0.9089, Loss: 0.0749
Epoch   1 Batch  224/538 - Train Accuracy: 0.9230, Validation Accuracy: 0.9084, Loss: 0.0676
Epoch   1 Batch  225/538 - Train Accuracy: 0.9403, Validation Accuracy: 0.9171, Loss: 0.0620
Epoch   1 Batch  226/538 - Train Accuracy: 0.9310, Validation Accuracy: 0.9201, Loss: 0.0632
Epoch   1 Batch  227/538 - Train Accuracy: 0.9398, Validation Accuracy: 0.9171, Loss: 0.0600
Epoch   1 Batch  228/538 - Train Accuracy: 0.9263, Validation Accuracy: 0.9252, Loss: 0.0630
Epoch   1 Batch  229/538 - Train Accuracy: 0.9254, Validation Accuracy: 0.9252, Loss: 0.0663
Epoch   1 Batch  230/538 - Train Accuracy: 0.9348, Validation Accuracy: 0.9341, Loss: 0.0619
Epoch   1 Batch  231/538 - Train Accuracy: 0.9234, Validation Accuracy: 0.9290, Loss: 0.0599
Epoch   1 Batch  232/538 - Train Accuracy: 0.9369, Validation Accuracy: 0.9267, Loss: 0.0564
Epoch   1 Batch  233/538 - Train Accuracy: 0.9485, Validation Accuracy: 0.9206, Loss: 0.0640
Epoch   1 Batch  234/538 - Train Accuracy: 0.9449, Validation Accuracy: 0.9158, Loss: 0.0556
Epoch   1 Batch  235/538 - Train Accuracy: 0.9462, Validation Accuracy: 0.9194, Loss: 0.0524
Epoch   1 Batch  236/538 - Train Accuracy: 0.9369, Validation Accuracy: 0.9237, Loss: 0.0580
Epoch   1 Batch  237/538 - Train Accuracy: 0.9295, Validation Accuracy: 0.9313, Loss: 0.0505
Epoch   1 Batch  238/538 - Train Accuracy: 0.9440, Validation Accuracy: 0.9261, Loss: 0.0534
Epoch   1 Batch  239/538 - Train Accuracy: 0.9258, Validation Accuracy: 0.9364, Loss: 0.0628
Epoch   1 Batch  240/538 - Train Accuracy: 0.9412, Validation Accuracy: 0.9308, Loss: 0.0624
Epoch   1 Batch  241/538 - Train Accuracy: 0.9125, Validation Accuracy: 0.9261, Loss: 0.0638
Epoch   1 Batch  242/538 - Train Accuracy: 0.9498, Validation Accuracy: 0.9238, Loss: 0.0554
Epoch   1 Batch  243/538 - Train Accuracy: 0.9505, Validation Accuracy: 0.9215, Loss: 0.0556
Epoch   1 Batch  244/538 - Train Accuracy: 0.9276, Validation Accuracy: 0.9231, Loss: 0.0523
Epoch   1 Batch  245/538 - Train Accuracy: 0.9424, Validation Accuracy: 0.9247, Loss: 0.0699
Epoch   1 Batch  246/538 - Train Accuracy: 0.9172, Validation Accuracy: 0.9299, Loss: 0.0493
Epoch   1 Batch  247/538 - Train Accuracy: 0.9318, Validation Accuracy: 0.9315, Loss: 0.0559
Epoch   1 Batch  248/538 - Train Accuracy: 0.9268, Validation Accuracy: 0.9288, Loss: 0.0596
Epoch   1 Batch  249/538 - Train Accuracy: 0.9323, Validation Accuracy: 0.9379, Loss: 0.0501
Epoch   1 Batch  250/538 - Train Accuracy: 0.9383, Validation Accuracy: 0.9409, Loss: 0.0549
Epoch   1 Batch  251/538 - Train Accuracy: 0.9330, Validation Accuracy: 0.9309, Loss: 0.0538
Epoch   1 Batch  252/538 - Train Accuracy: 0.9414, Validation Accuracy: 0.9286, Loss: 0.0539
Epoch   1 Batch  253/538 - Train Accuracy: 0.9053, Validation Accuracy: 0.9267, Loss: 0.0583
Epoch   1 Batch  254/538 - Train Accuracy: 0.9107, Validation Accuracy: 0.9339, Loss: 0.0609
Epoch   1 Batch  255/538 - Train Accuracy: 0.9568, Validation Accuracy: 0.9366, Loss: 0.0527
Epoch   1 Batch  256/538 - Train Accuracy: 0.9219, Validation Accuracy: 0.9352, Loss: 0.0601
Epoch   1 Batch  257/538 - Train Accuracy: 0.9546, Validation Accuracy: 0.9313, Loss: 0.0550
Epoch   1 Batch  258/538 - Train Accuracy: 0.9394, Validation Accuracy: 0.9281, Loss: 0.0573
Epoch   1 Batch  259/538 - Train Accuracy: 0.9602, Validation Accuracy: 0.9071, Loss: 0.0496
Epoch   1 Batch  260/538 - Train Accuracy: 0.9167, Validation Accuracy: 0.9237, Loss: 0.0607
Epoch   1 Batch  261/538 - Train Accuracy: 0.9365, Validation Accuracy: 0.9288, Loss: 0.0650
Epoch   1 Batch  262/538 - Train Accuracy: 0.9500, Validation Accuracy: 0.9267, Loss: 0.0583
Epoch   1 Batch  263/538 - Train Accuracy: 0.9156, Validation Accuracy: 0.9256, Loss: 0.0604
Epoch   1 Batch  264/538 - Train Accuracy: 0.9242, Validation Accuracy: 0.9261, Loss: 0.0575
Epoch   1 Batch  265/538 - Train Accuracy: 0.9340, Validation Accuracy: 0.9231, Loss: 0.0643
Epoch   1 Batch  266/538 - Train Accuracy: 0.9208, Validation Accuracy: 0.9274, Loss: 0.0598
Epoch   1 Batch  267/538 - Train Accuracy: 0.9326, Validation Accuracy: 0.9268, Loss: 0.0558
Epoch   1 Batch  268/538 - Train Accuracy: 0.9576, Validation Accuracy: 0.9384, Loss: 0.0434
Epoch   1 Batch  269/538 - Train Accuracy: 0.9371, Validation Accuracy: 0.9364, Loss: 0.0607
Epoch   1 Batch  270/538 - Train Accuracy: 0.9240, Validation Accuracy: 0.9261, Loss: 0.0527
Epoch   1 Batch  271/538 - Train Accuracy: 0.9453, Validation Accuracy: 0.9318, Loss: 0.0469
Epoch   1 Batch  272/538 - Train Accuracy: 0.9270, Validation Accuracy: 0.9295, Loss: 0.0629
Epoch   1 Batch  273/538 - Train Accuracy: 0.9197, Validation Accuracy: 0.9339, Loss: 0.0597
Epoch   1 Batch  274/538 - Train Accuracy: 0.9068, Validation Accuracy: 0.9347, Loss: 0.0623
Epoch   1 Batch  275/538 - Train Accuracy: 0.9191, Validation Accuracy: 0.9290, Loss: 0.0615
Epoch   1 Batch  276/538 - Train Accuracy: 0.9123, Validation Accuracy: 0.9315, Loss: 0.0629
Epoch   1 Batch  277/538 - Train Accuracy: 0.9400, Validation Accuracy: 0.9332, Loss: 0.0489
Epoch   1 Batch  278/538 - Train Accuracy: 0.9355, Validation Accuracy: 0.9336, Loss: 0.0483
Epoch   1 Batch  279/538 - Train Accuracy: 0.9359, Validation Accuracy: 0.9331, Loss: 0.0523
Epoch   1 Batch  280/538 - Train Accuracy: 0.9425, Validation Accuracy: 0.9306, Loss: 0.0453
Epoch   1 Batch  281/538 - Train Accuracy: 0.9359, Validation Accuracy: 0.9304, Loss: 0.0592
Epoch   1 Batch  282/538 - Train Accuracy: 0.9375, Validation Accuracy: 0.9160, Loss: 0.0607
Epoch   1 Batch  283/538 - Train Accuracy: 0.9285, Validation Accuracy: 0.9205, Loss: 0.0520
Epoch   1 Batch  284/538 - Train Accuracy: 0.9391, Validation Accuracy: 0.9245, Loss: 0.0585
Epoch   1 Batch  285/538 - Train Accuracy: 0.9403, Validation Accuracy: 0.9274, Loss: 0.0467
Epoch   1 Batch  286/538 - Train Accuracy: 0.9334, Validation Accuracy: 0.9304, Loss: 0.0580
Epoch   1 Batch  287/538 - Train Accuracy: 0.9596, Validation Accuracy: 0.9308, Loss: 0.0427
Epoch   1 Batch  288/538 - Train Accuracy: 0.9371, Validation Accuracy: 0.9272, Loss: 0.0540
Epoch   1 Batch  289/538 - Train Accuracy: 0.9401, Validation Accuracy: 0.9348, Loss: 0.0453
Epoch   1 Batch  290/538 - Train Accuracy: 0.9576, Validation Accuracy: 0.9382, Loss: 0.0445
Epoch   1 Batch  291/538 - Train Accuracy: 0.9511, Validation Accuracy: 0.9352, Loss: 0.0539
Epoch   1 Batch  292/538 - Train Accuracy: 0.9544, Validation Accuracy: 0.9371, Loss: 0.0425
Epoch   1 Batch  293/538 - Train Accuracy: 0.9384, Validation Accuracy: 0.9329, Loss: 0.0526
Epoch   1 Batch  294/538 - Train Accuracy: 0.9297, Validation Accuracy: 0.9345, Loss: 0.0579
Epoch   1 Batch  295/538 - Train Accuracy: 0.9476, Validation Accuracy: 0.9371, Loss: 0.0518
Epoch   1 Batch  296/538 - Train Accuracy: 0.9345, Validation Accuracy: 0.9373, Loss: 0.0635
Epoch   1 Batch  297/538 - Train Accuracy: 0.9449, Validation Accuracy: 0.9325, Loss: 0.0493
Epoch   1 Batch  298/538 - Train Accuracy: 0.9282, Validation Accuracy: 0.9382, Loss: 0.0512
Epoch   1 Batch  299/538 - Train Accuracy: 0.9349, Validation Accuracy: 0.9387, Loss: 0.0626
Epoch   1 Batch  300/538 - Train Accuracy: 0.9368, Validation Accuracy: 0.9384, Loss: 0.0532
Epoch   1 Batch  301/538 - Train Accuracy: 0.9340, Validation Accuracy: 0.9407, Loss: 0.0523
Epoch   1 Batch  302/538 - Train Accuracy: 0.9356, Validation Accuracy: 0.9450, Loss: 0.0512
Epoch   1 Batch  303/538 - Train Accuracy: 0.9476, Validation Accuracy: 0.9521, Loss: 0.0494
Epoch   1 Batch  304/538 - Train Accuracy: 0.9340, Validation Accuracy: 0.9437, Loss: 0.0537
Epoch   1 Batch  305/538 - Train Accuracy: 0.9462, Validation Accuracy: 0.9423, Loss: 0.0470
Epoch   1 Batch  306/538 - Train Accuracy: 0.9325, Validation Accuracy: 0.9432, Loss: 0.0572
Epoch   1 Batch  307/538 - Train Accuracy: 0.9639, Validation Accuracy: 0.9467, Loss: 0.0460
Epoch   1 Batch  308/538 - Train Accuracy: 0.9477, Validation Accuracy: 0.9513, Loss: 0.0478
Epoch   1 Batch  309/538 - Train Accuracy: 0.9439, Validation Accuracy: 0.9537, Loss: 0.0447
Epoch   1 Batch  310/538 - Train Accuracy: 0.9471, Validation Accuracy: 0.9529, Loss: 0.0601
Epoch   1 Batch  311/538 - Train Accuracy: 0.9254, Validation Accuracy: 0.9506, Loss: 0.0534
Epoch   1 Batch  312/538 - Train Accuracy: 0.9451, Validation Accuracy: 0.9444, Loss: 0.0434
Epoch   1 Batch  313/538 - Train Accuracy: 0.9533, Validation Accuracy: 0.9462, Loss: 0.0514
Epoch   1 Batch  314/538 - Train Accuracy: 0.9486, Validation Accuracy: 0.9494, Loss: 0.0529
Epoch   1 Batch  315/538 - Train Accuracy: 0.9369, Validation Accuracy: 0.9510, Loss: 0.0473
Epoch   1 Batch  316/538 - Train Accuracy: 0.9507, Validation Accuracy: 0.9545, Loss: 0.0421
Epoch   1 Batch  317/538 - Train Accuracy: 0.9375, Validation Accuracy: 0.9535, Loss: 0.0544
Epoch   1 Batch  318/538 - Train Accuracy: 0.9349, Validation Accuracy: 0.9458, Loss: 0.0471
Epoch   1 Batch  319/538 - Train Accuracy: 0.9488, Validation Accuracy: 0.9414, Loss: 0.0551
Epoch   1 Batch  320/538 - Train Accuracy: 0.9349, Validation Accuracy: 0.9419, Loss: 0.0458
Epoch   1 Batch  321/538 - Train Accuracy: 0.9386, Validation Accuracy: 0.9320, Loss: 0.0445
Epoch   1 Batch  322/538 - Train Accuracy: 0.9211, Validation Accuracy: 0.9412, Loss: 0.0538
Epoch   1 Batch  323/538 - Train Accuracy: 0.9528, Validation Accuracy: 0.9526, Loss: 0.0433
Epoch   1 Batch  324/538 - Train Accuracy: 0.9553, Validation Accuracy: 0.9505, Loss: 0.0494
Epoch   1 Batch  325/538 - Train Accuracy: 0.9355, Validation Accuracy: 0.9398, Loss: 0.0481
Epoch   1 Batch  326/538 - Train Accuracy: 0.9592, Validation Accuracy: 0.9545, Loss: 0.0485
Epoch   1 Batch  327/538 - Train Accuracy: 0.9338, Validation Accuracy: 0.9526, Loss: 0.0539
Epoch   1 Batch  328/538 - Train Accuracy: 0.9537, Validation Accuracy: 0.9379, Loss: 0.0418
Epoch   1 Batch  329/538 - Train Accuracy: 0.9518, Validation Accuracy: 0.9364, Loss: 0.0497
Epoch   1 Batch  330/538 - Train Accuracy: 0.9608, Validation Accuracy: 0.9441, Loss: 0.0446
Epoch   1 Batch  331/538 - Train Accuracy: 0.9463, Validation Accuracy: 0.9283, Loss: 0.0470
Epoch   1 Batch  332/538 - Train Accuracy: 0.9379, Validation Accuracy: 0.9334, Loss: 0.0481
Epoch   1 Batch  333/538 - Train Accuracy: 0.9440, Validation Accuracy: 0.9421, Loss: 0.0529
Epoch   1 Batch  334/538 - Train Accuracy: 0.9487, Validation Accuracy: 0.9570, Loss: 0.0463
Epoch   1 Batch  335/538 - Train Accuracy: 0.9533, Validation Accuracy: 0.9458, Loss: 0.0471
Epoch   1 Batch  336/538 - Train Accuracy: 0.9356, Validation Accuracy: 0.9393, Loss: 0.0506
Epoch   1 Batch  337/538 - Train Accuracy: 0.9351, Validation Accuracy: 0.9464, Loss: 0.0473
Epoch   1 Batch  338/538 - Train Accuracy: 0.9565, Validation Accuracy: 0.9471, Loss: 0.0507
Epoch   1 Batch  339/538 - Train Accuracy: 0.9323, Validation Accuracy: 0.9510, Loss: 0.0445
Epoch   1 Batch  340/538 - Train Accuracy: 0.9213, Validation Accuracy: 0.9453, Loss: 0.0480
Epoch   1 Batch  341/538 - Train Accuracy: 0.9406, Validation Accuracy: 0.9492, Loss: 0.0459
Epoch   1 Batch  342/538 - Train Accuracy: 0.9278, Validation Accuracy: 0.9519, Loss: 0.0472
Epoch   1 Batch  343/538 - Train Accuracy: 0.9580, Validation Accuracy: 0.9572, Loss: 0.0487
Epoch   1 Batch  344/538 - Train Accuracy: 0.9422, Validation Accuracy: 0.9512, Loss: 0.0444
Epoch   1 Batch  345/538 - Train Accuracy: 0.9429, Validation Accuracy: 0.9498, Loss: 0.0507
Epoch   1 Batch  346/538 - Train Accuracy: 0.9315, Validation Accuracy: 0.9435, Loss: 0.0540
Epoch   1 Batch  347/538 - Train Accuracy: 0.9406, Validation Accuracy: 0.9405, Loss: 0.0475
Epoch   1 Batch  348/538 - Train Accuracy: 0.9461, Validation Accuracy: 0.9386, Loss: 0.0439
Epoch   1 Batch  349/538 - Train Accuracy: 0.9641, Validation Accuracy: 0.9402, Loss: 0.0388
Epoch   1 Batch  350/538 - Train Accuracy: 0.9345, Validation Accuracy: 0.9455, Loss: 0.0555
Epoch   1 Batch  351/538 - Train Accuracy: 0.9430, Validation Accuracy: 0.9490, Loss: 0.0549
Epoch   1 Batch  352/538 - Train Accuracy: 0.9176, Validation Accuracy: 0.9439, Loss: 0.0681
Epoch   1 Batch  353/538 - Train Accuracy: 0.9201, Validation Accuracy: 0.9407, Loss: 0.0517
Epoch   1 Batch  354/538 - Train Accuracy: 0.9520, Validation Accuracy: 0.9405, Loss: 0.0487
Epoch   1 Batch  355/538 - Train Accuracy: 0.9453, Validation Accuracy: 0.9396, Loss: 0.0493
Epoch   1 Batch  356/538 - Train Accuracy: 0.9657, Validation Accuracy: 0.9551, Loss: 0.0412
Epoch   1 Batch  357/538 - Train Accuracy: 0.9281, Validation Accuracy: 0.9583, Loss: 0.0469
Epoch   1 Batch  358/538 - Train Accuracy: 0.9588, Validation Accuracy: 0.9567, Loss: 0.0374
Epoch   1 Batch  359/538 - Train Accuracy: 0.9423, Validation Accuracy: 0.9513, Loss: 0.0472
Epoch   1 Batch  360/538 - Train Accuracy: 0.9330, Validation Accuracy: 0.9538, Loss: 0.0456
Epoch   1 Batch  361/538 - Train Accuracy: 0.9505, Validation Accuracy: 0.9498, Loss: 0.0497
Epoch   1 Batch  362/538 - Train Accuracy: 0.9477, Validation Accuracy: 0.9430, Loss: 0.0390
Epoch   1 Batch  363/538 - Train Accuracy: 0.9507, Validation Accuracy: 0.9396, Loss: 0.0465
Epoch   1 Batch  364/538 - Train Accuracy: 0.9203, Validation Accuracy: 0.9261, Loss: 0.0543
Epoch   1 Batch  365/538 - Train Accuracy: 0.9288, Validation Accuracy: 0.9325, Loss: 0.0492
Epoch   1 Batch  366/538 - Train Accuracy: 0.9451, Validation Accuracy: 0.9405, Loss: 0.0467
Epoch   1 Batch  367/538 - Train Accuracy: 0.9527, Validation Accuracy: 0.9425, Loss: 0.0390
Epoch   1 Batch  368/538 - Train Accuracy: 0.9460, Validation Accuracy: 0.9542, Loss: 0.0424
Epoch   1 Batch  369/538 - Train Accuracy: 0.9477, Validation Accuracy: 0.9476, Loss: 0.0400
Epoch   1 Batch  370/538 - Train Accuracy: 0.9570, Validation Accuracy: 0.9446, Loss: 0.0480
Epoch   1 Batch  371/538 - Train Accuracy: 0.9583, Validation Accuracy: 0.9446, Loss: 0.0457
Epoch   1 Batch  372/538 - Train Accuracy: 0.9611, Validation Accuracy: 0.9423, Loss: 0.0457
Epoch   1 Batch  373/538 - Train Accuracy: 0.9469, Validation Accuracy: 0.9455, Loss: 0.0385
Epoch   1 Batch  374/538 - Train Accuracy: 0.9633, Validation Accuracy: 0.9467, Loss: 0.0435
Epoch   1 Batch  375/538 - Train Accuracy: 0.9567, Validation Accuracy: 0.9480, Loss: 0.0395
Epoch   1 Batch  376/538 - Train Accuracy: 0.9432, Validation Accuracy: 0.9448, Loss: 0.0471
Epoch   1 Batch  377/538 - Train Accuracy: 0.9691, Validation Accuracy: 0.9453, Loss: 0.0440
Epoch   1 Batch  378/538 - Train Accuracy: 0.9449, Validation Accuracy: 0.9414, Loss: 0.0395
Epoch   1 Batch  379/538 - Train Accuracy: 0.9347, Validation Accuracy: 0.9469, Loss: 0.0454
Epoch   1 Batch  380/538 - Train Accuracy: 0.9289, Validation Accuracy: 0.9513, Loss: 0.0390
Epoch   1 Batch  381/538 - Train Accuracy: 0.9520, Validation Accuracy: 0.9537, Loss: 0.0417
Epoch   1 Batch  382/538 - Train Accuracy: 0.9455, Validation Accuracy: 0.9535, Loss: 0.0477
Epoch   1 Batch  383/538 - Train Accuracy: 0.9570, Validation Accuracy: 0.9474, Loss: 0.0447
Epoch   1 Batch  384/538 - Train Accuracy: 0.9328, Validation Accuracy: 0.9386, Loss: 0.0442
Epoch   1 Batch  385/538 - Train Accuracy: 0.9505, Validation Accuracy: 0.9352, Loss: 0.0467
Epoch   1 Batch  386/538 - Train Accuracy: 0.9480, Validation Accuracy: 0.9460, Loss: 0.0491
Epoch   1 Batch  387/538 - Train Accuracy: 0.9385, Validation Accuracy: 0.9585, Loss: 0.0463
Epoch   1 Batch  388/538 - Train Accuracy: 0.9568, Validation Accuracy: 0.9480, Loss: 0.0439
Epoch   1 Batch  389/538 - Train Accuracy: 0.9322, Validation Accuracy: 0.9453, Loss: 0.0529
Epoch   1 Batch  390/538 - Train Accuracy: 0.9500, Validation Accuracy: 0.9364, Loss: 0.0393
Epoch   1 Batch  391/538 - Train Accuracy: 0.9347, Validation Accuracy: 0.9437, Loss: 0.0421
Epoch   1 Batch  392/538 - Train Accuracy: 0.9481, Validation Accuracy: 0.9576, Loss: 0.0431
Epoch   1 Batch  393/538 - Train Accuracy: 0.9593, Validation Accuracy: 0.9544, Loss: 0.0412
Epoch   1 Batch  394/538 - Train Accuracy: 0.9270, Validation Accuracy: 0.9586, Loss: 0.0504
Epoch   1 Batch  395/538 - Train Accuracy: 0.9332, Validation Accuracy: 0.9366, Loss: 0.0499
Epoch   1 Batch  396/538 - Train Accuracy: 0.9465, Validation Accuracy: 0.9299, Loss: 0.0408
Epoch   1 Batch  397/538 - Train Accuracy: 0.9369, Validation Accuracy: 0.9363, Loss: 0.0469
Epoch   1 Batch  398/538 - Train Accuracy: 0.9518, Validation Accuracy: 0.9423, Loss: 0.0459
Epoch   1 Batch  399/538 - Train Accuracy: 0.9361, Validation Accuracy: 0.9517, Loss: 0.0529
Epoch   1 Batch  400/538 - Train Accuracy: 0.9500, Validation Accuracy: 0.9585, Loss: 0.0483
Epoch   1 Batch  401/538 - Train Accuracy: 0.9539, Validation Accuracy: 0.9572, Loss: 0.0401
Epoch   1 Batch  402/538 - Train Accuracy: 0.9473, Validation Accuracy: 0.9609, Loss: 0.0400
Epoch   1 Batch  403/538 - Train Accuracy: 0.9451, Validation Accuracy: 0.9592, Loss: 0.0463
Epoch   1 Batch  404/538 - Train Accuracy: 0.9479, Validation Accuracy: 0.9524, Loss: 0.0424
Epoch   1 Batch  405/538 - Train Accuracy: 0.9535, Validation Accuracy: 0.9458, Loss: 0.0405
Epoch   1 Batch  406/538 - Train Accuracy: 0.9371, Validation Accuracy: 0.9451, Loss: 0.0438
Epoch   1 Batch  407/538 - Train Accuracy: 0.9400, Validation Accuracy: 0.9519, Loss: 0.0484
Epoch   1 Batch  408/538 - Train Accuracy: 0.9340, Validation Accuracy: 0.9549, Loss: 0.0518
Epoch   1 Batch  409/538 - Train Accuracy: 0.9391, Validation Accuracy: 0.9499, Loss: 0.0431
Epoch   1 Batch  410/538 - Train Accuracy: 0.9395, Validation Accuracy: 0.9428, Loss: 0.0438
Epoch   1 Batch  411/538 - Train Accuracy: 0.9552, Validation Accuracy: 0.9490, Loss: 0.0447
Epoch   1 Batch  412/538 - Train Accuracy: 0.9438, Validation Accuracy: 0.9469, Loss: 0.0360
Epoch   1 Batch  413/538 - Train Accuracy: 0.9418, Validation Accuracy: 0.9361, Loss: 0.0461
Epoch   1 Batch  414/538 - Train Accuracy: 0.9150, Validation Accuracy: 0.9324, Loss: 0.0561
Epoch   1 Batch  415/538 - Train Accuracy: 0.9299, Validation Accuracy: 0.9327, Loss: 0.0474
Epoch   1 Batch  416/538 - Train Accuracy: 0.9411, Validation Accuracy: 0.9423, Loss: 0.0464
Epoch   1 Batch  417/538 - Train Accuracy: 0.9518, Validation Accuracy: 0.9391, Loss: 0.0422
Epoch   1 Batch  418/538 - Train Accuracy: 0.9529, Validation Accuracy: 0.9387, Loss: 0.0472
Epoch   1 Batch  419/538 - Train Accuracy: 0.9533, Validation Accuracy: 0.9434, Loss: 0.0380
Epoch   1 Batch  420/538 - Train Accuracy: 0.9520, Validation Accuracy: 0.9391, Loss: 0.0458
Epoch   1 Batch  421/538 - Train Accuracy: 0.9334, Validation Accuracy: 0.9448, Loss: 0.0404
Epoch   1 Batch  422/538 - Train Accuracy: 0.9379, Validation Accuracy: 0.9503, Loss: 0.0469
Epoch   1 Batch  423/538 - Train Accuracy: 0.9398, Validation Accuracy: 0.9446, Loss: 0.0455
Epoch   1 Batch  424/538 - Train Accuracy: 0.9235, Validation Accuracy: 0.9448, Loss: 0.0507
Epoch   1 Batch  425/538 - Train Accuracy: 0.9412, Validation Accuracy: 0.9467, Loss: 0.0582
Epoch   1 Batch  426/538 - Train Accuracy: 0.9383, Validation Accuracy: 0.9403, Loss: 0.0439
Epoch   1 Batch  427/538 - Train Accuracy: 0.9441, Validation Accuracy: 0.9430, Loss: 0.0448
Epoch   1 Batch  428/538 - Train Accuracy: 0.9515, Validation Accuracy: 0.9389, Loss: 0.0375
Epoch   1 Batch  429/538 - Train Accuracy: 0.9518, Validation Accuracy: 0.9395, Loss: 0.0428
Epoch   1 Batch  430/538 - Train Accuracy: 0.9531, Validation Accuracy: 0.9570, Loss: 0.0412
Epoch   1 Batch  431/538 - Train Accuracy: 0.9443, Validation Accuracy: 0.9469, Loss: 0.0383
Epoch   1 Batch  432/538 - Train Accuracy: 0.9165, Validation Accuracy: 0.9409, Loss: 0.0510
Epoch   1 Batch  433/538 - Train Accuracy: 0.9408, Validation Accuracy: 0.9513, Loss: 0.0664
Epoch   1 Batch  434/538 - Train Accuracy: 0.9340, Validation Accuracy: 0.9506, Loss: 0.0402
Epoch   1 Batch  435/538 - Train Accuracy: 0.9596, Validation Accuracy: 0.9426, Loss: 0.0400
Epoch   1 Batch  436/538 - Train Accuracy: 0.9293, Validation Accuracy: 0.9428, Loss: 0.0500
Epoch   1 Batch  437/538 - Train Accuracy: 0.9439, Validation Accuracy: 0.9384, Loss: 0.0417
Epoch   1 Batch  438/538 - Train Accuracy: 0.9527, Validation Accuracy: 0.9398, Loss: 0.0378
Epoch   1 Batch  439/538 - Train Accuracy: 0.9604, Validation Accuracy: 0.9428, Loss: 0.0418
Epoch   1 Batch  440/538 - Train Accuracy: 0.9396, Validation Accuracy: 0.9474, Loss: 0.0481
Epoch   1 Batch  441/538 - Train Accuracy: 0.9338, Validation Accuracy: 0.9528, Loss: 0.0499
Epoch   1 Batch  442/538 - Train Accuracy: 0.9551, Validation Accuracy: 0.9457, Loss: 0.0312
Epoch   1 Batch  443/538 - Train Accuracy: 0.9500, Validation Accuracy: 0.9366, Loss: 0.0408
Epoch   1 Batch  444/538 - Train Accuracy: 0.9390, Validation Accuracy: 0.9297, Loss: 0.0394
Epoch   1 Batch  445/538 - Train Accuracy: 0.9568, Validation Accuracy: 0.9329, Loss: 0.0381
Epoch   1 Batch  446/538 - Train Accuracy: 0.9552, Validation Accuracy: 0.9473, Loss: 0.0392
Epoch   1 Batch  447/538 - Train Accuracy: 0.9510, Validation Accuracy: 0.9558, Loss: 0.0405
Epoch   1 Batch  448/538 - Train Accuracy: 0.9412, Validation Accuracy: 0.9473, Loss: 0.0348
Epoch   1 Batch  449/538 - Train Accuracy: 0.9600, Validation Accuracy: 0.9400, Loss: 0.0505
Epoch   1 Batch  450/538 - Train Accuracy: 0.9271, Validation Accuracy: 0.9437, Loss: 0.0516
Epoch   1 Batch  451/538 - Train Accuracy: 0.9365, Validation Accuracy: 0.9474, Loss: 0.0395
Epoch   1 Batch  452/538 - Train Accuracy: 0.9543, Validation Accuracy: 0.9492, Loss: 0.0364
Epoch   1 Batch  453/538 - Train Accuracy: 0.9504, Validation Accuracy: 0.9483, Loss: 0.0434
Epoch   1 Batch  454/538 - Train Accuracy: 0.9515, Validation Accuracy: 0.9467, Loss: 0.0483
Epoch   1 Batch  455/538 - Train Accuracy: 0.9556, Validation Accuracy: 0.9400, Loss: 0.0404
Epoch   1 Batch  456/538 - Train Accuracy: 0.9585, Validation Accuracy: 0.9357, Loss: 0.0517
Epoch   1 Batch  457/538 - Train Accuracy: 0.9486, Validation Accuracy: 0.9426, Loss: 0.0377
Epoch   1 Batch  458/538 - Train Accuracy: 0.9537, Validation Accuracy: 0.9544, Loss: 0.0393
Epoch   1 Batch  459/538 - Train Accuracy: 0.9520, Validation Accuracy: 0.9600, Loss: 0.0346
Epoch   1 Batch  460/538 - Train Accuracy: 0.9245, Validation Accuracy: 0.9526, Loss: 0.0437
Epoch   1 Batch  461/538 - Train Accuracy: 0.9422, Validation Accuracy: 0.9487, Loss: 0.0456
Epoch   1 Batch  462/538 - Train Accuracy: 0.9505, Validation Accuracy: 0.9517, Loss: 0.0374
Epoch   1 Batch  463/538 - Train Accuracy: 0.9391, Validation Accuracy: 0.9498, Loss: 0.0468
Epoch   1 Batch  464/538 - Train Accuracy: 0.9463, Validation Accuracy: 0.9535, Loss: 0.0391
Epoch   1 Batch  465/538 - Train Accuracy: 0.9559, Validation Accuracy: 0.9471, Loss: 0.0374
Epoch   1 Batch  466/538 - Train Accuracy: 0.9391, Validation Accuracy: 0.9432, Loss: 0.0385
Epoch   1 Batch  467/538 - Train Accuracy: 0.9522, Validation Accuracy: 0.9450, Loss: 0.0438
Epoch   1 Batch  468/538 - Train Accuracy: 0.9518, Validation Accuracy: 0.9466, Loss: 0.0478
Epoch   1 Batch  469/538 - Train Accuracy: 0.9504, Validation Accuracy: 0.9448, Loss: 0.0382
Epoch   1 Batch  470/538 - Train Accuracy: 0.9503, Validation Accuracy: 0.9458, Loss: 0.0428
Epoch   1 Batch  471/538 - Train Accuracy: 0.9604, Validation Accuracy: 0.9450, Loss: 0.0352
Epoch   1 Batch  472/538 - Train Accuracy: 0.9889, Validation Accuracy: 0.9570, Loss: 0.0315
Epoch   1 Batch  473/538 - Train Accuracy: 0.9422, Validation Accuracy: 0.9577, Loss: 0.0428
Epoch   1 Batch  474/538 - Train Accuracy: 0.9635, Validation Accuracy: 0.9492, Loss: 0.0350
Epoch   1 Batch  475/538 - Train Accuracy: 0.9459, Validation Accuracy: 0.9435, Loss: 0.0380
Epoch   1 Batch  476/538 - Train Accuracy: 0.9523, Validation Accuracy: 0.9535, Loss: 0.0394
Epoch   1 Batch  477/538 - Train Accuracy: 0.9549, Validation Accuracy: 0.9458, Loss: 0.0441
Epoch   1 Batch  478/538 - Train Accuracy: 0.9650, Validation Accuracy: 0.9364, Loss: 0.0319
Epoch   1 Batch  479/538 - Train Accuracy: 0.9533, Validation Accuracy: 0.9345, Loss: 0.0394
Epoch   1 Batch  480/538 - Train Accuracy: 0.9641, Validation Accuracy: 0.9441, Loss: 0.0391
Epoch   1 Batch  481/538 - Train Accuracy: 0.9544, Validation Accuracy: 0.9533, Loss: 0.0381
Epoch   1 Batch  482/538 - Train Accuracy: 0.9574, Validation Accuracy: 0.9558, Loss: 0.0330
Epoch   1 Batch  483/538 - Train Accuracy: 0.9322, Validation Accuracy: 0.9627, Loss: 0.0470
Epoch   1 Batch  484/538 - Train Accuracy: 0.9464, Validation Accuracy: 0.9581, Loss: 0.0450
Epoch   1 Batch  485/538 - Train Accuracy: 0.9509, Validation Accuracy: 0.9446, Loss: 0.0442
Epoch   1 Batch  486/538 - Train Accuracy: 0.9622, Validation Accuracy: 0.9480, Loss: 0.0344
Epoch   1 Batch  487/538 - Train Accuracy: 0.9647, Validation Accuracy: 0.9498, Loss: 0.0373
Epoch   1 Batch  488/538 - Train Accuracy: 0.9529, Validation Accuracy: 0.9471, Loss: 0.0315
Epoch   1 Batch  489/538 - Train Accuracy: 0.9553, Validation Accuracy: 0.9537, Loss: 0.0437
Epoch   1 Batch  490/538 - Train Accuracy: 0.9475, Validation Accuracy: 0.9583, Loss: 0.0402
Epoch   1 Batch  491/538 - Train Accuracy: 0.9328, Validation Accuracy: 0.9608, Loss: 0.0441
Epoch   1 Batch  492/538 - Train Accuracy: 0.9533, Validation Accuracy: 0.9533, Loss: 0.0355
Epoch   1 Batch  493/538 - Train Accuracy: 0.9442, Validation Accuracy: 0.9535, Loss: 0.0363
Epoch   1 Batch  494/538 - Train Accuracy: 0.9445, Validation Accuracy: 0.9522, Loss: 0.0458
Epoch   1 Batch  495/538 - Train Accuracy: 0.9359, Validation Accuracy: 0.9606, Loss: 0.0427
Epoch   1 Batch  496/538 - Train Accuracy: 0.9598, Validation Accuracy: 0.9590, Loss: 0.0310
Epoch   1 Batch  497/538 - Train Accuracy: 0.9528, Validation Accuracy: 0.9606, Loss: 0.0372
Epoch   1 Batch  498/538 - Train Accuracy: 0.9541, Validation Accuracy: 0.9583, Loss: 0.0387
Epoch   1 Batch  499/538 - Train Accuracy: 0.9388, Validation Accuracy: 0.9574, Loss: 0.0398
Epoch   1 Batch  500/538 - Train Accuracy: 0.9643, Validation Accuracy: 0.9498, Loss: 0.0291
Epoch   1 Batch  501/538 - Train Accuracy: 0.9555, Validation Accuracy: 0.9563, Loss: 0.0408
Epoch   1 Batch  502/538 - Train Accuracy: 0.9486, Validation Accuracy: 0.9577, Loss: 0.0365
Epoch   1 Batch  503/538 - Train Accuracy: 0.9581, Validation Accuracy: 0.9583, Loss: 0.0383
Epoch   1 Batch  504/538 - Train Accuracy: 0.9756, Validation Accuracy: 0.9608, Loss: 0.0282
Epoch   1 Batch  505/538 - Train Accuracy: 0.9593, Validation Accuracy: 0.9609, Loss: 0.0288
Epoch   1 Batch  506/538 - Train Accuracy: 0.9630, Validation Accuracy: 0.9705, Loss: 0.0299
Epoch   1 Batch  507/538 - Train Accuracy: 0.9401, Validation Accuracy: 0.9643, Loss: 0.0423
Epoch   1 Batch  508/538 - Train Accuracy: 0.9526, Validation Accuracy: 0.9696, Loss: 0.0347
Epoch   1 Batch  509/538 - Train Accuracy: 0.9648, Validation Accuracy: 0.9647, Loss: 0.0362
Epoch   1 Batch  510/538 - Train Accuracy: 0.9673, Validation Accuracy: 0.9712, Loss: 0.0348
Epoch   1 Batch  511/538 - Train Accuracy: 0.9510, Validation Accuracy: 0.9711, Loss: 0.0390
Epoch   1 Batch  512/538 - Train Accuracy: 0.9516, Validation Accuracy: 0.9709, Loss: 0.0433
Epoch   1 Batch  513/538 - Train Accuracy: 0.9479, Validation Accuracy: 0.9684, Loss: 0.0321
Epoch   1 Batch  514/538 - Train Accuracy: 0.9568, Validation Accuracy: 0.9645, Loss: 0.0352
Epoch   1 Batch  515/538 - Train Accuracy: 0.9526, Validation Accuracy: 0.9590, Loss: 0.0429
Epoch   1 Batch  516/538 - Train Accuracy: 0.9529, Validation Accuracy: 0.9544, Loss: 0.0380
Epoch   1 Batch  517/538 - Train Accuracy: 0.9637, Validation Accuracy: 0.9579, Loss: 0.0333
Epoch   1 Batch  518/538 - Train Accuracy: 0.9637, Validation Accuracy: 0.9558, Loss: 0.0436
Epoch   1 Batch  519/538 - Train Accuracy: 0.9559, Validation Accuracy: 0.9506, Loss: 0.0344
Epoch   1 Batch  520/538 - Train Accuracy: 0.9539, Validation Accuracy: 0.9448, Loss: 0.0387
Epoch   1 Batch  521/538 - Train Accuracy: 0.9490, Validation Accuracy: 0.9439, Loss: 0.0411
Epoch   1 Batch  522/538 - Train Accuracy: 0.9563, Validation Accuracy: 0.9503, Loss: 0.0336
Epoch   1 Batch  523/538 - Train Accuracy: 0.9504, Validation Accuracy: 0.9508, Loss: 0.0363
Epoch   1 Batch  524/538 - Train Accuracy: 0.9559, Validation Accuracy: 0.9450, Loss: 0.0329
Epoch   1 Batch  525/538 - Train Accuracy: 0.9431, Validation Accuracy: 0.9464, Loss: 0.0373
Epoch   1 Batch  526/538 - Train Accuracy: 0.9542, Validation Accuracy: 0.9455, Loss: 0.0375
Epoch   1 Batch  527/538 - Train Accuracy: 0.9416, Validation Accuracy: 0.9464, Loss: 0.0362
Epoch   1 Batch  528/538 - Train Accuracy: 0.9498, Validation Accuracy: 0.9498, Loss: 0.0421
Epoch   1 Batch  529/538 - Train Accuracy: 0.9350, Validation Accuracy: 0.9441, Loss: 0.0377
Epoch   1 Batch  530/538 - Train Accuracy: 0.9314, Validation Accuracy: 0.9460, Loss: 0.0443
Epoch   1 Batch  531/538 - Train Accuracy: 0.9467, Validation Accuracy: 0.9489, Loss: 0.0420
Epoch   1 Batch  532/538 - Train Accuracy: 0.9457, Validation Accuracy: 0.9554, Loss: 0.0321
Epoch   1 Batch  533/538 - Train Accuracy: 0.9508, Validation Accuracy: 0.9540, Loss: 0.0329
Epoch   1 Batch  534/538 - Train Accuracy: 0.9647, Validation Accuracy: 0.9519, Loss: 0.0282
Epoch   1 Batch  535/538 - Train Accuracy: 0.9585, Validation Accuracy: 0.9455, Loss: 0.0354
Epoch   1 Batch  536/538 - Train Accuracy: 0.9619, Validation Accuracy: 0.9492, Loss: 0.0426
Epoch   2 Batch    0/538 - Train Accuracy: 0.9547, Validation Accuracy: 0.9482, Loss: 0.0279
Epoch   2 Batch    1/538 - Train Accuracy: 0.9658, Validation Accuracy: 0.9476, Loss: 0.0360
Epoch   2 Batch    2/538 - Train Accuracy: 0.9520, Validation Accuracy: 0.9524, Loss: 0.0424
Epoch   2 Batch    3/538 - Train Accuracy: 0.9699, Validation Accuracy: 0.9544, Loss: 0.0345
Epoch   2 Batch    4/538 - Train Accuracy: 0.9566, Validation Accuracy: 0.9480, Loss: 0.0319
Epoch   2 Batch    5/538 - Train Accuracy: 0.9522, Validation Accuracy: 0.9487, Loss: 0.0397
Epoch   2 Batch    6/538 - Train Accuracy: 0.9487, Validation Accuracy: 0.9490, Loss: 0.0322
Epoch   2 Batch    7/538 - Train Accuracy: 0.9588, Validation Accuracy: 0.9535, Loss: 0.0333
Epoch   2 Batch    8/538 - Train Accuracy: 0.9521, Validation Accuracy: 0.9537, Loss: 0.0343
Epoch   2 Batch    9/538 - Train Accuracy: 0.9479, Validation Accuracy: 0.9567, Loss: 0.0319
Epoch   2 Batch   10/538 - Train Accuracy: 0.9369, Validation Accuracy: 0.9583, Loss: 0.0394
Epoch   2 Batch   11/538 - Train Accuracy: 0.9615, Validation Accuracy: 0.9517, Loss: 0.0334
Epoch   2 Batch   12/538 - Train Accuracy: 0.9564, Validation Accuracy: 0.9503, Loss: 0.0337
Epoch   2 Batch   13/538 - Train Accuracy: 0.9704, Validation Accuracy: 0.9524, Loss: 0.0304
Epoch   2 Batch   14/538 - Train Accuracy: 0.9563, Validation Accuracy: 0.9592, Loss: 0.0319
Epoch   2 Batch   15/538 - Train Accuracy: 0.9594, Validation Accuracy: 0.9528, Loss: 0.0324
Epoch   2 Batch   16/538 - Train Accuracy: 0.9528, Validation Accuracy: 0.9515, Loss: 0.0344
Epoch   2 Batch   17/538 - Train Accuracy: 0.9633, Validation Accuracy: 0.9545, Loss: 0.0336
Epoch   2 Batch   18/538 - Train Accuracy: 0.9586, Validation Accuracy: 0.9505, Loss: 0.0460
Epoch   2 Batch   19/538 - Train Accuracy: 0.9389, Validation Accuracy: 0.9474, Loss: 0.0356
Epoch   2 Batch   20/538 - Train Accuracy: 0.9511, Validation Accuracy: 0.9466, Loss: 0.0359
Epoch   2 Batch   21/538 - Train Accuracy: 0.9735, Validation Accuracy: 0.9473, Loss: 0.0247
Epoch   2 Batch   22/538 - Train Accuracy: 0.9506, Validation Accuracy: 0.9515, Loss: 0.0342
Epoch   2 Batch   23/538 - Train Accuracy: 0.9479, Validation Accuracy: 0.9482, Loss: 0.0434
Epoch   2 Batch   24/538 - Train Accuracy: 0.9561, Validation Accuracy: 0.9498, Loss: 0.0381
Epoch   2 Batch   25/538 - Train Accuracy: 0.9359, Validation Accuracy: 0.9545, Loss: 0.0384
Epoch   2 Batch   26/538 - Train Accuracy: 0.9480, Validation Accuracy: 0.9524, Loss: 0.0441
Epoch   2 Batch   27/538 - Train Accuracy: 0.9691, Validation Accuracy: 0.9512, Loss: 0.0298
Epoch   2 Batch   28/538 - Train Accuracy: 0.9512, Validation Accuracy: 0.9508, Loss: 0.0362
Epoch   2 Batch   29/538 - Train Accuracy: 0.9602, Validation Accuracy: 0.9498, Loss: 0.0295
Epoch   2 Batch   30/538 - Train Accuracy: 0.9525, Validation Accuracy: 0.9519, Loss: 0.0382
Epoch   2 Batch   31/538 - Train Accuracy: 0.9790, Validation Accuracy: 0.9521, Loss: 0.0261
Epoch   2 Batch   32/538 - Train Accuracy: 0.9589, Validation Accuracy: 0.9565, Loss: 0.0228
Epoch   2 Batch   33/538 - Train Accuracy: 0.9619, Validation Accuracy: 0.9609, Loss: 0.0369
Epoch   2 Batch   34/538 - Train Accuracy: 0.9389, Validation Accuracy: 0.9602, Loss: 0.0396
Epoch   2 Batch   35/538 - Train Accuracy: 0.9627, Validation Accuracy: 0.9609, Loss: 0.0292
Epoch   2 Batch   36/538 - Train Accuracy: 0.9578, Validation Accuracy: 0.9616, Loss: 0.0288
Epoch   2 Batch   37/538 - Train Accuracy: 0.9611, Validation Accuracy: 0.9572, Loss: 0.0340
Epoch   2 Batch   38/538 - Train Accuracy: 0.9508, Validation Accuracy: 0.9572, Loss: 0.0318
Epoch   2 Batch   39/538 - Train Accuracy: 0.9619, Validation Accuracy: 0.9572, Loss: 0.0314
Epoch   2 Batch   40/538 - Train Accuracy: 0.9577, Validation Accuracy: 0.9563, Loss: 0.0255
Epoch   2 Batch   41/538 - Train Accuracy: 0.9602, Validation Accuracy: 0.9689, Loss: 0.0325
Epoch   2 Batch   42/538 - Train Accuracy: 0.9598, Validation Accuracy: 0.9688, Loss: 0.0295
Epoch   2 Batch   43/538 - Train Accuracy: 0.9426, Validation Accuracy: 0.9657, Loss: 0.0420
Epoch   2 Batch   44/538 - Train Accuracy: 0.9518, Validation Accuracy: 0.9625, Loss: 0.0365
Epoch   2 Batch   45/538 - Train Accuracy: 0.9550, Validation Accuracy: 0.9592, Loss: 0.0373
Epoch   2 Batch   46/538 - Train Accuracy: 0.9689, Validation Accuracy: 0.9609, Loss: 0.0297
Epoch   2 Batch   47/538 - Train Accuracy: 0.9663, Validation Accuracy: 0.9569, Loss: 0.0360
Epoch   2 Batch   48/538 - Train Accuracy: 0.9397, Validation Accuracy: 0.9600, Loss: 0.0351
Epoch   2 Batch   49/538 - Train Accuracy: 0.9650, Validation Accuracy: 0.9608, Loss: 0.0321
Epoch   2 Batch   50/538 - Train Accuracy: 0.9684, Validation Accuracy: 0.9510, Loss: 0.0283
Epoch   2 Batch   51/538 - Train Accuracy: 0.9554, Validation Accuracy: 0.9474, Loss: 0.0398
Epoch   2 Batch   52/538 - Train Accuracy: 0.9682, Validation Accuracy: 0.9496, Loss: 0.0341
Epoch   2 Batch   53/538 - Train Accuracy: 0.9391, Validation Accuracy: 0.9490, Loss: 0.0370
Epoch   2 Batch   54/538 - Train Accuracy: 0.9617, Validation Accuracy: 0.9503, Loss: 0.0292
Epoch   2 Batch   55/538 - Train Accuracy: 0.9428, Validation Accuracy: 0.9533, Loss: 0.0319
Epoch   2 Batch   56/538 - Train Accuracy: 0.9598, Validation Accuracy: 0.9476, Loss: 0.0334
Epoch   2 Batch   57/538 - Train Accuracy: 0.9279, Validation Accuracy: 0.9529, Loss: 0.0384
Epoch   2 Batch   58/538 - Train Accuracy: 0.9590, Validation Accuracy: 0.9565, Loss: 0.0307
Epoch   2 Batch   59/538 - Train Accuracy: 0.9453, Validation Accuracy: 0.9521, Loss: 0.0371
Epoch   2 Batch   60/538 - Train Accuracy: 0.9609, Validation Accuracy: 0.9567, Loss: 0.0338
Epoch   2 Batch   61/538 - Train Accuracy: 0.9604, Validation Accuracy: 0.9572, Loss: 0.0319
Epoch   2 Batch   62/538 - Train Accuracy: 0.9563, Validation Accuracy: 0.9547, Loss: 0.0371
Epoch   2 Batch   63/538 - Train Accuracy: 0.9704, Validation Accuracy: 0.9510, Loss: 0.0325
Epoch   2 Batch   64/538 - Train Accuracy: 0.9665, Validation Accuracy: 0.9505, Loss: 0.0341
Epoch   2 Batch   65/538 - Train Accuracy: 0.9557, Validation Accuracy: 0.9464, Loss: 0.0353
Epoch   2 Batch   66/538 - Train Accuracy: 0.9689, Validation Accuracy: 0.9458, Loss: 0.0281
Epoch   2 Batch   67/538 - Train Accuracy: 0.9705, Validation Accuracy: 0.9551, Loss: 0.0329
Epoch   2 Batch   68/538 - Train Accuracy: 0.9667, Validation Accuracy: 0.9585, Loss: 0.0284
Epoch   2 Batch   69/538 - Train Accuracy: 0.9539, Validation Accuracy: 0.9519, Loss: 0.0314
Epoch   2 Batch   70/538 - Train Accuracy: 0.9565, Validation Accuracy: 0.9400, Loss: 0.0310
Epoch   2 Batch   71/538 - Train Accuracy: 0.9514, Validation Accuracy: 0.9485, Loss: 0.0422
Epoch   2 Batch   72/538 - Train Accuracy: 0.9526, Validation Accuracy: 0.9496, Loss: 0.0426
Epoch   2 Batch   73/538 - Train Accuracy: 0.9555, Validation Accuracy: 0.9483, Loss: 0.0377
Epoch   2 Batch   74/538 - Train Accuracy: 0.9658, Validation Accuracy: 0.9437, Loss: 0.0294
Epoch   2 Batch   75/538 - Train Accuracy: 0.9505, Validation Accuracy: 0.9537, Loss: 0.0369
Epoch   2 Batch   76/538 - Train Accuracy: 0.9559, Validation Accuracy: 0.9615, Loss: 0.0342
Epoch   2 Batch   77/538 - Train Accuracy: 0.9545, Validation Accuracy: 0.9629, Loss: 0.0300
Epoch   2 Batch   78/538 - Train Accuracy: 0.9494, Validation Accuracy: 0.9586, Loss: 0.0314
Epoch   2 Batch   79/538 - Train Accuracy: 0.9550, Validation Accuracy: 0.9604, Loss: 0.0263
Epoch   2 Batch   80/538 - Train Accuracy: 0.9602, Validation Accuracy: 0.9663, Loss: 0.0347
Epoch   2 Batch   81/538 - Train Accuracy: 0.9443, Validation Accuracy: 0.9599, Loss: 0.0372
Epoch   2 Batch   82/538 - Train Accuracy: 0.9393, Validation Accuracy: 0.9533, Loss: 0.0345
Epoch   2 Batch   83/538 - Train Accuracy: 0.9273, Validation Accuracy: 0.9464, Loss: 0.0379
Epoch   2 Batch   84/538 - Train Accuracy: 0.9431, Validation Accuracy: 0.9432, Loss: 0.0368
Epoch   2 Batch   85/538 - Train Accuracy: 0.9693, Validation Accuracy: 0.9450, Loss: 0.0277
Epoch   2 Batch   86/538 - Train Accuracy: 0.9682, Validation Accuracy: 0.9517, Loss: 0.0295
Epoch   2 Batch   87/538 - Train Accuracy: 0.9523, Validation Accuracy: 0.9538, Loss: 0.0348
Epoch   2 Batch   88/538 - Train Accuracy: 0.9574, Validation Accuracy: 0.9579, Loss: 0.0336
Epoch   2 Batch   89/538 - Train Accuracy: 0.9547, Validation Accuracy: 0.9551, Loss: 0.0299
Epoch   2 Batch   90/538 - Train Accuracy: 0.9522, Validation Accuracy: 0.9510, Loss: 0.0401
Epoch   2 Batch   91/538 - Train Accuracy: 0.9449, Validation Accuracy: 0.9553, Loss: 0.0385
Epoch   2 Batch   92/538 - Train Accuracy: 0.9596, Validation Accuracy: 0.9521, Loss: 0.0331
Epoch   2 Batch   93/538 - Train Accuracy: 0.9500, Validation Accuracy: 0.9441, Loss: 0.0294
Epoch   2 Batch   94/538 - Train Accuracy: 0.9604, Validation Accuracy: 0.9469, Loss: 0.0286
Epoch   2 Batch   95/538 - Train Accuracy: 0.9506, Validation Accuracy: 0.9464, Loss: 0.0286
Epoch   2 Batch   96/538 - Train Accuracy: 0.9706, Validation Accuracy: 0.9506, Loss: 0.0249
Epoch   2 Batch   97/538 - Train Accuracy: 0.9607, Validation Accuracy: 0.9563, Loss: 0.0279
Epoch   2 Batch   98/538 - Train Accuracy: 0.9676, Validation Accuracy: 0.9474, Loss: 0.0361
Epoch   2 Batch   99/538 - Train Accuracy: 0.9543, Validation Accuracy: 0.9448, Loss: 0.0342
Epoch   2 Batch  100/538 - Train Accuracy: 0.9596, Validation Accuracy: 0.9446, Loss: 0.0278
Epoch   2 Batch  101/538 - Train Accuracy: 0.9555, Validation Accuracy: 0.9624, Loss: 0.0408
Epoch   2 Batch  102/538 - Train Accuracy: 0.9527, Validation Accuracy: 0.9615, Loss: 0.0357
Epoch   2 Batch  103/538 - Train Accuracy: 0.9524, Validation Accuracy: 0.9545, Loss: 0.0319
Epoch   2 Batch  104/538 - Train Accuracy: 0.9554, Validation Accuracy: 0.9521, Loss: 0.0297
Epoch   2 Batch  105/538 - Train Accuracy: 0.9585, Validation Accuracy: 0.9510, Loss: 0.0285
Epoch   2 Batch  106/538 - Train Accuracy: 0.9480, Validation Accuracy: 0.9494, Loss: 0.0320
Epoch   2 Batch  107/538 - Train Accuracy: 0.9379, Validation Accuracy: 0.9466, Loss: 0.0404
Epoch   2 Batch  108/538 - Train Accuracy: 0.9613, Validation Accuracy: 0.9471, Loss: 0.0315
Epoch   2 Batch  109/538 - Train Accuracy: 0.9635, Validation Accuracy: 0.9483, Loss: 0.0278
Epoch   2 Batch  110/538 - Train Accuracy: 0.9488, Validation Accuracy: 0.9526, Loss: 0.0344
Epoch   2 Batch  111/538 - Train Accuracy: 0.9639, Validation Accuracy: 0.9544, Loss: 0.0288
Epoch   2 Batch  112/538 - Train Accuracy: 0.9488, Validation Accuracy: 0.9560, Loss: 0.0358
Epoch   2 Batch  113/538 - Train Accuracy: 0.9318, Validation Accuracy: 0.9600, Loss: 0.0391
Epoch   2 Batch  114/538 - Train Accuracy: 0.9648, Validation Accuracy: 0.9553, Loss: 0.0284
Epoch   2 Batch  115/538 - Train Accuracy: 0.9596, Validation Accuracy: 0.9439, Loss: 0.0341
Epoch   2 Batch  116/538 - Train Accuracy: 0.9511, Validation Accuracy: 0.9535, Loss: 0.0430
Epoch   2 Batch  117/538 - Train Accuracy: 0.9520, Validation Accuracy: 0.9510, Loss: 0.0395
Epoch   2 Batch  118/538 - Train Accuracy: 0.9719, Validation Accuracy: 0.9482, Loss: 0.0318
Epoch   2 Batch  119/538 - Train Accuracy: 0.9736, Validation Accuracy: 0.9460, Loss: 0.0242
Epoch   2 Batch  120/538 - Train Accuracy: 0.9648, Validation Accuracy: 0.9522, Loss: 0.0257
Epoch   2 Batch  121/538 - Train Accuracy: 0.9634, Validation Accuracy: 0.9499, Loss: 0.0298
Epoch   2 Batch  122/538 - Train Accuracy: 0.9528, Validation Accuracy: 0.9508, Loss: 0.0309
Epoch   2 Batch  123/538 - Train Accuracy: 0.9511, Validation Accuracy: 0.9510, Loss: 0.0282
Epoch   2 Batch  124/538 - Train Accuracy: 0.9648, Validation Accuracy: 0.9482, Loss: 0.0275
Epoch   2 Batch  125/538 - Train Accuracy: 0.9501, Validation Accuracy: 0.9554, Loss: 0.0358
Epoch   2 Batch  126/538 - Train Accuracy: 0.9416, Validation Accuracy: 0.9590, Loss: 0.0341
Epoch   2 Batch  127/538 - Train Accuracy: 0.9477, Validation Accuracy: 0.9588, Loss: 0.0410
Epoch   2 Batch  128/538 - Train Accuracy: 0.9531, Validation Accuracy: 0.9586, Loss: 0.0327
Epoch   2 Batch  129/538 - Train Accuracy: 0.9669, Validation Accuracy: 0.9597, Loss: 0.0246
Epoch   2 Batch  130/538 - Train Accuracy: 0.9630, Validation Accuracy: 0.9673, Loss: 0.0282
Epoch   2 Batch  131/538 - Train Accuracy: 0.9701, Validation Accuracy: 0.9634, Loss: 0.0302
Epoch   2 Batch  132/538 - Train Accuracy: 0.9567, Validation Accuracy: 0.9647, Loss: 0.0301
Epoch   2 Batch  133/538 - Train Accuracy: 0.9512, Validation Accuracy: 0.9624, Loss: 0.0336
Epoch   2 Batch  134/538 - Train Accuracy: 0.9635, Validation Accuracy: 0.9640, Loss: 0.0383
Epoch   2 Batch  135/538 - Train Accuracy: 0.9587, Validation Accuracy: 0.9574, Loss: 0.0390
Epoch   2 Batch  136/538 - Train Accuracy: 0.9552, Validation Accuracy: 0.9561, Loss: 0.0298
Epoch   2 Batch  137/538 - Train Accuracy: 0.9648, Validation Accuracy: 0.9517, Loss: 0.0394
Epoch   2 Batch  138/538 - Train Accuracy: 0.9479, Validation Accuracy: 0.9581, Loss: 0.0341
Epoch   2 Batch  139/538 - Train Accuracy: 0.9492, Validation Accuracy: 0.9574, Loss: 0.0358
Epoch   2 Batch  140/538 - Train Accuracy: 0.9342, Validation Accuracy: 0.9577, Loss: 0.0400
Epoch   2 Batch  141/538 - Train Accuracy: 0.9551, Validation Accuracy: 0.9476, Loss: 0.0326
Epoch   2 Batch  142/538 - Train Accuracy: 0.9500, Validation Accuracy: 0.9503, Loss: 0.0330
Epoch   2 Batch  143/538 - Train Accuracy: 0.9576, Validation Accuracy: 0.9574, Loss: 0.0401
Epoch   2 Batch  144/538 - Train Accuracy: 0.9590, Validation Accuracy: 0.9529, Loss: 0.0351
Epoch   2 Batch  145/538 - Train Accuracy: 0.9522, Validation Accuracy: 0.9425, Loss: 0.0386
Epoch   2 Batch  146/538 - Train Accuracy: 0.9538, Validation Accuracy: 0.9457, Loss: 0.0342
Epoch   2 Batch  147/538 - Train Accuracy: 0.9576, Validation Accuracy: 0.9522, Loss: 0.0331
Epoch   2 Batch  148/538 - Train Accuracy: 0.9385, Validation Accuracy: 0.9622, Loss: 0.0376
Epoch   2 Batch  149/538 - Train Accuracy: 0.9633, Validation Accuracy: 0.9528, Loss: 0.0299
Epoch   2 Batch  150/538 - Train Accuracy: 0.9525, Validation Accuracy: 0.9549, Loss: 0.0290
Epoch   2 Batch  151/538 - Train Accuracy: 0.9567, Validation Accuracy: 0.9542, Loss: 0.0363
Epoch   2 Batch  152/538 - Train Accuracy: 0.9581, Validation Accuracy: 0.9531, Loss: 0.0314
Epoch   2 Batch  153/538 - Train Accuracy: 0.9466, Validation Accuracy: 0.9586, Loss: 0.0310
Epoch   2 Batch  154/538 - Train Accuracy: 0.9708, Validation Accuracy: 0.9585, Loss: 0.0262
Epoch   2 Batch  155/538 - Train Accuracy: 0.9580, Validation Accuracy: 0.9585, Loss: 0.0367
Epoch   2 Batch  156/538 - Train Accuracy: 0.9766, Validation Accuracy: 0.9602, Loss: 0.0270
Epoch   2 Batch  157/538 - Train Accuracy: 0.9767, Validation Accuracy: 0.9643, Loss: 0.0293
Epoch   2 Batch  158/538 - Train Accuracy: 0.9701, Validation Accuracy: 0.9624, Loss: 0.0296
Epoch   2 Batch  159/538 - Train Accuracy: 0.9570, Validation Accuracy: 0.9652, Loss: 0.0341
Epoch   2 Batch  160/538 - Train Accuracy: 0.9531, Validation Accuracy: 0.9659, Loss: 0.0279
Epoch   2 Batch  161/538 - Train Accuracy: 0.9471, Validation Accuracy: 0.9668, Loss: 0.0276
Epoch   2 Batch  162/538 - Train Accuracy: 0.9622, Validation Accuracy: 0.9581, Loss: 0.0306
Epoch   2 Batch  163/538 - Train Accuracy: 0.9433, Validation Accuracy: 0.9606, Loss: 0.0389
Epoch   2 Batch  164/538 - Train Accuracy: 0.9617, Validation Accuracy: 0.9590, Loss: 0.0308
Epoch   2 Batch  165/538 - Train Accuracy: 0.9753, Validation Accuracy: 0.9567, Loss: 0.0244
Epoch   2 Batch  166/538 - Train Accuracy: 0.9617, Validation Accuracy: 0.9586, Loss: 0.0301
Epoch   2 Batch  167/538 - Train Accuracy: 0.9613, Validation Accuracy: 0.9604, Loss: 0.0381
Epoch   2 Batch  168/538 - Train Accuracy: 0.9381, Validation Accuracy: 0.9599, Loss: 0.0381
Epoch   2 Batch  169/538 - Train Accuracy: 0.9822, Validation Accuracy: 0.9558, Loss: 0.0256
Epoch   2 Batch  170/538 - Train Accuracy: 0.9617, Validation Accuracy: 0.9533, Loss: 0.0300
Epoch   2 Batch  171/538 - Train Accuracy: 0.9547, Validation Accuracy: 0.9554, Loss: 0.0313
Epoch   2 Batch  172/538 - Train Accuracy: 0.9505, Validation Accuracy: 0.9551, Loss: 0.0268
Epoch   2 Batch  173/538 - Train Accuracy: 0.9678, Validation Accuracy: 0.9462, Loss: 0.0233
Epoch   2 Batch  174/538 - Train Accuracy: 0.9553, Validation Accuracy: 0.9453, Loss: 0.0278
Epoch   2 Batch  175/538 - Train Accuracy: 0.9613, Validation Accuracy: 0.9398, Loss: 0.0274
Epoch   2 Batch  176/538 - Train Accuracy: 0.9588, Validation Accuracy: 0.9391, Loss: 0.0334
Epoch   2 Batch  177/538 - Train Accuracy: 0.9667, Validation Accuracy: 0.9476, Loss: 0.0291
Epoch   2 Batch  178/538 - Train Accuracy: 0.9271, Validation Accuracy: 0.9547, Loss: 0.0338
Epoch   2 Batch  179/538 - Train Accuracy: 0.9600, Validation Accuracy: 0.9547, Loss: 0.0269
Epoch   2 Batch  180/538 - Train Accuracy: 0.9609, Validation Accuracy: 0.9466, Loss: 0.0278
Epoch   2 Batch  181/538 - Train Accuracy: 0.9395, Validation Accuracy: 0.9528, Loss: 0.0364
Epoch   2 Batch  182/538 - Train Accuracy: 0.9674, Validation Accuracy: 0.9542, Loss: 0.0272
Epoch   2 Batch  183/538 - Train Accuracy: 0.9764, Validation Accuracy: 0.9473, Loss: 0.0222
Epoch   2 Batch  184/538 - Train Accuracy: 0.9541, Validation Accuracy: 0.9455, Loss: 0.0313
Epoch   2 Batch  185/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9513, Loss: 0.0238
Epoch   2 Batch  186/538 - Train Accuracy: 0.9609, Validation Accuracy: 0.9538, Loss: 0.0301
Epoch   2 Batch  187/538 - Train Accuracy: 0.9698, Validation Accuracy: 0.9547, Loss: 0.0289
Epoch   2 Batch  188/538 - Train Accuracy: 0.9459, Validation Accuracy: 0.9558, Loss: 0.0261
Epoch   2 Batch  189/538 - Train Accuracy: 0.9701, Validation Accuracy: 0.9581, Loss: 0.0313
Epoch   2 Batch  190/538 - Train Accuracy: 0.9364, Validation Accuracy: 0.9606, Loss: 0.0416
Epoch   2 Batch  191/538 - Train Accuracy: 0.9717, Validation Accuracy: 0.9645, Loss: 0.0253
Epoch   2 Batch  192/538 - Train Accuracy: 0.9663, Validation Accuracy: 0.9640, Loss: 0.0271
Epoch   2 Batch  193/538 - Train Accuracy: 0.9658, Validation Accuracy: 0.9636, Loss: 0.0250
Epoch   2 Batch  194/538 - Train Accuracy: 0.9320, Validation Accuracy: 0.9588, Loss: 0.0343
Epoch   2 Batch  195/538 - Train Accuracy: 0.9756, Validation Accuracy: 0.9606, Loss: 0.0384
Epoch   2 Batch  196/538 - Train Accuracy: 0.9622, Validation Accuracy: 0.9627, Loss: 0.0259
Epoch   2 Batch  197/538 - Train Accuracy: 0.9695, Validation Accuracy: 0.9656, Loss: 0.0282
Epoch   2 Batch  198/538 - Train Accuracy: 0.9533, Validation Accuracy: 0.9673, Loss: 0.0284
Epoch   2 Batch  199/538 - Train Accuracy: 0.9582, Validation Accuracy: 0.9648, Loss: 0.0296
Epoch   2 Batch  200/538 - Train Accuracy: 0.9719, Validation Accuracy: 0.9593, Loss: 0.0233
Epoch   2 Batch  201/538 - Train Accuracy: 0.9641, Validation Accuracy: 0.9537, Loss: 0.0333
Epoch   2 Batch  202/538 - Train Accuracy: 0.9628, Validation Accuracy: 0.9590, Loss: 0.0286
Epoch   2 Batch  203/538 - Train Accuracy: 0.9590, Validation Accuracy: 0.9529, Loss: 0.0307
Epoch   2 Batch  204/538 - Train Accuracy: 0.9412, Validation Accuracy: 0.9512, Loss: 0.0408
Epoch   2 Batch  205/538 - Train Accuracy: 0.9479, Validation Accuracy: 0.9515, Loss: 0.0266
Epoch   2 Batch  206/538 - Train Accuracy: 0.9672, Validation Accuracy: 0.9581, Loss: 0.0248
Epoch   2 Batch  207/538 - Train Accuracy: 0.9663, Validation Accuracy: 0.9668, Loss: 0.0287
Epoch   2 Batch  208/538 - Train Accuracy: 0.9697, Validation Accuracy: 0.9606, Loss: 0.0387
Epoch   2 Batch  209/538 - Train Accuracy: 0.9783, Validation Accuracy: 0.9625, Loss: 0.0267
Epoch   2 Batch  210/538 - Train Accuracy: 0.9461, Validation Accuracy: 0.9648, Loss: 0.0321
Epoch   2 Batch  211/538 - Train Accuracy: 0.9598, Validation Accuracy: 0.9732, Loss: 0.0334
Epoch   2 Batch  212/538 - Train Accuracy: 0.9656, Validation Accuracy: 0.9698, Loss: 0.0257
Epoch   2 Batch  213/538 - Train Accuracy: 0.9648, Validation Accuracy: 0.9661, Loss: 0.0274
Epoch   2 Batch  214/538 - Train Accuracy: 0.9709, Validation Accuracy: 0.9624, Loss: 0.0246
Epoch   2 Batch  215/538 - Train Accuracy: 0.9646, Validation Accuracy: 0.9625, Loss: 0.0253
Epoch   2 Batch  216/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9618, Loss: 0.0334
Epoch   2 Batch  217/538 - Train Accuracy: 0.9585, Validation Accuracy: 0.9673, Loss: 0.0318
Epoch   2 Batch  218/538 - Train Accuracy: 0.9670, Validation Accuracy: 0.9561, Loss: 0.0235
Epoch   2 Batch  219/538 - Train Accuracy: 0.9514, Validation Accuracy: 0.9501, Loss: 0.0339
Epoch   2 Batch  220/538 - Train Accuracy: 0.9518, Validation Accuracy: 0.9554, Loss: 0.0311
Epoch   2 Batch  221/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9627, Loss: 0.0249
Epoch   2 Batch  222/538 - Train Accuracy: 0.9479, Validation Accuracy: 0.9576, Loss: 0.0283
Epoch   2 Batch  223/538 - Train Accuracy: 0.9504, Validation Accuracy: 0.9592, Loss: 0.0293
Epoch   2 Batch  224/538 - Train Accuracy: 0.9578, Validation Accuracy: 0.9595, Loss: 0.0329
Epoch   2 Batch  225/538 - Train Accuracy: 0.9663, Validation Accuracy: 0.9599, Loss: 0.0272
Epoch   2 Batch  226/538 - Train Accuracy: 0.9490, Validation Accuracy: 0.9547, Loss: 0.0299
Epoch   2 Batch  227/538 - Train Accuracy: 0.9506, Validation Accuracy: 0.9545, Loss: 0.0273
Epoch   2 Batch  228/538 - Train Accuracy: 0.9613, Validation Accuracy: 0.9545, Loss: 0.0286
Epoch   2 Batch  229/538 - Train Accuracy: 0.9537, Validation Accuracy: 0.9597, Loss: 0.0308
Epoch   2 Batch  230/538 - Train Accuracy: 0.9672, Validation Accuracy: 0.9570, Loss: 0.0252
Epoch   2 Batch  231/538 - Train Accuracy: 0.9443, Validation Accuracy: 0.9529, Loss: 0.0278
Epoch   2 Batch  232/538 - Train Accuracy: 0.9488, Validation Accuracy: 0.9519, Loss: 0.0294
Epoch   2 Batch  233/538 - Train Accuracy: 0.9656, Validation Accuracy: 0.9499, Loss: 0.0274
Epoch   2 Batch  234/538 - Train Accuracy: 0.9785, Validation Accuracy: 0.9480, Loss: 0.0240
Epoch   2 Batch  235/538 - Train Accuracy: 0.9533, Validation Accuracy: 0.9462, Loss: 0.0271
Epoch   2 Batch  236/538 - Train Accuracy: 0.9479, Validation Accuracy: 0.9451, Loss: 0.0273
Epoch   2 Batch  237/538 - Train Accuracy: 0.9604, Validation Accuracy: 0.9586, Loss: 0.0224
Epoch   2 Batch  238/538 - Train Accuracy: 0.9647, Validation Accuracy: 0.9632, Loss: 0.0256
Epoch   2 Batch  239/538 - Train Accuracy: 0.9615, Validation Accuracy: 0.9490, Loss: 0.0284
Epoch   2 Batch  240/538 - Train Accuracy: 0.9717, Validation Accuracy: 0.9553, Loss: 0.0252
Epoch   2 Batch  241/538 - Train Accuracy: 0.9387, Validation Accuracy: 0.9579, Loss: 0.0355
Epoch   2 Batch  242/538 - Train Accuracy: 0.9656, Validation Accuracy: 0.9551, Loss: 0.0276
Epoch   2 Batch  243/538 - Train Accuracy: 0.9679, Validation Accuracy: 0.9574, Loss: 0.0251
Epoch   2 Batch  244/538 - Train Accuracy: 0.9660, Validation Accuracy: 0.9547, Loss: 0.0229
Epoch   2 Batch  245/538 - Train Accuracy: 0.9598, Validation Accuracy: 0.9533, Loss: 0.0339
Epoch   2 Batch  246/538 - Train Accuracy: 0.9626, Validation Accuracy: 0.9554, Loss: 0.0211
Epoch   2 Batch  247/538 - Train Accuracy: 0.9564, Validation Accuracy: 0.9569, Loss: 0.0288
Epoch   2 Batch  248/538 - Train Accuracy: 0.9580, Validation Accuracy: 0.9611, Loss: 0.0283
Epoch   2 Batch  249/538 - Train Accuracy: 0.9740, Validation Accuracy: 0.9565, Loss: 0.0210
Epoch   2 Batch  250/538 - Train Accuracy: 0.9639, Validation Accuracy: 0.9620, Loss: 0.0247
Epoch   2 Batch  251/538 - Train Accuracy: 0.9688, Validation Accuracy: 0.9613, Loss: 0.0259
Epoch   2 Batch  252/538 - Train Accuracy: 0.9552, Validation Accuracy: 0.9622, Loss: 0.0286
Epoch   2 Batch  253/538 - Train Accuracy: 0.9619, Validation Accuracy: 0.9625, Loss: 0.0246
Epoch   2 Batch  254/538 - Train Accuracy: 0.9561, Validation Accuracy: 0.9581, Loss: 0.0307
Epoch   2 Batch  255/538 - Train Accuracy: 0.9783, Validation Accuracy: 0.9558, Loss: 0.0247
Epoch   2 Batch  256/538 - Train Accuracy: 0.9525, Validation Accuracy: 0.9583, Loss: 0.0306
Epoch   2 Batch  257/538 - Train Accuracy: 0.9647, Validation Accuracy: 0.9560, Loss: 0.0275
Epoch   2 Batch  258/538 - Train Accuracy: 0.9528, Validation Accuracy: 0.9517, Loss: 0.0290
Epoch   2 Batch  259/538 - Train Accuracy: 0.9686, Validation Accuracy: 0.9544, Loss: 0.0245
Epoch   2 Batch  260/538 - Train Accuracy: 0.9375, Validation Accuracy: 0.9574, Loss: 0.0319
Epoch   2 Batch  261/538 - Train Accuracy: 0.9686, Validation Accuracy: 0.9547, Loss: 0.0352
Epoch   2 Batch  262/538 - Train Accuracy: 0.9736, Validation Accuracy: 0.9586, Loss: 0.0269
Epoch   2 Batch  263/538 - Train Accuracy: 0.9521, Validation Accuracy: 0.9561, Loss: 0.0288
Epoch   2 Batch  264/538 - Train Accuracy: 0.9502, Validation Accuracy: 0.9586, Loss: 0.0313
Epoch   2 Batch  265/538 - Train Accuracy: 0.9490, Validation Accuracy: 0.9517, Loss: 0.0311
Epoch   2 Batch  266/538 - Train Accuracy: 0.9505, Validation Accuracy: 0.9505, Loss: 0.0291
Epoch   2 Batch  267/538 - Train Accuracy: 0.9541, Validation Accuracy: 0.9467, Loss: 0.0281
Epoch   2 Batch  268/538 - Train Accuracy: 0.9688, Validation Accuracy: 0.9462, Loss: 0.0226
Epoch   2 Batch  269/538 - Train Accuracy: 0.9633, Validation Accuracy: 0.9510, Loss: 0.0279
Epoch   2 Batch  270/538 - Train Accuracy: 0.9643, Validation Accuracy: 0.9531, Loss: 0.0247
Epoch   2 Batch  271/538 - Train Accuracy: 0.9588, Validation Accuracy: 0.9460, Loss: 0.0228
Epoch   2 Batch  272/538 - Train Accuracy: 0.9629, Validation Accuracy: 0.9485, Loss: 0.0305
Epoch   2 Batch  273/538 - Train Accuracy: 0.9613, Validation Accuracy: 0.9483, Loss: 0.0287
Epoch   2 Batch  274/538 - Train Accuracy: 0.9398, Validation Accuracy: 0.9446, Loss: 0.0312
Epoch   2 Batch  275/538 - Train Accuracy: 0.9570, Validation Accuracy: 0.9537, Loss: 0.0318
Epoch   2 Batch  276/538 - Train Accuracy: 0.9627, Validation Accuracy: 0.9545, Loss: 0.0331
Epoch   2 Batch  277/538 - Train Accuracy: 0.9697, Validation Accuracy: 0.9604, Loss: 0.0243
Epoch   2 Batch  278/538 - Train Accuracy: 0.9607, Validation Accuracy: 0.9590, Loss: 0.0232
Epoch   2 Batch  279/538 - Train Accuracy: 0.9447, Validation Accuracy: 0.9542, Loss: 0.0281
Epoch   2 Batch  280/538 - Train Accuracy: 0.9693, Validation Accuracy: 0.9538, Loss: 0.0240
Epoch   2 Batch  281/538 - Train Accuracy: 0.9629, Validation Accuracy: 0.9604, Loss: 0.0289
Epoch   2 Batch  282/538 - Train Accuracy: 0.9587, Validation Accuracy: 0.9581, Loss: 0.0303
Epoch   2 Batch  283/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9547, Loss: 0.0246
Epoch   2 Batch  284/538 - Train Accuracy: 0.9463, Validation Accuracy: 0.9592, Loss: 0.0318
Epoch   2 Batch  285/538 - Train Accuracy: 0.9613, Validation Accuracy: 0.9664, Loss: 0.0237
Epoch   2 Batch  286/538 - Train Accuracy: 0.9695, Validation Accuracy: 0.9624, Loss: 0.0349
Epoch   2 Batch  287/538 - Train Accuracy: 0.9751, Validation Accuracy: 0.9597, Loss: 0.0180
Epoch   2 Batch  288/538 - Train Accuracy: 0.9475, Validation Accuracy: 0.9586, Loss: 0.0260
Epoch   2 Batch  289/538 - Train Accuracy: 0.9596, Validation Accuracy: 0.9574, Loss: 0.0248
Epoch   2 Batch  290/538 - Train Accuracy: 0.9713, Validation Accuracy: 0.9634, Loss: 0.0219
Epoch   2 Batch  291/538 - Train Accuracy: 0.9641, Validation Accuracy: 0.9684, Loss: 0.0295
Epoch   2 Batch  292/538 - Train Accuracy: 0.9609, Validation Accuracy: 0.9695, Loss: 0.0208
Epoch   2 Batch  293/538 - Train Accuracy: 0.9660, Validation Accuracy: 0.9716, Loss: 0.0252
Epoch   2 Batch  294/538 - Train Accuracy: 0.9589, Validation Accuracy: 0.9654, Loss: 0.0314
Epoch   2 Batch  295/538 - Train Accuracy: 0.9609, Validation Accuracy: 0.9627, Loss: 0.0277
Epoch   2 Batch  296/538 - Train Accuracy: 0.9515, Validation Accuracy: 0.9657, Loss: 0.0383
Epoch   2 Batch  297/538 - Train Accuracy: 0.9666, Validation Accuracy: 0.9638, Loss: 0.0256
Epoch   2 Batch  298/538 - Train Accuracy: 0.9641, Validation Accuracy: 0.9632, Loss: 0.0242
Epoch   2 Batch  299/538 - Train Accuracy: 0.9673, Validation Accuracy: 0.9688, Loss: 0.0310
Epoch   2 Batch  300/538 - Train Accuracy: 0.9518, Validation Accuracy: 0.9641, Loss: 0.0260
Epoch   2 Batch  301/538 - Train Accuracy: 0.9518, Validation Accuracy: 0.9631, Loss: 0.0282
Epoch   2 Batch  302/538 - Train Accuracy: 0.9728, Validation Accuracy: 0.9631, Loss: 0.0291
Epoch   2 Batch  303/538 - Train Accuracy: 0.9668, Validation Accuracy: 0.9615, Loss: 0.0289
Epoch   2 Batch  304/538 - Train Accuracy: 0.9615, Validation Accuracy: 0.9670, Loss: 0.0317
Epoch   2 Batch  305/538 - Train Accuracy: 0.9652, Validation Accuracy: 0.9592, Loss: 0.0247
Epoch   2 Batch  306/538 - Train Accuracy: 0.9643, Validation Accuracy: 0.9640, Loss: 0.0290
Epoch   2 Batch  307/538 - Train Accuracy: 0.9668, Validation Accuracy: 0.9611, Loss: 0.0238
Epoch   2 Batch  308/538 - Train Accuracy: 0.9650, Validation Accuracy: 0.9647, Loss: 0.0263
Epoch   2 Batch  309/538 - Train Accuracy: 0.9695, Validation Accuracy: 0.9677, Loss: 0.0227
Epoch   2 Batch  310/538 - Train Accuracy: 0.9807, Validation Accuracy: 0.9636, Loss: 0.0359
Epoch   2 Batch  311/538 - Train Accuracy: 0.9555, Validation Accuracy: 0.9606, Loss: 0.0267
Epoch   2 Batch  312/538 - Train Accuracy: 0.9629, Validation Accuracy: 0.9636, Loss: 0.0226
Epoch   2 Batch  313/538 - Train Accuracy: 0.9664, Validation Accuracy: 0.9638, Loss: 0.0274
Epoch   2 Batch  314/538 - Train Accuracy: 0.9588, Validation Accuracy: 0.9643, Loss: 0.0308
Epoch   2 Batch  315/538 - Train Accuracy: 0.9634, Validation Accuracy: 0.9592, Loss: 0.0228
Epoch   2 Batch  316/538 - Train Accuracy: 0.9470, Validation Accuracy: 0.9592, Loss: 0.0217
Epoch   2 Batch  317/538 - Train Accuracy: 0.9580, Validation Accuracy: 0.9597, Loss: 0.0272
Epoch   2 Batch  318/538 - Train Accuracy: 0.9676, Validation Accuracy: 0.9563, Loss: 0.0260
Epoch   2 Batch  319/538 - Train Accuracy: 0.9535, Validation Accuracy: 0.9521, Loss: 0.0314
Epoch   2 Batch  320/538 - Train Accuracy: 0.9656, Validation Accuracy: 0.9494, Loss: 0.0243
Epoch   2 Batch  321/538 - Train Accuracy: 0.9639, Validation Accuracy: 0.9570, Loss: 0.0222
Epoch   2 Batch  322/538 - Train Accuracy: 0.9680, Validation Accuracy: 0.9620, Loss: 0.0282
Epoch   2 Batch  323/538 - Train Accuracy: 0.9663, Validation Accuracy: 0.9620, Loss: 0.0222
Epoch   2 Batch  324/538 - Train Accuracy: 0.9711, Validation Accuracy: 0.9656, Loss: 0.0243
Epoch   2 Batch  325/538 - Train Accuracy: 0.9669, Validation Accuracy: 0.9631, Loss: 0.0250
Epoch   2 Batch  326/538 - Train Accuracy: 0.9791, Validation Accuracy: 0.9657, Loss: 0.0261
Epoch   2 Batch  327/538 - Train Accuracy: 0.9668, Validation Accuracy: 0.9645, Loss: 0.0296
Epoch   2 Batch  328/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9604, Loss: 0.0228
Epoch   2 Batch  329/538 - Train Accuracy: 0.9725, Validation Accuracy: 0.9585, Loss: 0.0223
Epoch   2 Batch  330/538 - Train Accuracy: 0.9702, Validation Accuracy: 0.9597, Loss: 0.0237
Epoch   2 Batch  331/538 - Train Accuracy: 0.9639, Validation Accuracy: 0.9650, Loss: 0.0248
Epoch   2 Batch  332/538 - Train Accuracy: 0.9672, Validation Accuracy: 0.9672, Loss: 0.0259
Epoch   2 Batch  333/538 - Train Accuracy: 0.9617, Validation Accuracy: 0.9684, Loss: 0.0308
Epoch   2 Batch  334/538 - Train Accuracy: 0.9743, Validation Accuracy: 0.9759, Loss: 0.0217
Epoch   2 Batch  335/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9746, Loss: 0.0229
Epoch   2 Batch  336/538 - Train Accuracy: 0.9621, Validation Accuracy: 0.9686, Loss: 0.0247
Epoch   2 Batch  337/538 - Train Accuracy: 0.9634, Validation Accuracy: 0.9750, Loss: 0.0261
Epoch   2 Batch  338/538 - Train Accuracy: 0.9661, Validation Accuracy: 0.9712, Loss: 0.0245
Epoch   2 Batch  339/538 - Train Accuracy: 0.9658, Validation Accuracy: 0.9711, Loss: 0.0220
Epoch   2 Batch  340/538 - Train Accuracy: 0.9604, Validation Accuracy: 0.9600, Loss: 0.0247
Epoch   2 Batch  341/538 - Train Accuracy: 0.9658, Validation Accuracy: 0.9638, Loss: 0.0230
Epoch   2 Batch  342/538 - Train Accuracy: 0.9500, Validation Accuracy: 0.9664, Loss: 0.0258
Epoch   2 Batch  343/538 - Train Accuracy: 0.9748, Validation Accuracy: 0.9719, Loss: 0.0239
Epoch   2 Batch  344/538 - Train Accuracy: 0.9529, Validation Accuracy: 0.9696, Loss: 0.0232
Epoch   2 Batch  345/538 - Train Accuracy: 0.9572, Validation Accuracy: 0.9659, Loss: 0.0270
Epoch   2 Batch  346/538 - Train Accuracy: 0.9542, Validation Accuracy: 0.9696, Loss: 0.0296
Epoch   2 Batch  347/538 - Train Accuracy: 0.9750, Validation Accuracy: 0.9640, Loss: 0.0237
Epoch   2 Batch  348/538 - Train Accuracy: 0.9494, Validation Accuracy: 0.9606, Loss: 0.0212
Epoch   2 Batch  349/538 - Train Accuracy: 0.9660, Validation Accuracy: 0.9664, Loss: 0.0179
Epoch   2 Batch  350/538 - Train Accuracy: 0.9635, Validation Accuracy: 0.9650, Loss: 0.0282
Epoch   2 Batch  351/538 - Train Accuracy: 0.9672, Validation Accuracy: 0.9654, Loss: 0.0271
Epoch   2 Batch  352/538 - Train Accuracy: 0.9663, Validation Accuracy: 0.9611, Loss: 0.0407
Epoch   2 Batch  353/538 - Train Accuracy: 0.9592, Validation Accuracy: 0.9625, Loss: 0.0293
Epoch   2 Batch  354/538 - Train Accuracy: 0.9660, Validation Accuracy: 0.9652, Loss: 0.0244
Epoch   2 Batch  355/538 - Train Accuracy: 0.9766, Validation Accuracy: 0.9668, Loss: 0.0225
Epoch   2 Batch  356/538 - Train Accuracy: 0.9725, Validation Accuracy: 0.9663, Loss: 0.0213
Epoch   2 Batch  357/538 - Train Accuracy: 0.9658, Validation Accuracy: 0.9672, Loss: 0.0223
Epoch   2 Batch  358/538 - Train Accuracy: 0.9768, Validation Accuracy: 0.9695, Loss: 0.0183
Epoch   2 Batch  359/538 - Train Accuracy: 0.9648, Validation Accuracy: 0.9632, Loss: 0.0265
Epoch   2 Batch  360/538 - Train Accuracy: 0.9604, Validation Accuracy: 0.9627, Loss: 0.0230
Epoch   2 Batch  361/538 - Train Accuracy: 0.9723, Validation Accuracy: 0.9668, Loss: 0.0253
Epoch   2 Batch  362/538 - Train Accuracy: 0.9699, Validation Accuracy: 0.9645, Loss: 0.0217
Epoch   2 Batch  363/538 - Train Accuracy: 0.9647, Validation Accuracy: 0.9583, Loss: 0.0265
Epoch   2 Batch  364/538 - Train Accuracy: 0.9521, Validation Accuracy: 0.9524, Loss: 0.0308
Epoch   2 Batch  365/538 - Train Accuracy: 0.9589, Validation Accuracy: 0.9581, Loss: 0.0261
Epoch   2 Batch  366/538 - Train Accuracy: 0.9578, Validation Accuracy: 0.9574, Loss: 0.0277
Epoch   2 Batch  367/538 - Train Accuracy: 0.9695, Validation Accuracy: 0.9677, Loss: 0.0239
Epoch   2 Batch  368/538 - Train Accuracy: 0.9757, Validation Accuracy: 0.9663, Loss: 0.0207
Epoch   2 Batch  369/538 - Train Accuracy: 0.9586, Validation Accuracy: 0.9666, Loss: 0.0231
Epoch   2 Batch  370/538 - Train Accuracy: 0.9637, Validation Accuracy: 0.9640, Loss: 0.0266
Epoch   2 Batch  371/538 - Train Accuracy: 0.9719, Validation Accuracy: 0.9620, Loss: 0.0265
Epoch   2 Batch  372/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9684, Loss: 0.0255
Epoch   2 Batch  373/538 - Train Accuracy: 0.9637, Validation Accuracy: 0.9625, Loss: 0.0220
Epoch   2 Batch  374/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9528, Loss: 0.0224
Epoch   2 Batch  375/538 - Train Accuracy: 0.9736, Validation Accuracy: 0.9556, Loss: 0.0232
Epoch   2 Batch  376/538 - Train Accuracy: 0.9645, Validation Accuracy: 0.9496, Loss: 0.0251
Epoch   2 Batch  377/538 - Train Accuracy: 0.9633, Validation Accuracy: 0.9563, Loss: 0.0239
Epoch   2 Batch  378/538 - Train Accuracy: 0.9643, Validation Accuracy: 0.9565, Loss: 0.0205
Epoch   2 Batch  379/538 - Train Accuracy: 0.9643, Validation Accuracy: 0.9556, Loss: 0.0265
Epoch   2 Batch  380/538 - Train Accuracy: 0.9693, Validation Accuracy: 0.9556, Loss: 0.0210
Epoch   2 Batch  381/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9625, Loss: 0.0211
Epoch   2 Batch  382/538 - Train Accuracy: 0.9561, Validation Accuracy: 0.9609, Loss: 0.0291
Epoch   2 Batch  383/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9625, Loss: 0.0247
Epoch   2 Batch  384/538 - Train Accuracy: 0.9734, Validation Accuracy: 0.9599, Loss: 0.0239
Epoch   2 Batch  385/538 - Train Accuracy: 0.9622, Validation Accuracy: 0.9640, Loss: 0.0257
Epoch   2 Batch  386/538 - Train Accuracy: 0.9768, Validation Accuracy: 0.9636, Loss: 0.0223
Epoch   2 Batch  387/538 - Train Accuracy: 0.9621, Validation Accuracy: 0.9650, Loss: 0.0239
Epoch   2 Batch  388/538 - Train Accuracy: 0.9771, Validation Accuracy: 0.9597, Loss: 0.0219
Epoch   2 Batch  389/538 - Train Accuracy: 0.9549, Validation Accuracy: 0.9537, Loss: 0.0288
Epoch   2 Batch  390/538 - Train Accuracy: 0.9665, Validation Accuracy: 0.9480, Loss: 0.0210
Epoch   2 Batch  391/538 - Train Accuracy: 0.9598, Validation Accuracy: 0.9544, Loss: 0.0242
Epoch   2 Batch  392/538 - Train Accuracy: 0.9695, Validation Accuracy: 0.9554, Loss: 0.0213
Epoch   2 Batch  393/538 - Train Accuracy: 0.9661, Validation Accuracy: 0.9576, Loss: 0.0260
Epoch   2 Batch  394/538 - Train Accuracy: 0.9615, Validation Accuracy: 0.9634, Loss: 0.0272
Epoch   2 Batch  395/538 - Train Accuracy: 0.9584, Validation Accuracy: 0.9654, Loss: 0.0271
Epoch   2 Batch  396/538 - Train Accuracy: 0.9596, Validation Accuracy: 0.9677, Loss: 0.0214
Epoch   2 Batch  397/538 - Train Accuracy: 0.9713, Validation Accuracy: 0.9613, Loss: 0.0252
Epoch   2 Batch  398/538 - Train Accuracy: 0.9723, Validation Accuracy: 0.9641, Loss: 0.0248
Epoch   2 Batch  399/538 - Train Accuracy: 0.9637, Validation Accuracy: 0.9606, Loss: 0.0294
Epoch   2 Batch  400/538 - Train Accuracy: 0.9702, Validation Accuracy: 0.9556, Loss: 0.0243
Epoch   2 Batch  401/538 - Train Accuracy: 0.9838, Validation Accuracy: 0.9547, Loss: 0.0208
Epoch   2 Batch  402/538 - Train Accuracy: 0.9627, Validation Accuracy: 0.9567, Loss: 0.0251
Epoch   2 Batch  403/538 - Train Accuracy: 0.9643, Validation Accuracy: 0.9522, Loss: 0.0281
Epoch   2 Batch  404/538 - Train Accuracy: 0.9730, Validation Accuracy: 0.9560, Loss: 0.0242
Epoch   2 Batch  405/538 - Train Accuracy: 0.9725, Validation Accuracy: 0.9624, Loss: 0.0219
Epoch   2 Batch  406/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9604, Loss: 0.0234
Epoch   2 Batch  407/538 - Train Accuracy: 0.9773, Validation Accuracy: 0.9576, Loss: 0.0277
Epoch   2 Batch  408/538 - Train Accuracy: 0.9496, Validation Accuracy: 0.9577, Loss: 0.0281
Epoch   2 Batch  409/538 - Train Accuracy: 0.9578, Validation Accuracy: 0.9588, Loss: 0.0239
Epoch   2 Batch  410/538 - Train Accuracy: 0.9748, Validation Accuracy: 0.9609, Loss: 0.0237
Epoch   2 Batch  411/538 - Train Accuracy: 0.9691, Validation Accuracy: 0.9581, Loss: 0.0286
Epoch   2 Batch  412/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9545, Loss: 0.0189
Epoch   2 Batch  413/538 - Train Accuracy: 0.9650, Validation Accuracy: 0.9510, Loss: 0.0237
Epoch   2 Batch  414/538 - Train Accuracy: 0.9434, Validation Accuracy: 0.9542, Loss: 0.0329
Epoch   2 Batch  415/538 - Train Accuracy: 0.9553, Validation Accuracy: 0.9554, Loss: 0.0254
Epoch   2 Batch  416/538 - Train Accuracy: 0.9609, Validation Accuracy: 0.9570, Loss: 0.0290
Epoch   2 Batch  417/538 - Train Accuracy: 0.9807, Validation Accuracy: 0.9569, Loss: 0.0226
Epoch   2 Batch  418/538 - Train Accuracy: 0.9727, Validation Accuracy: 0.9540, Loss: 0.0269
Epoch   2 Batch  419/538 - Train Accuracy: 0.9701, Validation Accuracy: 0.9616, Loss: 0.0223
Epoch   2 Batch  420/538 - Train Accuracy: 0.9658, Validation Accuracy: 0.9604, Loss: 0.0305
Epoch   2 Batch  421/538 - Train Accuracy: 0.9526, Validation Accuracy: 0.9638, Loss: 0.0234
Epoch   2 Batch  422/538 - Train Accuracy: 0.9617, Validation Accuracy: 0.9636, Loss: 0.0265
Epoch   2 Batch  423/538 - Train Accuracy: 0.9705, Validation Accuracy: 0.9659, Loss: 0.0252
Epoch   2 Batch  424/538 - Train Accuracy: 0.9492, Validation Accuracy: 0.9654, Loss: 0.0280
Epoch   2 Batch  425/538 - Train Accuracy: 0.9585, Validation Accuracy: 0.9588, Loss: 0.0360
Epoch   2 Batch  426/538 - Train Accuracy: 0.9479, Validation Accuracy: 0.9611, Loss: 0.0298
Epoch   2 Batch  427/538 - Train Accuracy: 0.9662, Validation Accuracy: 0.9572, Loss: 0.0257
Epoch   2 Batch  428/538 - Train Accuracy: 0.9730, Validation Accuracy: 0.9529, Loss: 0.0178
Epoch   2 Batch  429/538 - Train Accuracy: 0.9701, Validation Accuracy: 0.9569, Loss: 0.0233
Epoch   2 Batch  430/538 - Train Accuracy: 0.9646, Validation Accuracy: 0.9508, Loss: 0.0238
Epoch   2 Batch  431/538 - Train Accuracy: 0.9590, Validation Accuracy: 0.9494, Loss: 0.0233
Epoch   2 Batch  432/538 - Train Accuracy: 0.9476, Validation Accuracy: 0.9549, Loss: 0.0290
Epoch   2 Batch  433/538 - Train Accuracy: 0.9551, Validation Accuracy: 0.9602, Loss: 0.0454
Epoch   2 Batch  434/538 - Train Accuracy: 0.9574, Validation Accuracy: 0.9586, Loss: 0.0219
Epoch   2 Batch  435/538 - Train Accuracy: 0.9645, Validation Accuracy: 0.9624, Loss: 0.0249
Epoch   2 Batch  436/538 - Train Accuracy: 0.9518, Validation Accuracy: 0.9629, Loss: 0.0279
Epoch   2 Batch  437/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9670, Loss: 0.0228
Epoch   2 Batch  438/538 - Train Accuracy: 0.9699, Validation Accuracy: 0.9709, Loss: 0.0224
Epoch   2 Batch  439/538 - Train Accuracy: 0.9842, Validation Accuracy: 0.9608, Loss: 0.0242
Epoch   2 Batch  440/538 - Train Accuracy: 0.9676, Validation Accuracy: 0.9618, Loss: 0.0247
Epoch   2 Batch  441/538 - Train Accuracy: 0.9553, Validation Accuracy: 0.9629, Loss: 0.0309
Epoch   2 Batch  442/538 - Train Accuracy: 0.9702, Validation Accuracy: 0.9583, Loss: 0.0198
Epoch   2 Batch  443/538 - Train Accuracy: 0.9621, Validation Accuracy: 0.9657, Loss: 0.0245
Epoch   2 Batch  444/538 - Train Accuracy: 0.9555, Validation Accuracy: 0.9478, Loss: 0.0246
Epoch   2 Batch  445/538 - Train Accuracy: 0.9699, Validation Accuracy: 0.9485, Loss: 0.0202
Epoch   2 Batch  446/538 - Train Accuracy: 0.9626, Validation Accuracy: 0.9533, Loss: 0.0206
Epoch   2 Batch  447/538 - Train Accuracy: 0.9590, Validation Accuracy: 0.9599, Loss: 0.0247
Epoch   2 Batch  448/538 - Train Accuracy: 0.9676, Validation Accuracy: 0.9689, Loss: 0.0226
Epoch   2 Batch  449/538 - Train Accuracy: 0.9775, Validation Accuracy: 0.9677, Loss: 0.0276
Epoch   2 Batch  450/538 - Train Accuracy: 0.9542, Validation Accuracy: 0.9643, Loss: 0.0305
Epoch   2 Batch  451/538 - Train Accuracy: 0.9479, Validation Accuracy: 0.9657, Loss: 0.0241
Epoch   2 Batch  452/538 - Train Accuracy: 0.9750, Validation Accuracy: 0.9643, Loss: 0.0223
Epoch   2 Batch  453/538 - Train Accuracy: 0.9646, Validation Accuracy: 0.9631, Loss: 0.0274
Epoch   2 Batch  454/538 - Train Accuracy: 0.9693, Validation Accuracy: 0.9542, Loss: 0.0289
Epoch   2 Batch  455/538 - Train Accuracy: 0.9776, Validation Accuracy: 0.9499, Loss: 0.0252
Epoch   2 Batch  456/538 - Train Accuracy: 0.9740, Validation Accuracy: 0.9508, Loss: 0.0318
Epoch   2 Batch  457/538 - Train Accuracy: 0.9666, Validation Accuracy: 0.9524, Loss: 0.0207
Epoch   2 Batch  458/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9544, Loss: 0.0233
Epoch   2 Batch  459/538 - Train Accuracy: 0.9717, Validation Accuracy: 0.9510, Loss: 0.0187
Epoch   2 Batch  460/538 - Train Accuracy: 0.9637, Validation Accuracy: 0.9545, Loss: 0.0227
Epoch   2 Batch  461/538 - Train Accuracy: 0.9704, Validation Accuracy: 0.9519, Loss: 0.0259
Epoch   2 Batch  462/538 - Train Accuracy: 0.9669, Validation Accuracy: 0.9574, Loss: 0.0210
Epoch   2 Batch  463/538 - Train Accuracy: 0.9572, Validation Accuracy: 0.9638, Loss: 0.0285
Epoch   2 Batch  464/538 - Train Accuracy: 0.9615, Validation Accuracy: 0.9618, Loss: 0.0225
Epoch   2 Batch  465/538 - Train Accuracy: 0.9602, Validation Accuracy: 0.9542, Loss: 0.0228
Epoch   2 Batch  466/538 - Train Accuracy: 0.9648, Validation Accuracy: 0.9535, Loss: 0.0239
Epoch   2 Batch  467/538 - Train Accuracy: 0.9732, Validation Accuracy: 0.9547, Loss: 0.0244
Epoch   2 Batch  468/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9551, Loss: 0.0294
Epoch   2 Batch  469/538 - Train Accuracy: 0.9615, Validation Accuracy: 0.9604, Loss: 0.0252
Epoch   2 Batch  470/538 - Train Accuracy: 0.9665, Validation Accuracy: 0.9696, Loss: 0.0245
Epoch   2 Batch  471/538 - Train Accuracy: 0.9769, Validation Accuracy: 0.9689, Loss: 0.0195
Epoch   2 Batch  472/538 - Train Accuracy: 0.9943, Validation Accuracy: 0.9707, Loss: 0.0168
Epoch   2 Batch  473/538 - Train Accuracy: 0.9586, Validation Accuracy: 0.9700, Loss: 0.0242
Epoch   2 Batch  474/538 - Train Accuracy: 0.9658, Validation Accuracy: 0.9725, Loss: 0.0210
Epoch   2 Batch  475/538 - Train Accuracy: 0.9790, Validation Accuracy: 0.9702, Loss: 0.0201
Epoch   2 Batch  476/538 - Train Accuracy: 0.9787, Validation Accuracy: 0.9728, Loss: 0.0236
Epoch   2 Batch  477/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9657, Loss: 0.0273
Epoch   2 Batch  478/538 - Train Accuracy: 0.9795, Validation Accuracy: 0.9528, Loss: 0.0179
Epoch   2 Batch  479/538 - Train Accuracy: 0.9552, Validation Accuracy: 0.9469, Loss: 0.0272
Epoch   2 Batch  480/538 - Train Accuracy: 0.9688, Validation Accuracy: 0.9467, Loss: 0.0226
Epoch   2 Batch  481/538 - Train Accuracy: 0.9702, Validation Accuracy: 0.9510, Loss: 0.0260
Epoch   2 Batch  482/538 - Train Accuracy: 0.9620, Validation Accuracy: 0.9592, Loss: 0.0193
Epoch   2 Batch  483/538 - Train Accuracy: 0.9602, Validation Accuracy: 0.9624, Loss: 0.0254
Epoch   2 Batch  484/538 - Train Accuracy: 0.9572, Validation Accuracy: 0.9640, Loss: 0.0269
Epoch   2 Batch  485/538 - Train Accuracy: 0.9706, Validation Accuracy: 0.9663, Loss: 0.0283
Epoch   2 Batch  486/538 - Train Accuracy: 0.9784, Validation Accuracy: 0.9679, Loss: 0.0179
Epoch   2 Batch  487/538 - Train Accuracy: 0.9634, Validation Accuracy: 0.9711, Loss: 0.0201
Epoch   2 Batch  488/538 - Train Accuracy: 0.9768, Validation Accuracy: 0.9673, Loss: 0.0176
Epoch   2 Batch  489/538 - Train Accuracy: 0.9645, Validation Accuracy: 0.9620, Loss: 0.0251
Epoch   2 Batch  490/538 - Train Accuracy: 0.9591, Validation Accuracy: 0.9608, Loss: 0.0217
Epoch   2 Batch  491/538 - Train Accuracy: 0.9443, Validation Accuracy: 0.9609, Loss: 0.0279
Epoch   2 Batch  492/538 - Train Accuracy: 0.9695, Validation Accuracy: 0.9609, Loss: 0.0215
Epoch   2 Batch  493/538 - Train Accuracy: 0.9628, Validation Accuracy: 0.9611, Loss: 0.0230
Epoch   2 Batch  494/538 - Train Accuracy: 0.9646, Validation Accuracy: 0.9581, Loss: 0.0271
Epoch   2 Batch  495/538 - Train Accuracy: 0.9594, Validation Accuracy: 0.9574, Loss: 0.0254
Epoch   2 Batch  496/538 - Train Accuracy: 0.9773, Validation Accuracy: 0.9579, Loss: 0.0189
Epoch   2 Batch  497/538 - Train Accuracy: 0.9741, Validation Accuracy: 0.9604, Loss: 0.0199
Epoch   2 Batch  498/538 - Train Accuracy: 0.9719, Validation Accuracy: 0.9604, Loss: 0.0220
Epoch   2 Batch  499/538 - Train Accuracy: 0.9613, Validation Accuracy: 0.9647, Loss: 0.0233
Epoch   2 Batch  500/538 - Train Accuracy: 0.9838, Validation Accuracy: 0.9659, Loss: 0.0166
Epoch   2 Batch  501/538 - Train Accuracy: 0.9686, Validation Accuracy: 0.9636, Loss: 0.0248
Epoch   2 Batch  502/538 - Train Accuracy: 0.9486, Validation Accuracy: 0.9696, Loss: 0.0235
Epoch   2 Batch  503/538 - Train Accuracy: 0.9691, Validation Accuracy: 0.9680, Loss: 0.0234
Epoch   2 Batch  504/538 - Train Accuracy: 0.9832, Validation Accuracy: 0.9663, Loss: 0.0156
Epoch   2 Batch  505/538 - Train Accuracy: 0.9634, Validation Accuracy: 0.9663, Loss: 0.0144
Epoch   2 Batch  506/538 - Train Accuracy: 0.9794, Validation Accuracy: 0.9688, Loss: 0.0178
Epoch   2 Batch  507/538 - Train Accuracy: 0.9574, Validation Accuracy: 0.9688, Loss: 0.0240
Epoch   2 Batch  508/538 - Train Accuracy: 0.9680, Validation Accuracy: 0.9664, Loss: 0.0213
Epoch   2 Batch  509/538 - Train Accuracy: 0.9705, Validation Accuracy: 0.9700, Loss: 0.0248
Epoch   2 Batch  510/538 - Train Accuracy: 0.9702, Validation Accuracy: 0.9696, Loss: 0.0208
Epoch   2 Batch  511/538 - Train Accuracy: 0.9599, Validation Accuracy: 0.9698, Loss: 0.0243
Epoch   2 Batch  512/538 - Train Accuracy: 0.9723, Validation Accuracy: 0.9727, Loss: 0.0288
Epoch   2 Batch  513/538 - Train Accuracy: 0.9650, Validation Accuracy: 0.9725, Loss: 0.0196
Epoch   2 Batch  514/538 - Train Accuracy: 0.9680, Validation Accuracy: 0.9714, Loss: 0.0225
Epoch   2 Batch  515/538 - Train Accuracy: 0.9665, Validation Accuracy: 0.9684, Loss: 0.0265
Epoch   2 Batch  516/538 - Train Accuracy: 0.9684, Validation Accuracy: 0.9723, Loss: 0.0236
Epoch   2 Batch  517/538 - Train Accuracy: 0.9775, Validation Accuracy: 0.9753, Loss: 0.0196
Epoch   2 Batch  518/538 - Train Accuracy: 0.9803, Validation Accuracy: 0.9725, Loss: 0.0275
Epoch   2 Batch  519/538 - Train Accuracy: 0.9719, Validation Accuracy: 0.9640, Loss: 0.0217
Epoch   2 Batch  520/538 - Train Accuracy: 0.9689, Validation Accuracy: 0.9600, Loss: 0.0266
Epoch   2 Batch  521/538 - Train Accuracy: 0.9723, Validation Accuracy: 0.9554, Loss: 0.0267
Epoch   2 Batch  522/538 - Train Accuracy: 0.9727, Validation Accuracy: 0.9659, Loss: 0.0199
Epoch   2 Batch  523/538 - Train Accuracy: 0.9740, Validation Accuracy: 0.9659, Loss: 0.0253
Epoch   2 Batch  524/538 - Train Accuracy: 0.9689, Validation Accuracy: 0.9672, Loss: 0.0211
Epoch   2 Batch  525/538 - Train Accuracy: 0.9606, Validation Accuracy: 0.9654, Loss: 0.0238
Epoch   2 Batch  526/538 - Train Accuracy: 0.9645, Validation Accuracy: 0.9654, Loss: 0.0229
Epoch   2 Batch  527/538 - Train Accuracy: 0.9699, Validation Accuracy: 0.9625, Loss: 0.0221
Epoch   2 Batch  528/538 - Train Accuracy: 0.9735, Validation Accuracy: 0.9595, Loss: 0.0296
Epoch   2 Batch  529/538 - Train Accuracy: 0.9545, Validation Accuracy: 0.9609, Loss: 0.0257
Epoch   2 Batch  530/538 - Train Accuracy: 0.9523, Validation Accuracy: 0.9689, Loss: 0.0278
Epoch   2 Batch  531/538 - Train Accuracy: 0.9674, Validation Accuracy: 0.9709, Loss: 0.0251
Epoch   2 Batch  532/538 - Train Accuracy: 0.9643, Validation Accuracy: 0.9688, Loss: 0.0185
Epoch   2 Batch  533/538 - Train Accuracy: 0.9723, Validation Accuracy: 0.9691, Loss: 0.0178
Epoch   2 Batch  534/538 - Train Accuracy: 0.9710, Validation Accuracy: 0.9664, Loss: 0.0168
Epoch   2 Batch  535/538 - Train Accuracy: 0.9643, Validation Accuracy: 0.9673, Loss: 0.0226
Epoch   2 Batch  536/538 - Train Accuracy: 0.9753, Validation Accuracy: 0.9650, Loss: 0.0243
Epoch   3 Batch    0/538 - Train Accuracy: 0.9680, Validation Accuracy: 0.9632, Loss: 0.0186
Epoch   3 Batch    1/538 - Train Accuracy: 0.9787, Validation Accuracy: 0.9631, Loss: 0.0221
Epoch   3 Batch    2/538 - Train Accuracy: 0.9742, Validation Accuracy: 0.9629, Loss: 0.0239
Epoch   3 Batch    3/538 - Train Accuracy: 0.9828, Validation Accuracy: 0.9679, Loss: 0.0190
Epoch   3 Batch    4/538 - Train Accuracy: 0.9811, Validation Accuracy: 0.9689, Loss: 0.0209
Epoch   3 Batch    5/538 - Train Accuracy: 0.9656, Validation Accuracy: 0.9640, Loss: 0.0256
Epoch   3 Batch    6/538 - Train Accuracy: 0.9686, Validation Accuracy: 0.9622, Loss: 0.0194
Epoch   3 Batch    7/538 - Train Accuracy: 0.9789, Validation Accuracy: 0.9604, Loss: 0.0196
Epoch   3 Batch    8/538 - Train Accuracy: 0.9738, Validation Accuracy: 0.9656, Loss: 0.0224
Epoch   3 Batch    9/538 - Train Accuracy: 0.9637, Validation Accuracy: 0.9645, Loss: 0.0200
Epoch   3 Batch   10/538 - Train Accuracy: 0.9625, Validation Accuracy: 0.9613, Loss: 0.0239
Epoch   3 Batch   11/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9600, Loss: 0.0218
Epoch   3 Batch   12/538 - Train Accuracy: 0.9672, Validation Accuracy: 0.9574, Loss: 0.0223
Epoch   3 Batch   13/538 - Train Accuracy: 0.9827, Validation Accuracy: 0.9602, Loss: 0.0188
Epoch   3 Batch   14/538 - Train Accuracy: 0.9662, Validation Accuracy: 0.9631, Loss: 0.0200
Epoch   3 Batch   15/538 - Train Accuracy: 0.9678, Validation Accuracy: 0.9688, Loss: 0.0205
Epoch   3 Batch   16/538 - Train Accuracy: 0.9708, Validation Accuracy: 0.9695, Loss: 0.0214
Epoch   3 Batch   17/538 - Train Accuracy: 0.9768, Validation Accuracy: 0.9684, Loss: 0.0212
Epoch   3 Batch   18/538 - Train Accuracy: 0.9643, Validation Accuracy: 0.9691, Loss: 0.0337
Epoch   3 Batch   19/538 - Train Accuracy: 0.9686, Validation Accuracy: 0.9666, Loss: 0.0242
Epoch   3 Batch   20/538 - Train Accuracy: 0.9727, Validation Accuracy: 0.9549, Loss: 0.0244
Epoch   3 Batch   21/538 - Train Accuracy: 0.9801, Validation Accuracy: 0.9567, Loss: 0.0140
Epoch   3 Batch   22/538 - Train Accuracy: 0.9639, Validation Accuracy: 0.9576, Loss: 0.0227
Epoch   3 Batch   23/538 - Train Accuracy: 0.9629, Validation Accuracy: 0.9663, Loss: 0.0271
Epoch   3 Batch   24/538 - Train Accuracy: 0.9671, Validation Accuracy: 0.9673, Loss: 0.0238
Epoch   3 Batch   25/538 - Train Accuracy: 0.9525, Validation Accuracy: 0.9650, Loss: 0.0256
Epoch   3 Batch   26/538 - Train Accuracy: 0.9602, Validation Accuracy: 0.9661, Loss: 0.0277
Epoch   3 Batch   27/538 - Train Accuracy: 0.9686, Validation Accuracy: 0.9629, Loss: 0.0195
Epoch   3 Batch   28/538 - Train Accuracy: 0.9608, Validation Accuracy: 0.9618, Loss: 0.0224
Epoch   3 Batch   29/538 - Train Accuracy: 0.9658, Validation Accuracy: 0.9577, Loss: 0.0171
Epoch   3 Batch   30/538 - Train Accuracy: 0.9631, Validation Accuracy: 0.9529, Loss: 0.0233
Epoch   3 Batch   31/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9551, Loss: 0.0179
Epoch   3 Batch   32/538 - Train Accuracy: 0.9825, Validation Accuracy: 0.9561, Loss: 0.0145
Epoch   3 Batch   33/538 - Train Accuracy: 0.9462, Validation Accuracy: 0.9602, Loss: 0.0276
Epoch   3 Batch   34/538 - Train Accuracy: 0.9570, Validation Accuracy: 0.9627, Loss: 0.0282
Epoch   3 Batch   35/538 - Train Accuracy: 0.9752, Validation Accuracy: 0.9616, Loss: 0.0177
Epoch   3 Batch   36/538 - Train Accuracy: 0.9719, Validation Accuracy: 0.9629, Loss: 0.0206
Epoch   3 Batch   37/538 - Train Accuracy: 0.9656, Validation Accuracy: 0.9609, Loss: 0.0250
Epoch   3 Batch   38/538 - Train Accuracy: 0.9732, Validation Accuracy: 0.9672, Loss: 0.0229
Epoch   3 Batch   39/538 - Train Accuracy: 0.9713, Validation Accuracy: 0.9641, Loss: 0.0197
Epoch   3 Batch   40/538 - Train Accuracy: 0.9714, Validation Accuracy: 0.9650, Loss: 0.0163
Epoch   3 Batch   41/538 - Train Accuracy: 0.9729, Validation Accuracy: 0.9645, Loss: 0.0203
Epoch   3 Batch   42/538 - Train Accuracy: 0.9707, Validation Accuracy: 0.9659, Loss: 0.0179
Epoch   3 Batch   43/538 - Train Accuracy: 0.9563, Validation Accuracy: 0.9668, Loss: 0.0290
Epoch   3 Batch   44/538 - Train Accuracy: 0.9643, Validation Accuracy: 0.9652, Loss: 0.0218
Epoch   3 Batch   45/538 - Train Accuracy: 0.9622, Validation Accuracy: 0.9650, Loss: 0.0215
Epoch   3 Batch   46/538 - Train Accuracy: 0.9771, Validation Accuracy: 0.9659, Loss: 0.0183
Epoch   3 Batch   47/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9592, Loss: 0.0224
Epoch   3 Batch   48/538 - Train Accuracy: 0.9498, Validation Accuracy: 0.9574, Loss: 0.0224
Epoch   3 Batch   49/538 - Train Accuracy: 0.9783, Validation Accuracy: 0.9618, Loss: 0.0194
Epoch   3 Batch   50/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9680, Loss: 0.0176
Epoch   3 Batch   51/538 - Train Accuracy: 0.9700, Validation Accuracy: 0.9632, Loss: 0.0236
Epoch   3 Batch   52/538 - Train Accuracy: 0.9723, Validation Accuracy: 0.9663, Loss: 0.0199
Epoch   3 Batch   53/538 - Train Accuracy: 0.9579, Validation Accuracy: 0.9631, Loss: 0.0223
Epoch   3 Batch   54/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9553, Loss: 0.0173
Epoch   3 Batch   55/538 - Train Accuracy: 0.9602, Validation Accuracy: 0.9567, Loss: 0.0196
Epoch   3 Batch   56/538 - Train Accuracy: 0.9684, Validation Accuracy: 0.9613, Loss: 0.0210
Epoch   3 Batch   57/538 - Train Accuracy: 0.9428, Validation Accuracy: 0.9613, Loss: 0.0280
Epoch   3 Batch   58/538 - Train Accuracy: 0.9721, Validation Accuracy: 0.9606, Loss: 0.0181
Epoch   3 Batch   59/538 - Train Accuracy: 0.9639, Validation Accuracy: 0.9664, Loss: 0.0254
Epoch   3 Batch   60/538 - Train Accuracy: 0.9775, Validation Accuracy: 0.9719, Loss: 0.0226
Epoch   3 Batch   61/538 - Train Accuracy: 0.9652, Validation Accuracy: 0.9696, Loss: 0.0222
Epoch   3 Batch   62/538 - Train Accuracy: 0.9660, Validation Accuracy: 0.9577, Loss: 0.0240
Epoch   3 Batch   63/538 - Train Accuracy: 0.9823, Validation Accuracy: 0.9588, Loss: 0.0202
Epoch   3 Batch   64/538 - Train Accuracy: 0.9600, Validation Accuracy: 0.9545, Loss: 0.0211
Epoch   3 Batch   65/538 - Train Accuracy: 0.9574, Validation Accuracy: 0.9638, Loss: 0.0234
Epoch   3 Batch   66/538 - Train Accuracy: 0.9740, Validation Accuracy: 0.9563, Loss: 0.0164
Epoch   3 Batch   67/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9588, Loss: 0.0211
Epoch   3 Batch   68/538 - Train Accuracy: 0.9634, Validation Accuracy: 0.9695, Loss: 0.0198
Epoch   3 Batch   69/538 - Train Accuracy: 0.9688, Validation Accuracy: 0.9648, Loss: 0.0184
Epoch   3 Batch   70/538 - Train Accuracy: 0.9695, Validation Accuracy: 0.9565, Loss: 0.0159
Epoch   3 Batch   71/538 - Train Accuracy: 0.9686, Validation Accuracy: 0.9545, Loss: 0.0253
Epoch   3 Batch   72/538 - Train Accuracy: 0.9656, Validation Accuracy: 0.9524, Loss: 0.0306
Epoch   3 Batch   73/538 - Train Accuracy: 0.9621, Validation Accuracy: 0.9560, Loss: 0.0259
Epoch   3 Batch   74/538 - Train Accuracy: 0.9660, Validation Accuracy: 0.9620, Loss: 0.0217
Epoch   3 Batch   75/538 - Train Accuracy: 0.9576, Validation Accuracy: 0.9560, Loss: 0.0226
Epoch   3 Batch   76/538 - Train Accuracy: 0.9664, Validation Accuracy: 0.9528, Loss: 0.0217
Epoch   3 Batch   77/538 - Train Accuracy: 0.9615, Validation Accuracy: 0.9547, Loss: 0.0199
Epoch   3 Batch   78/538 - Train Accuracy: 0.9609, Validation Accuracy: 0.9588, Loss: 0.0222
Epoch   3 Batch   79/538 - Train Accuracy: 0.9680, Validation Accuracy: 0.9673, Loss: 0.0170
Epoch   3 Batch   80/538 - Train Accuracy: 0.9658, Validation Accuracy: 0.9689, Loss: 0.0185
Epoch   3 Batch   81/538 - Train Accuracy: 0.9719, Validation Accuracy: 0.9743, Loss: 0.0242
Epoch   3 Batch   82/538 - Train Accuracy: 0.9656, Validation Accuracy: 0.9723, Loss: 0.0236
Epoch   3 Batch   83/538 - Train Accuracy: 0.9553, Validation Accuracy: 0.9663, Loss: 0.0236
Epoch   3 Batch   84/538 - Train Accuracy: 0.9550, Validation Accuracy: 0.9689, Loss: 0.0242
Epoch   3 Batch   85/538 - Train Accuracy: 0.9854, Validation Accuracy: 0.9618, Loss: 0.0163
Epoch   3 Batch   86/538 - Train Accuracy: 0.9705, Validation Accuracy: 0.9535, Loss: 0.0187
Epoch   3 Batch   87/538 - Train Accuracy: 0.9615, Validation Accuracy: 0.9519, Loss: 0.0225
Epoch   3 Batch   88/538 - Train Accuracy: 0.9725, Validation Accuracy: 0.9625, Loss: 0.0226
Epoch   3 Batch   89/538 - Train Accuracy: 0.9795, Validation Accuracy: 0.9515, Loss: 0.0192
Epoch   3 Batch   90/538 - Train Accuracy: 0.9663, Validation Accuracy: 0.9561, Loss: 0.0271
Epoch   3 Batch   91/538 - Train Accuracy: 0.9600, Validation Accuracy: 0.9567, Loss: 0.0265
Epoch   3 Batch   92/538 - Train Accuracy: 0.9646, Validation Accuracy: 0.9606, Loss: 0.0201
Epoch   3 Batch   93/538 - Train Accuracy: 0.9627, Validation Accuracy: 0.9597, Loss: 0.0193
Epoch   3 Batch   94/538 - Train Accuracy: 0.9701, Validation Accuracy: 0.9638, Loss: 0.0174
Epoch   3 Batch   95/538 - Train Accuracy: 0.9553, Validation Accuracy: 0.9663, Loss: 0.0194
Epoch   3 Batch   96/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9661, Loss: 0.0166
Epoch   3 Batch   97/538 - Train Accuracy: 0.9693, Validation Accuracy: 0.9673, Loss: 0.0171
Epoch   3 Batch   98/538 - Train Accuracy: 0.9773, Validation Accuracy: 0.9668, Loss: 0.0233
Epoch   3 Batch   99/538 - Train Accuracy: 0.9695, Validation Accuracy: 0.9711, Loss: 0.0192
Epoch   3 Batch  100/538 - Train Accuracy: 0.9816, Validation Accuracy: 0.9698, Loss: 0.0176
Epoch   3 Batch  101/538 - Train Accuracy: 0.9479, Validation Accuracy: 0.9677, Loss: 0.0314
Epoch   3 Batch  102/538 - Train Accuracy: 0.9549, Validation Accuracy: 0.9650, Loss: 0.0267
Epoch   3 Batch  103/538 - Train Accuracy: 0.9689, Validation Accuracy: 0.9645, Loss: 0.0215
Epoch   3 Batch  104/538 - Train Accuracy: 0.9710, Validation Accuracy: 0.9668, Loss: 0.0185
Epoch   3 Batch  105/538 - Train Accuracy: 0.9632, Validation Accuracy: 0.9703, Loss: 0.0169
Epoch   3 Batch  106/538 - Train Accuracy: 0.9635, Validation Accuracy: 0.9654, Loss: 0.0174
Epoch   3 Batch  107/538 - Train Accuracy: 0.9527, Validation Accuracy: 0.9695, Loss: 0.0272
Epoch   3 Batch  108/538 - Train Accuracy: 0.9703, Validation Accuracy: 0.9672, Loss: 0.0201
Epoch   3 Batch  109/538 - Train Accuracy: 0.9734, Validation Accuracy: 0.9645, Loss: 0.0193
Epoch   3 Batch  110/538 - Train Accuracy: 0.9713, Validation Accuracy: 0.9627, Loss: 0.0208
Epoch   3 Batch  111/538 - Train Accuracy: 0.9643, Validation Accuracy: 0.9703, Loss: 0.0182
Epoch   3 Batch  112/538 - Train Accuracy: 0.9672, Validation Accuracy: 0.9679, Loss: 0.0215
Epoch   3 Batch  113/538 - Train Accuracy: 0.9508, Validation Accuracy: 0.9609, Loss: 0.0232
Epoch   3 Batch  114/538 - Train Accuracy: 0.9624, Validation Accuracy: 0.9583, Loss: 0.0170
Epoch   3 Batch  115/538 - Train Accuracy: 0.9828, Validation Accuracy: 0.9586, Loss: 0.0198
Epoch   3 Batch  116/538 - Train Accuracy: 0.9661, Validation Accuracy: 0.9577, Loss: 0.0257
Epoch   3 Batch  117/538 - Train Accuracy: 0.9688, Validation Accuracy: 0.9604, Loss: 0.0241
Epoch   3 Batch  118/538 - Train Accuracy: 0.9741, Validation Accuracy: 0.9577, Loss: 0.0206
Epoch   3 Batch  119/538 - Train Accuracy: 0.9844, Validation Accuracy: 0.9593, Loss: 0.0143
Epoch   3 Batch  120/538 - Train Accuracy: 0.9730, Validation Accuracy: 0.9627, Loss: 0.0165
Epoch   3 Batch  121/538 - Train Accuracy: 0.9746, Validation Accuracy: 0.9661, Loss: 0.0209
Epoch   3 Batch  122/538 - Train Accuracy: 0.9643, Validation Accuracy: 0.9677, Loss: 0.0218
Epoch   3 Batch  123/538 - Train Accuracy: 0.9630, Validation Accuracy: 0.9718, Loss: 0.0190
Epoch   3 Batch  124/538 - Train Accuracy: 0.9719, Validation Accuracy: 0.9734, Loss: 0.0176
Epoch   3 Batch  125/538 - Train Accuracy: 0.9734, Validation Accuracy: 0.9734, Loss: 0.0213
Epoch   3 Batch  126/538 - Train Accuracy: 0.9567, Validation Accuracy: 0.9759, Loss: 0.0207
Epoch   3 Batch  127/538 - Train Accuracy: 0.9662, Validation Accuracy: 0.9728, Loss: 0.0251
Epoch   3 Batch  128/538 - Train Accuracy: 0.9639, Validation Accuracy: 0.9679, Loss: 0.0218
Epoch   3 Batch  129/538 - Train Accuracy: 0.9756, Validation Accuracy: 0.9634, Loss: 0.0160
Epoch   3 Batch  130/538 - Train Accuracy: 0.9782, Validation Accuracy: 0.9624, Loss: 0.0182
Epoch   3 Batch  131/538 - Train Accuracy: 0.9723, Validation Accuracy: 0.9622, Loss: 0.0199
Epoch   3 Batch  132/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9670, Loss: 0.0184
Epoch   3 Batch  133/538 - Train Accuracy: 0.9608, Validation Accuracy: 0.9647, Loss: 0.0222
Epoch   3 Batch  134/538 - Train Accuracy: 0.9828, Validation Accuracy: 0.9641, Loss: 0.0262
Epoch   3 Batch  135/538 - Train Accuracy: 0.9652, Validation Accuracy: 0.9668, Loss: 0.0266
Epoch   3 Batch  136/538 - Train Accuracy: 0.9604, Validation Accuracy: 0.9714, Loss: 0.0197
Epoch   3 Batch  137/538 - Train Accuracy: 0.9753, Validation Accuracy: 0.9611, Loss: 0.0256
Epoch   3 Batch  138/538 - Train Accuracy: 0.9719, Validation Accuracy: 0.9560, Loss: 0.0199
Epoch   3 Batch  139/538 - Train Accuracy: 0.9598, Validation Accuracy: 0.9652, Loss: 0.0238
Epoch   3 Batch  140/538 - Train Accuracy: 0.9547, Validation Accuracy: 0.9672, Loss: 0.0279
Epoch   3 Batch  141/538 - Train Accuracy: 0.9689, Validation Accuracy: 0.9581, Loss: 0.0197
Epoch   3 Batch  142/538 - Train Accuracy: 0.9663, Validation Accuracy: 0.9645, Loss: 0.0203
Epoch   3 Batch  143/538 - Train Accuracy: 0.9559, Validation Accuracy: 0.9631, Loss: 0.0287
Epoch   3 Batch  144/538 - Train Accuracy: 0.9822, Validation Accuracy: 0.9661, Loss: 0.0230
Epoch   3 Batch  145/538 - Train Accuracy: 0.9654, Validation Accuracy: 0.9595, Loss: 0.0261
Epoch   3 Batch  146/538 - Train Accuracy: 0.9718, Validation Accuracy: 0.9545, Loss: 0.0217
Epoch   3 Batch  147/538 - Train Accuracy: 0.9753, Validation Accuracy: 0.9569, Loss: 0.0223
Epoch   3 Batch  148/538 - Train Accuracy: 0.9469, Validation Accuracy: 0.9725, Loss: 0.0264
Epoch   3 Batch  149/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9760, Loss: 0.0183
Epoch   3 Batch  150/538 - Train Accuracy: 0.9814, Validation Accuracy: 0.9764, Loss: 0.0170
Epoch   3 Batch  151/538 - Train Accuracy: 0.9632, Validation Accuracy: 0.9743, Loss: 0.0269
Epoch   3 Batch  152/538 - Train Accuracy: 0.9710, Validation Accuracy: 0.9709, Loss: 0.0214
Epoch   3 Batch  153/538 - Train Accuracy: 0.9688, Validation Accuracy: 0.9766, Loss: 0.0213
Epoch   3 Batch  154/538 - Train Accuracy: 0.9725, Validation Accuracy: 0.9597, Loss: 0.0190
Epoch   3 Batch  155/538 - Train Accuracy: 0.9626, Validation Accuracy: 0.9513, Loss: 0.0226
Epoch   3 Batch  156/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9569, Loss: 0.0184
Epoch   3 Batch  157/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9650, Loss: 0.0220
Epoch   3 Batch  158/538 - Train Accuracy: 0.9791, Validation Accuracy: 0.9654, Loss: 0.0215
Epoch   3 Batch  159/538 - Train Accuracy: 0.9705, Validation Accuracy: 0.9666, Loss: 0.0255
Epoch   3 Batch  160/538 - Train Accuracy: 0.9635, Validation Accuracy: 0.9680, Loss: 0.0192
Epoch   3 Batch  161/538 - Train Accuracy: 0.9650, Validation Accuracy: 0.9600, Loss: 0.0204
Epoch   3 Batch  162/538 - Train Accuracy: 0.9702, Validation Accuracy: 0.9727, Loss: 0.0219
Epoch   3 Batch  163/538 - Train Accuracy: 0.9745, Validation Accuracy: 0.9775, Loss: 0.0270
Epoch   3 Batch  164/538 - Train Accuracy: 0.9686, Validation Accuracy: 0.9755, Loss: 0.0201
Epoch   3 Batch  165/538 - Train Accuracy: 0.9714, Validation Accuracy: 0.9753, Loss: 0.0190
Epoch   3 Batch  166/538 - Train Accuracy: 0.9791, Validation Accuracy: 0.9750, Loss: 0.0189
Epoch   3 Batch  167/538 - Train Accuracy: 0.9669, Validation Accuracy: 0.9735, Loss: 0.0321
Epoch   3 Batch  168/538 - Train Accuracy: 0.9670, Validation Accuracy: 0.9650, Loss: 0.0257
Epoch   3 Batch  169/538 - Train Accuracy: 0.9822, Validation Accuracy: 0.9659, Loss: 0.0168
Epoch   3 Batch  170/538 - Train Accuracy: 0.9600, Validation Accuracy: 0.9590, Loss: 0.0247
Epoch   3 Batch  171/538 - Train Accuracy: 0.9578, Validation Accuracy: 0.9615, Loss: 0.0225
Epoch   3 Batch  172/538 - Train Accuracy: 0.9639, Validation Accuracy: 0.9620, Loss: 0.0190
Epoch   3 Batch  173/538 - Train Accuracy: 0.9797, Validation Accuracy: 0.9529, Loss: 0.0158
Epoch   3 Batch  174/538 - Train Accuracy: 0.9689, Validation Accuracy: 0.9517, Loss: 0.0193
Epoch   3 Batch  175/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9553, Loss: 0.0207
Epoch   3 Batch  176/538 - Train Accuracy: 0.9645, Validation Accuracy: 0.9421, Loss: 0.0217
Epoch   3 Batch  177/538 - Train Accuracy: 0.9645, Validation Accuracy: 0.9485, Loss: 0.0203
Epoch   3 Batch  178/538 - Train Accuracy: 0.9472, Validation Accuracy: 0.9506, Loss: 0.0235
Epoch   3 Batch  179/538 - Train Accuracy: 0.9613, Validation Accuracy: 0.9503, Loss: 0.0214
Epoch   3 Batch  180/538 - Train Accuracy: 0.9714, Validation Accuracy: 0.9570, Loss: 0.0222
Epoch   3 Batch  181/538 - Train Accuracy: 0.9555, Validation Accuracy: 0.9638, Loss: 0.0270
Epoch   3 Batch  182/538 - Train Accuracy: 0.9717, Validation Accuracy: 0.9634, Loss: 0.0184
Epoch   3 Batch  183/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9632, Loss: 0.0185
Epoch   3 Batch  184/538 - Train Accuracy: 0.9762, Validation Accuracy: 0.9629, Loss: 0.0213
Epoch   3 Batch  185/538 - Train Accuracy: 0.9885, Validation Accuracy: 0.9634, Loss: 0.0142
Epoch   3 Batch  186/538 - Train Accuracy: 0.9663, Validation Accuracy: 0.9574, Loss: 0.0220
Epoch   3 Batch  187/538 - Train Accuracy: 0.9814, Validation Accuracy: 0.9640, Loss: 0.0218
Epoch   3 Batch  188/538 - Train Accuracy: 0.9697, Validation Accuracy: 0.9585, Loss: 0.0185
Epoch   3 Batch  189/538 - Train Accuracy: 0.9725, Validation Accuracy: 0.9638, Loss: 0.0236
Epoch   3 Batch  190/538 - Train Accuracy: 0.9632, Validation Accuracy: 0.9640, Loss: 0.0298
Epoch   3 Batch  191/538 - Train Accuracy: 0.9829, Validation Accuracy: 0.9656, Loss: 0.0184
Epoch   3 Batch  192/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9673, Loss: 0.0170
Epoch   3 Batch  193/538 - Train Accuracy: 0.9568, Validation Accuracy: 0.9682, Loss: 0.0193
Epoch   3 Batch  194/538 - Train Accuracy: 0.9547, Validation Accuracy: 0.9657, Loss: 0.0257
Epoch   3 Batch  195/538 - Train Accuracy: 0.9801, Validation Accuracy: 0.9620, Loss: 0.0311
Epoch   3 Batch  196/538 - Train Accuracy: 0.9710, Validation Accuracy: 0.9620, Loss: 0.0157
Epoch   3 Batch  197/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9565, Loss: 0.0177
Epoch   3 Batch  198/538 - Train Accuracy: 0.9654, Validation Accuracy: 0.9579, Loss: 0.0216
Epoch   3 Batch  199/538 - Train Accuracy: 0.9645, Validation Accuracy: 0.9554, Loss: 0.0211
Epoch   3 Batch  200/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9627, Loss: 0.0160
Epoch   3 Batch  201/538 - Train Accuracy: 0.9673, Validation Accuracy: 0.9631, Loss: 0.0255
Epoch   3 Batch  202/538 - Train Accuracy: 0.9776, Validation Accuracy: 0.9640, Loss: 0.0190
Epoch   3 Batch  203/538 - Train Accuracy: 0.9654, Validation Accuracy: 0.9609, Loss: 0.0197
Epoch   3 Batch  204/538 - Train Accuracy: 0.9451, Validation Accuracy: 0.9663, Loss: 0.0309
Epoch   3 Batch  205/538 - Train Accuracy: 0.9658, Validation Accuracy: 0.9664, Loss: 0.0187
Epoch   3 Batch  206/538 - Train Accuracy: 0.9795, Validation Accuracy: 0.9602, Loss: 0.0171
Epoch   3 Batch  207/538 - Train Accuracy: 0.9714, Validation Accuracy: 0.9640, Loss: 0.0225
Epoch   3 Batch  208/538 - Train Accuracy: 0.9689, Validation Accuracy: 0.9625, Loss: 0.0279
Epoch   3 Batch  209/538 - Train Accuracy: 0.9727, Validation Accuracy: 0.9641, Loss: 0.0183
Epoch   3 Batch  210/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9638, Loss: 0.0207
Epoch   3 Batch  211/538 - Train Accuracy: 0.9713, Validation Accuracy: 0.9656, Loss: 0.0213
Epoch   3 Batch  212/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9609, Loss: 0.0189
Epoch   3 Batch  213/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9652, Loss: 0.0207
Epoch   3 Batch  214/538 - Train Accuracy: 0.9834, Validation Accuracy: 0.9716, Loss: 0.0160
Epoch   3 Batch  215/538 - Train Accuracy: 0.9635, Validation Accuracy: 0.9673, Loss: 0.0172
Epoch   3 Batch  216/538 - Train Accuracy: 0.9627, Validation Accuracy: 0.9661, Loss: 0.0226
Epoch   3 Batch  217/538 - Train Accuracy: 0.9797, Validation Accuracy: 0.9700, Loss: 0.0219
Epoch   3 Batch  218/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9611, Loss: 0.0154
Epoch   3 Batch  219/538 - Train Accuracy: 0.9643, Validation Accuracy: 0.9590, Loss: 0.0232
Epoch   3 Batch  220/538 - Train Accuracy: 0.9572, Validation Accuracy: 0.9586, Loss: 0.0254
Epoch   3 Batch  221/538 - Train Accuracy: 0.9688, Validation Accuracy: 0.9560, Loss: 0.0169
Epoch   3 Batch  222/538 - Train Accuracy: 0.9723, Validation Accuracy: 0.9529, Loss: 0.0176
Epoch   3 Batch  223/538 - Train Accuracy: 0.9689, Validation Accuracy: 0.9563, Loss: 0.0202
Epoch   3 Batch  224/538 - Train Accuracy: 0.9721, Validation Accuracy: 0.9588, Loss: 0.0235
Epoch   3 Batch  225/538 - Train Accuracy: 0.9810, Validation Accuracy: 0.9590, Loss: 0.0174
Epoch   3 Batch  226/538 - Train Accuracy: 0.9702, Validation Accuracy: 0.9581, Loss: 0.0221
Epoch   3 Batch  227/538 - Train Accuracy: 0.9714, Validation Accuracy: 0.9590, Loss: 0.0199
Epoch   3 Batch  228/538 - Train Accuracy: 0.9622, Validation Accuracy: 0.9574, Loss: 0.0220
Epoch   3 Batch  229/538 - Train Accuracy: 0.9782, Validation Accuracy: 0.9600, Loss: 0.0209
Epoch   3 Batch  230/538 - Train Accuracy: 0.9617, Validation Accuracy: 0.9608, Loss: 0.0211
Epoch   3 Batch  231/538 - Train Accuracy: 0.9623, Validation Accuracy: 0.9640, Loss: 0.0208
Epoch   3 Batch  232/538 - Train Accuracy: 0.9580, Validation Accuracy: 0.9624, Loss: 0.0214
Epoch   3 Batch  233/538 - Train Accuracy: 0.9753, Validation Accuracy: 0.9627, Loss: 0.0182
Epoch   3 Batch  234/538 - Train Accuracy: 0.9785, Validation Accuracy: 0.9627, Loss: 0.0159
Epoch   3 Batch  235/538 - Train Accuracy: 0.9680, Validation Accuracy: 0.9625, Loss: 0.0203
Epoch   3 Batch  236/538 - Train Accuracy: 0.9557, Validation Accuracy: 0.9615, Loss: 0.0184
Epoch   3 Batch  237/538 - Train Accuracy: 0.9664, Validation Accuracy: 0.9599, Loss: 0.0160
Epoch   3 Batch  238/538 - Train Accuracy: 0.9669, Validation Accuracy: 0.9585, Loss: 0.0203
Epoch   3 Batch  239/538 - Train Accuracy: 0.9678, Validation Accuracy: 0.9627, Loss: 0.0199
Epoch   3 Batch  240/538 - Train Accuracy: 0.9695, Validation Accuracy: 0.9652, Loss: 0.0186
Epoch   3 Batch  241/538 - Train Accuracy: 0.9486, Validation Accuracy: 0.9634, Loss: 0.0259
Epoch   3 Batch  242/538 - Train Accuracy: 0.9729, Validation Accuracy: 0.9602, Loss: 0.0184
Epoch   3 Batch  243/538 - Train Accuracy: 0.9702, Validation Accuracy: 0.9556, Loss: 0.0202
Epoch   3 Batch  244/538 - Train Accuracy: 0.9634, Validation Accuracy: 0.9599, Loss: 0.0188
Epoch   3 Batch  245/538 - Train Accuracy: 0.9721, Validation Accuracy: 0.9624, Loss: 0.0254
Epoch   3 Batch  246/538 - Train Accuracy: 0.9714, Validation Accuracy: 0.9609, Loss: 0.0151
Epoch   3 Batch  247/538 - Train Accuracy: 0.9648, Validation Accuracy: 0.9661, Loss: 0.0214
Epoch   3 Batch  248/538 - Train Accuracy: 0.9689, Validation Accuracy: 0.9659, Loss: 0.0201
Epoch   3 Batch  249/538 - Train Accuracy: 0.9658, Validation Accuracy: 0.9668, Loss: 0.0137
Epoch   3 Batch  250/538 - Train Accuracy: 0.9732, Validation Accuracy: 0.9668, Loss: 0.0191
Epoch   3 Batch  251/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9677, Loss: 0.0175
Epoch   3 Batch  252/538 - Train Accuracy: 0.9725, Validation Accuracy: 0.9664, Loss: 0.0192
Epoch   3 Batch  253/538 - Train Accuracy: 0.9704, Validation Accuracy: 0.9636, Loss: 0.0183
Epoch   3 Batch  254/538 - Train Accuracy: 0.9619, Validation Accuracy: 0.9588, Loss: 0.0242
Epoch   3 Batch  255/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9608, Loss: 0.0161
Epoch   3 Batch  256/538 - Train Accuracy: 0.9701, Validation Accuracy: 0.9597, Loss: 0.0189
Epoch   3 Batch  257/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9631, Loss: 0.0189
Epoch   3 Batch  258/538 - Train Accuracy: 0.9680, Validation Accuracy: 0.9652, Loss: 0.0205
Epoch   3 Batch  259/538 - Train Accuracy: 0.9767, Validation Accuracy: 0.9620, Loss: 0.0171
Epoch   3 Batch  260/538 - Train Accuracy: 0.9466, Validation Accuracy: 0.9627, Loss: 0.0215
Epoch   3 Batch  261/538 - Train Accuracy: 0.9676, Validation Accuracy: 0.9593, Loss: 0.0236
Epoch   3 Batch  262/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9505, Loss: 0.0220
Epoch   3 Batch  263/538 - Train Accuracy: 0.9615, Validation Accuracy: 0.9533, Loss: 0.0220
Epoch   3 Batch  264/538 - Train Accuracy: 0.9648, Validation Accuracy: 0.9570, Loss: 0.0212
Epoch   3 Batch  265/538 - Train Accuracy: 0.9605, Validation Accuracy: 0.9585, Loss: 0.0222
Epoch   3 Batch  266/538 - Train Accuracy: 0.9669, Validation Accuracy: 0.9570, Loss: 0.0207
Epoch   3 Batch  267/538 - Train Accuracy: 0.9674, Validation Accuracy: 0.9547, Loss: 0.0202
Epoch   3 Batch  268/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9535, Loss: 0.0149
Epoch   3 Batch  269/538 - Train Accuracy: 0.9705, Validation Accuracy: 0.9517, Loss: 0.0191
Epoch   3 Batch  270/538 - Train Accuracy: 0.9650, Validation Accuracy: 0.9537, Loss: 0.0186
Epoch   3 Batch  271/538 - Train Accuracy: 0.9678, Validation Accuracy: 0.9586, Loss: 0.0143
Epoch   3 Batch  272/538 - Train Accuracy: 0.9764, Validation Accuracy: 0.9585, Loss: 0.0183
Epoch   3 Batch  273/538 - Train Accuracy: 0.9615, Validation Accuracy: 0.9489, Loss: 0.0209
Epoch   3 Batch  274/538 - Train Accuracy: 0.9467, Validation Accuracy: 0.9466, Loss: 0.0195
Epoch   3 Batch  275/538 - Train Accuracy: 0.9586, Validation Accuracy: 0.9494, Loss: 0.0239
Epoch   3 Batch  276/538 - Train Accuracy: 0.9646, Validation Accuracy: 0.9574, Loss: 0.0248
Epoch   3 Batch  277/538 - Train Accuracy: 0.9865, Validation Accuracy: 0.9636, Loss: 0.0171
Epoch   3 Batch  278/538 - Train Accuracy: 0.9740, Validation Accuracy: 0.9663, Loss: 0.0162
Epoch   3 Batch  279/538 - Train Accuracy: 0.9590, Validation Accuracy: 0.9673, Loss: 0.0205
Epoch   3 Batch  280/538 - Train Accuracy: 0.9892, Validation Accuracy: 0.9629, Loss: 0.0160
Epoch   3 Batch  281/538 - Train Accuracy: 0.9623, Validation Accuracy: 0.9677, Loss: 0.0230
Epoch   3 Batch  282/538 - Train Accuracy: 0.9788, Validation Accuracy: 0.9679, Loss: 0.0214
Epoch   3 Batch  283/538 - Train Accuracy: 0.9857, Validation Accuracy: 0.9696, Loss: 0.0172
Epoch   3 Batch  284/538 - Train Accuracy: 0.9668, Validation Accuracy: 0.9636, Loss: 0.0221
Epoch   3 Batch  285/538 - Train Accuracy: 0.9624, Validation Accuracy: 0.9615, Loss: 0.0197
Epoch   3 Batch  286/538 - Train Accuracy: 0.9602, Validation Accuracy: 0.9599, Loss: 0.0263
Epoch   3 Batch  287/538 - Train Accuracy: 0.9887, Validation Accuracy: 0.9631, Loss: 0.0124
Epoch   3 Batch  288/538 - Train Accuracy: 0.9580, Validation Accuracy: 0.9632, Loss: 0.0180
Epoch   3 Batch  289/538 - Train Accuracy: 0.9665, Validation Accuracy: 0.9632, Loss: 0.0177
Epoch   3 Batch  290/538 - Train Accuracy: 0.9785, Validation Accuracy: 0.9645, Loss: 0.0152
Epoch   3 Batch  291/538 - Train Accuracy: 0.9877, Validation Accuracy: 0.9602, Loss: 0.0191
Epoch   3 Batch  292/538 - Train Accuracy: 0.9767, Validation Accuracy: 0.9661, Loss: 0.0128
Epoch   3 Batch  293/538 - Train Accuracy: 0.9723, Validation Accuracy: 0.9696, Loss: 0.0201
Epoch   3 Batch  294/538 - Train Accuracy: 0.9657, Validation Accuracy: 0.9707, Loss: 0.0210
Epoch   3 Batch  295/538 - Train Accuracy: 0.9723, Validation Accuracy: 0.9723, Loss: 0.0207
Epoch   3 Batch  296/538 - Train Accuracy: 0.9563, Validation Accuracy: 0.9712, Loss: 0.0294
Epoch   3 Batch  297/538 - Train Accuracy: 0.9801, Validation Accuracy: 0.9663, Loss: 0.0188
Epoch   3 Batch  298/538 - Train Accuracy: 0.9686, Validation Accuracy: 0.9675, Loss: 0.0162
Epoch   3 Batch  299/538 - Train Accuracy: 0.9604, Validation Accuracy: 0.9645, Loss: 0.0249
Epoch   3 Batch  300/538 - Train Accuracy: 0.9693, Validation Accuracy: 0.9624, Loss: 0.0192
Epoch   3 Batch  301/538 - Train Accuracy: 0.9606, Validation Accuracy: 0.9606, Loss: 0.0219
Epoch   3 Batch  302/538 - Train Accuracy: 0.9730, Validation Accuracy: 0.9648, Loss: 0.0238
Epoch   3 Batch  303/538 - Train Accuracy: 0.9661, Validation Accuracy: 0.9698, Loss: 0.0211
Epoch   3 Batch  304/538 - Train Accuracy: 0.9711, Validation Accuracy: 0.9723, Loss: 0.0219
Epoch   3 Batch  305/538 - Train Accuracy: 0.9688, Validation Accuracy: 0.9682, Loss: 0.0177
Epoch   3 Batch  306/538 - Train Accuracy: 0.9747, Validation Accuracy: 0.9712, Loss: 0.0195
Epoch   3 Batch  307/538 - Train Accuracy: 0.9736, Validation Accuracy: 0.9666, Loss: 0.0179
Epoch   3 Batch  308/538 - Train Accuracy: 0.9691, Validation Accuracy: 0.9604, Loss: 0.0197
Epoch   3 Batch  309/538 - Train Accuracy: 0.9793, Validation Accuracy: 0.9627, Loss: 0.0155
Epoch   3 Batch  310/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9680, Loss: 0.0261
Epoch   3 Batch  311/538 - Train Accuracy: 0.9704, Validation Accuracy: 0.9618, Loss: 0.0207
Epoch   3 Batch  312/538 - Train Accuracy: 0.9737, Validation Accuracy: 0.9558, Loss: 0.0156
Epoch   3 Batch  313/538 - Train Accuracy: 0.9703, Validation Accuracy: 0.9560, Loss: 0.0217
Epoch   3 Batch  314/538 - Train Accuracy: 0.9773, Validation Accuracy: 0.9618, Loss: 0.0207
Epoch   3 Batch  315/538 - Train Accuracy: 0.9706, Validation Accuracy: 0.9632, Loss: 0.0180
Epoch   3 Batch  316/538 - Train Accuracy: 0.9639, Validation Accuracy: 0.9638, Loss: 0.0157
Epoch   3 Batch  317/538 - Train Accuracy: 0.9551, Validation Accuracy: 0.9656, Loss: 0.0190
Epoch   3 Batch  318/538 - Train Accuracy: 0.9725, Validation Accuracy: 0.9668, Loss: 0.0176
Epoch   3 Batch  319/538 - Train Accuracy: 0.9669, Validation Accuracy: 0.9609, Loss: 0.0223
Epoch   3 Batch  320/538 - Train Accuracy: 0.9693, Validation Accuracy: 0.9597, Loss: 0.0172
Epoch   3 Batch  321/538 - Train Accuracy: 0.9674, Validation Accuracy: 0.9641, Loss: 0.0173
Epoch   3 Batch  322/538 - Train Accuracy: 0.9836, Validation Accuracy: 0.9705, Loss: 0.0200
Epoch   3 Batch  323/538 - Train Accuracy: 0.9803, Validation Accuracy: 0.9705, Loss: 0.0169
Epoch   3 Batch  324/538 - Train Accuracy: 0.9809, Validation Accuracy: 0.9755, Loss: 0.0178
Epoch   3 Batch  325/538 - Train Accuracy: 0.9701, Validation Accuracy: 0.9741, Loss: 0.0183
Epoch   3 Batch  326/538 - Train Accuracy: 0.9701, Validation Accuracy: 0.9680, Loss: 0.0180
Epoch   3 Batch  327/538 - Train Accuracy: 0.9750, Validation Accuracy: 0.9790, Loss: 0.0189
Epoch   3 Batch  328/538 - Train Accuracy: 0.9875, Validation Accuracy: 0.9734, Loss: 0.0149
Epoch   3 Batch  329/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9728, Loss: 0.0153
Epoch   3 Batch  330/538 - Train Accuracy: 0.9821, Validation Accuracy: 0.9673, Loss: 0.0172
Epoch   3 Batch  331/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9636, Loss: 0.0185
Epoch   3 Batch  332/538 - Train Accuracy: 0.9727, Validation Accuracy: 0.9672, Loss: 0.0163
Epoch   3 Batch  333/538 - Train Accuracy: 0.9732, Validation Accuracy: 0.9730, Loss: 0.0226
Epoch   3 Batch  334/538 - Train Accuracy: 0.9782, Validation Accuracy: 0.9746, Loss: 0.0157
Epoch   3 Batch  335/538 - Train Accuracy: 0.9730, Validation Accuracy: 0.9794, Loss: 0.0173
Epoch   3 Batch  336/538 - Train Accuracy: 0.9764, Validation Accuracy: 0.9767, Loss: 0.0184
Epoch   3 Batch  337/538 - Train Accuracy: 0.9732, Validation Accuracy: 0.9776, Loss: 0.0181
Epoch   3 Batch  338/538 - Train Accuracy: 0.9807, Validation Accuracy: 0.9805, Loss: 0.0177
Epoch   3 Batch  339/538 - Train Accuracy: 0.9771, Validation Accuracy: 0.9744, Loss: 0.0157
Epoch   3 Batch  340/538 - Train Accuracy: 0.9676, Validation Accuracy: 0.9707, Loss: 0.0174
Epoch   3 Batch  341/538 - Train Accuracy: 0.9787, Validation Accuracy: 0.9624, Loss: 0.0176
Epoch   3 Batch  342/538 - Train Accuracy: 0.9684, Validation Accuracy: 0.9650, Loss: 0.0193
Epoch   3 Batch  343/538 - Train Accuracy: 0.9902, Validation Accuracy: 0.9650, Loss: 0.0161
Epoch   3 Batch  344/538 - Train Accuracy: 0.9773, Validation Accuracy: 0.9650, Loss: 0.0168
Epoch   3 Batch  345/538 - Train Accuracy: 0.9667, Validation Accuracy: 0.9632, Loss: 0.0197
Epoch   3 Batch  346/538 - Train Accuracy: 0.9660, Validation Accuracy: 0.9615, Loss: 0.0229
Epoch   3 Batch  347/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9602, Loss: 0.0184
Epoch   3 Batch  348/538 - Train Accuracy: 0.9617, Validation Accuracy: 0.9682, Loss: 0.0162
Epoch   3 Batch  349/538 - Train Accuracy: 0.9822, Validation Accuracy: 0.9702, Loss: 0.0129
Epoch   3 Batch  350/538 - Train Accuracy: 0.9695, Validation Accuracy: 0.9751, Loss: 0.0189
Epoch   3 Batch  351/538 - Train Accuracy: 0.9740, Validation Accuracy: 0.9728, Loss: 0.0211
Epoch   3 Batch  352/538 - Train Accuracy: 0.9661, Validation Accuracy: 0.9693, Loss: 0.0350
Epoch   3 Batch  353/538 - Train Accuracy: 0.9623, Validation Accuracy: 0.9684, Loss: 0.0199
Epoch   3 Batch  354/538 - Train Accuracy: 0.9826, Validation Accuracy: 0.9714, Loss: 0.0169
Epoch   3 Batch  355/538 - Train Accuracy: 0.9830, Validation Accuracy: 0.9702, Loss: 0.0188
Epoch   3 Batch  356/538 - Train Accuracy: 0.9714, Validation Accuracy: 0.9728, Loss: 0.0168
Epoch   3 Batch  357/538 - Train Accuracy: 0.9734, Validation Accuracy: 0.9703, Loss: 0.0196
Epoch   3 Batch  358/538 - Train Accuracy: 0.9887, Validation Accuracy: 0.9688, Loss: 0.0122
Epoch   3 Batch  359/538 - Train Accuracy: 0.9660, Validation Accuracy: 0.9707, Loss: 0.0191
Epoch   3 Batch  360/538 - Train Accuracy: 0.9707, Validation Accuracy: 0.9744, Loss: 0.0153
Epoch   3 Batch  361/538 - Train Accuracy: 0.9769, Validation Accuracy: 0.9689, Loss: 0.0188
Epoch   3 Batch  362/538 - Train Accuracy: 0.9773, Validation Accuracy: 0.9693, Loss: 0.0156
Epoch   3 Batch  363/538 - Train Accuracy: 0.9762, Validation Accuracy: 0.9680, Loss: 0.0175
Epoch   3 Batch  364/538 - Train Accuracy: 0.9648, Validation Accuracy: 0.9670, Loss: 0.0224
Epoch   3 Batch  365/538 - Train Accuracy: 0.9663, Validation Accuracy: 0.9714, Loss: 0.0182
Epoch   3 Batch  366/538 - Train Accuracy: 0.9717, Validation Accuracy: 0.9725, Loss: 0.0184
Epoch   3 Batch  367/538 - Train Accuracy: 0.9887, Validation Accuracy: 0.9753, Loss: 0.0145
Epoch   3 Batch  368/538 - Train Accuracy: 0.9810, Validation Accuracy: 0.9735, Loss: 0.0152
Epoch   3 Batch  369/538 - Train Accuracy: 0.9768, Validation Accuracy: 0.9751, Loss: 0.0161
Epoch   3 Batch  370/538 - Train Accuracy: 0.9771, Validation Accuracy: 0.9688, Loss: 0.0177
Epoch   3 Batch  371/538 - Train Accuracy: 0.9859, Validation Accuracy: 0.9700, Loss: 0.0168
Epoch   3 Batch  372/538 - Train Accuracy: 0.9707, Validation Accuracy: 0.9629, Loss: 0.0194
Epoch   3 Batch  373/538 - Train Accuracy: 0.9742, Validation Accuracy: 0.9618, Loss: 0.0148
Epoch   3 Batch  374/538 - Train Accuracy: 0.9752, Validation Accuracy: 0.9648, Loss: 0.0158
Epoch   3 Batch  375/538 - Train Accuracy: 0.9771, Validation Accuracy: 0.9624, Loss: 0.0155
Epoch   3 Batch  376/538 - Train Accuracy: 0.9729, Validation Accuracy: 0.9647, Loss: 0.0167
Epoch   3 Batch  377/538 - Train Accuracy: 0.9678, Validation Accuracy: 0.9608, Loss: 0.0187
Epoch   3 Batch  378/538 - Train Accuracy: 0.9782, Validation Accuracy: 0.9588, Loss: 0.0131
Epoch   3 Batch  379/538 - Train Accuracy: 0.9689, Validation Accuracy: 0.9551, Loss: 0.0185
Epoch   3 Batch  380/538 - Train Accuracy: 0.9771, Validation Accuracy: 0.9560, Loss: 0.0151
Epoch   3 Batch  381/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9560, Loss: 0.0151
Epoch   3 Batch  382/538 - Train Accuracy: 0.9658, Validation Accuracy: 0.9590, Loss: 0.0246
Epoch   3 Batch  383/538 - Train Accuracy: 0.9871, Validation Accuracy: 0.9551, Loss: 0.0164
Epoch   3 Batch  384/538 - Train Accuracy: 0.9645, Validation Accuracy: 0.9611, Loss: 0.0172
Epoch   3 Batch  385/538 - Train Accuracy: 0.9712, Validation Accuracy: 0.9517, Loss: 0.0178
Epoch   3 Batch  386/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9533, Loss: 0.0181
Epoch   3 Batch  387/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9563, Loss: 0.0179
Epoch   3 Batch  388/538 - Train Accuracy: 0.9745, Validation Accuracy: 0.9529, Loss: 0.0167
Epoch   3 Batch  389/538 - Train Accuracy: 0.9625, Validation Accuracy: 0.9521, Loss: 0.0232
Epoch   3 Batch  390/538 - Train Accuracy: 0.9669, Validation Accuracy: 0.9467, Loss: 0.0162
Epoch   3 Batch  391/538 - Train Accuracy: 0.9671, Validation Accuracy: 0.9503, Loss: 0.0172
Epoch   3 Batch  392/538 - Train Accuracy: 0.9730, Validation Accuracy: 0.9549, Loss: 0.0158
Epoch   3 Batch  393/538 - Train Accuracy: 0.9708, Validation Accuracy: 0.9576, Loss: 0.0175
Epoch   3 Batch  394/538 - Train Accuracy: 0.9656, Validation Accuracy: 0.9659, Loss: 0.0224
Epoch   3 Batch  395/538 - Train Accuracy: 0.9666, Validation Accuracy: 0.9682, Loss: 0.0194
Epoch   3 Batch  396/538 - Train Accuracy: 0.9693, Validation Accuracy: 0.9652, Loss: 0.0155
Epoch   3 Batch  397/538 - Train Accuracy: 0.9795, Validation Accuracy: 0.9650, Loss: 0.0179
Epoch   3 Batch  398/538 - Train Accuracy: 0.9652, Validation Accuracy: 0.9631, Loss: 0.0193
Epoch   3 Batch  399/538 - Train Accuracy: 0.9709, Validation Accuracy: 0.9595, Loss: 0.0213
Epoch   3 Batch  400/538 - Train Accuracy: 0.9723, Validation Accuracy: 0.9624, Loss: 0.0173
Epoch   3 Batch  401/538 - Train Accuracy: 0.9902, Validation Accuracy: 0.9636, Loss: 0.0141
Epoch   3 Batch  402/538 - Train Accuracy: 0.9762, Validation Accuracy: 0.9666, Loss: 0.0162
Epoch   3 Batch  403/538 - Train Accuracy: 0.9730, Validation Accuracy: 0.9625, Loss: 0.0205
Epoch   3 Batch  404/538 - Train Accuracy: 0.9602, Validation Accuracy: 0.9585, Loss: 0.0189
Epoch   3 Batch  405/538 - Train Accuracy: 0.9747, Validation Accuracy: 0.9588, Loss: 0.0167
Epoch   3 Batch  406/538 - Train Accuracy: 0.9740, Validation Accuracy: 0.9547, Loss: 0.0182
Epoch   3 Batch  407/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9522, Loss: 0.0182
Epoch   3 Batch  408/538 - Train Accuracy: 0.9537, Validation Accuracy: 0.9563, Loss: 0.0219
Epoch   3 Batch  409/538 - Train Accuracy: 0.9641, Validation Accuracy: 0.9627, Loss: 0.0183
Epoch   3 Batch  410/538 - Train Accuracy: 0.9822, Validation Accuracy: 0.9634, Loss: 0.0169
Epoch   3 Batch  411/538 - Train Accuracy: 0.9635, Validation Accuracy: 0.9540, Loss: 0.0210
Epoch   3 Batch  412/538 - Train Accuracy: 0.9788, Validation Accuracy: 0.9620, Loss: 0.0131
Epoch   3 Batch  413/538 - Train Accuracy: 0.9676, Validation Accuracy: 0.9647, Loss: 0.0183
Epoch   3 Batch  414/538 - Train Accuracy: 0.9621, Validation Accuracy: 0.9611, Loss: 0.0256
Epoch   3 Batch  415/538 - Train Accuracy: 0.9549, Validation Accuracy: 0.9544, Loss: 0.0190
Epoch   3 Batch  416/538 - Train Accuracy: 0.9645, Validation Accuracy: 0.9553, Loss: 0.0201
Epoch   3 Batch  417/538 - Train Accuracy: 0.9764, Validation Accuracy: 0.9640, Loss: 0.0175
Epoch   3 Batch  418/538 - Train Accuracy: 0.9750, Validation Accuracy: 0.9652, Loss: 0.0202
Epoch   3 Batch  419/538 - Train Accuracy: 0.9713, Validation Accuracy: 0.9561, Loss: 0.0182
Epoch   3 Batch  420/538 - Train Accuracy: 0.9693, Validation Accuracy: 0.9528, Loss: 0.0219
Epoch   3 Batch  421/538 - Train Accuracy: 0.9676, Validation Accuracy: 0.9513, Loss: 0.0177
Epoch   3 Batch  422/538 - Train Accuracy: 0.9621, Validation Accuracy: 0.9577, Loss: 0.0209
Epoch   3 Batch  423/538 - Train Accuracy: 0.9793, Validation Accuracy: 0.9675, Loss: 0.0210
Epoch   3 Batch  424/538 - Train Accuracy: 0.9622, Validation Accuracy: 0.9691, Loss: 0.0219
Epoch   3 Batch  425/538 - Train Accuracy: 0.9637, Validation Accuracy: 0.9666, Loss: 0.0261
Epoch   3 Batch  426/538 - Train Accuracy: 0.9559, Validation Accuracy: 0.9666, Loss: 0.0200
Epoch   3 Batch  427/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9668, Loss: 0.0201
Epoch   3 Batch  428/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9636, Loss: 0.0133
Epoch   3 Batch  429/538 - Train Accuracy: 0.9775, Validation Accuracy: 0.9583, Loss: 0.0165
Epoch   3 Batch  430/538 - Train Accuracy: 0.9691, Validation Accuracy: 0.9631, Loss: 0.0196
Epoch   3 Batch  431/538 - Train Accuracy: 0.9668, Validation Accuracy: 0.9641, Loss: 0.0181
Epoch   3 Batch  432/538 - Train Accuracy: 0.9640, Validation Accuracy: 0.9586, Loss: 0.0218
Epoch   3 Batch  433/538 - Train Accuracy: 0.9668, Validation Accuracy: 0.9652, Loss: 0.0352
Epoch   3 Batch  434/538 - Train Accuracy: 0.9656, Validation Accuracy: 0.9652, Loss: 0.0159
Epoch   3 Batch  435/538 - Train Accuracy: 0.9730, Validation Accuracy: 0.9673, Loss: 0.0186
Epoch   3 Batch  436/538 - Train Accuracy: 0.9670, Validation Accuracy: 0.9632, Loss: 0.0199
Epoch   3 Batch  437/538 - Train Accuracy: 0.9811, Validation Accuracy: 0.9648, Loss: 0.0159
Epoch   3 Batch  438/538 - Train Accuracy: 0.9645, Validation Accuracy: 0.9645, Loss: 0.0151
Epoch   3 Batch  439/538 - Train Accuracy: 0.9896, Validation Accuracy: 0.9645, Loss: 0.0198
Epoch   3 Batch  440/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9673, Loss: 0.0176
Epoch   3 Batch  441/538 - Train Accuracy: 0.9689, Validation Accuracy: 0.9670, Loss: 0.0206
Epoch   3 Batch  442/538 - Train Accuracy: 0.9695, Validation Accuracy: 0.9638, Loss: 0.0145
Epoch   3 Batch  443/538 - Train Accuracy: 0.9684, Validation Accuracy: 0.9624, Loss: 0.0154
Epoch   3 Batch  444/538 - Train Accuracy: 0.9699, Validation Accuracy: 0.9640, Loss: 0.0176
Epoch   3 Batch  445/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9608, Loss: 0.0157
Epoch   3 Batch  446/538 - Train Accuracy: 0.9688, Validation Accuracy: 0.9604, Loss: 0.0149
Epoch   3 Batch  447/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9648, Loss: 0.0151
Epoch   3 Batch  448/538 - Train Accuracy: 0.9717, Validation Accuracy: 0.9679, Loss: 0.0175
Epoch   3 Batch  449/538 - Train Accuracy: 0.9797, Validation Accuracy: 0.9680, Loss: 0.0190
Epoch   3 Batch  450/538 - Train Accuracy: 0.9622, Validation Accuracy: 0.9688, Loss: 0.0262
Epoch   3 Batch  451/538 - Train Accuracy: 0.9660, Validation Accuracy: 0.9698, Loss: 0.0170
Epoch   3 Batch  452/538 - Train Accuracy: 0.9814, Validation Accuracy: 0.9680, Loss: 0.0153
Epoch   3 Batch  453/538 - Train Accuracy: 0.9637, Validation Accuracy: 0.9677, Loss: 0.0212
Epoch   3 Batch  454/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9616, Loss: 0.0194
Epoch   3 Batch  455/538 - Train Accuracy: 0.9735, Validation Accuracy: 0.9640, Loss: 0.0189
Epoch   3 Batch  456/538 - Train Accuracy: 0.9704, Validation Accuracy: 0.9569, Loss: 0.0276
Epoch   3 Batch  457/538 - Train Accuracy: 0.9699, Validation Accuracy: 0.9648, Loss: 0.0156
Epoch   3 Batch  458/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9622, Loss: 0.0152
Epoch   3 Batch  459/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9638, Loss: 0.0148
Epoch   3 Batch  460/538 - Train Accuracy: 0.9641, Validation Accuracy: 0.9631, Loss: 0.0169
Epoch   3 Batch  461/538 - Train Accuracy: 0.9716, Validation Accuracy: 0.9656, Loss: 0.0206
Epoch   3 Batch  462/538 - Train Accuracy: 0.9771, Validation Accuracy: 0.9680, Loss: 0.0141
Epoch   3 Batch  463/538 - Train Accuracy: 0.9680, Validation Accuracy: 0.9682, Loss: 0.0207
Epoch   3 Batch  464/538 - Train Accuracy: 0.9805, Validation Accuracy: 0.9707, Loss: 0.0158
Epoch   3 Batch  465/538 - Train Accuracy: 0.9668, Validation Accuracy: 0.9734, Loss: 0.0183
Epoch   3 Batch  466/538 - Train Accuracy: 0.9621, Validation Accuracy: 0.9695, Loss: 0.0191
Epoch   3 Batch  467/538 - Train Accuracy: 0.9727, Validation Accuracy: 0.9668, Loss: 0.0186
Epoch   3 Batch  468/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9647, Loss: 0.0220
Epoch   3 Batch  469/538 - Train Accuracy: 0.9742, Validation Accuracy: 0.9636, Loss: 0.0188
Epoch   3 Batch  470/538 - Train Accuracy: 0.9626, Validation Accuracy: 0.9615, Loss: 0.0199
Epoch   3 Batch  471/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9648, Loss: 0.0149
Epoch   3 Batch  472/538 - Train Accuracy: 0.9975, Validation Accuracy: 0.9643, Loss: 0.0108
Epoch   3 Batch  473/538 - Train Accuracy: 0.9689, Validation Accuracy: 0.9709, Loss: 0.0194
Epoch   3 Batch  474/538 - Train Accuracy: 0.9786, Validation Accuracy: 0.9698, Loss: 0.0169
Epoch   3 Batch  475/538 - Train Accuracy: 0.9844, Validation Accuracy: 0.9672, Loss: 0.0144
Epoch   3 Batch  476/538 - Train Accuracy: 0.9729, Validation Accuracy: 0.9714, Loss: 0.0165
Epoch   3 Batch  477/538 - Train Accuracy: 0.9783, Validation Accuracy: 0.9739, Loss: 0.0203
Epoch   3 Batch  478/538 - Train Accuracy: 0.9842, Validation Accuracy: 0.9737, Loss: 0.0144
Epoch   3 Batch  479/538 - Train Accuracy: 0.9740, Validation Accuracy: 0.9698, Loss: 0.0202
Epoch   3 Batch  480/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9636, Loss: 0.0161
Epoch   3 Batch  481/538 - Train Accuracy: 0.9671, Validation Accuracy: 0.9602, Loss: 0.0214
Epoch   3 Batch  482/538 - Train Accuracy: 0.9728, Validation Accuracy: 0.9656, Loss: 0.0154
Epoch   3 Batch  483/538 - Train Accuracy: 0.9654, Validation Accuracy: 0.9702, Loss: 0.0202
Epoch   3 Batch  484/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9689, Loss: 0.0182
Epoch   3 Batch  485/538 - Train Accuracy: 0.9712, Validation Accuracy: 0.9721, Loss: 0.0233
Epoch   3 Batch  486/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9759, Loss: 0.0125
Epoch   3 Batch  487/538 - Train Accuracy: 0.9823, Validation Accuracy: 0.9723, Loss: 0.0135
Epoch   3 Batch  488/538 - Train Accuracy: 0.9713, Validation Accuracy: 0.9718, Loss: 0.0162
Epoch   3 Batch  489/538 - Train Accuracy: 0.9789, Validation Accuracy: 0.9689, Loss: 0.0184
Epoch   3 Batch  490/538 - Train Accuracy: 0.9650, Validation Accuracy: 0.9689, Loss: 0.0171
Epoch   3 Batch  491/538 - Train Accuracy: 0.9670, Validation Accuracy: 0.9686, Loss: 0.0194
Epoch   3 Batch  492/538 - Train Accuracy: 0.9805, Validation Accuracy: 0.9696, Loss: 0.0150
Epoch   3 Batch  493/538 - Train Accuracy: 0.9674, Validation Accuracy: 0.9725, Loss: 0.0172
Epoch   3 Batch  494/538 - Train Accuracy: 0.9688, Validation Accuracy: 0.9782, Loss: 0.0182
Epoch   3 Batch  495/538 - Train Accuracy: 0.9646, Validation Accuracy: 0.9705, Loss: 0.0210
Epoch   3 Batch  496/538 - Train Accuracy: 0.9805, Validation Accuracy: 0.9718, Loss: 0.0135
Epoch   3 Batch  497/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9670, Loss: 0.0154
Epoch   3 Batch  498/538 - Train Accuracy: 0.9787, Validation Accuracy: 0.9636, Loss: 0.0161
Epoch   3 Batch  499/538 - Train Accuracy: 0.9689, Validation Accuracy: 0.9638, Loss: 0.0171
Epoch   3 Batch  500/538 - Train Accuracy: 0.9842, Validation Accuracy: 0.9627, Loss: 0.0092
Epoch   3 Batch  501/538 - Train Accuracy: 0.9734, Validation Accuracy: 0.9622, Loss: 0.0169
Epoch   3 Batch  502/538 - Train Accuracy: 0.9617, Validation Accuracy: 0.9648, Loss: 0.0170
Epoch   3 Batch  503/538 - Train Accuracy: 0.9782, Validation Accuracy: 0.9680, Loss: 0.0176
Epoch   3 Batch  504/538 - Train Accuracy: 0.9875, Validation Accuracy: 0.9705, Loss: 0.0103
Epoch   3 Batch  505/538 - Train Accuracy: 0.9734, Validation Accuracy: 0.9695, Loss: 0.0119
Epoch   3 Batch  506/538 - Train Accuracy: 0.9741, Validation Accuracy: 0.9664, Loss: 0.0136
Epoch   3 Batch  507/538 - Train Accuracy: 0.9753, Validation Accuracy: 0.9643, Loss: 0.0151
Epoch   3 Batch  508/538 - Train Accuracy: 0.9728, Validation Accuracy: 0.9668, Loss: 0.0150
Epoch   3 Batch  509/538 - Train Accuracy: 0.9672, Validation Accuracy: 0.9680, Loss: 0.0194
Epoch   3 Batch  510/538 - Train Accuracy: 0.9821, Validation Accuracy: 0.9686, Loss: 0.0146
Epoch   3 Batch  511/538 - Train Accuracy: 0.9673, Validation Accuracy: 0.9632, Loss: 0.0180
Epoch   3 Batch  512/538 - Train Accuracy: 0.9805, Validation Accuracy: 0.9645, Loss: 0.0201
Epoch   3 Batch  513/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9696, Loss: 0.0158
Epoch   3 Batch  514/538 - Train Accuracy: 0.9709, Validation Accuracy: 0.9709, Loss: 0.0162
Epoch   3 Batch  515/538 - Train Accuracy: 0.9693, Validation Accuracy: 0.9670, Loss: 0.0175
Epoch   3 Batch  516/538 - Train Accuracy: 0.9710, Validation Accuracy: 0.9668, Loss: 0.0158
Epoch   3 Batch  517/538 - Train Accuracy: 0.9784, Validation Accuracy: 0.9647, Loss: 0.0138
Epoch   3 Batch  518/538 - Train Accuracy: 0.9801, Validation Accuracy: 0.9656, Loss: 0.0185
Epoch   3 Batch  519/538 - Train Accuracy: 0.9691, Validation Accuracy: 0.9563, Loss: 0.0157
Epoch   3 Batch  520/538 - Train Accuracy: 0.9672, Validation Accuracy: 0.9647, Loss: 0.0210
Epoch   3 Batch  521/538 - Train Accuracy: 0.9805, Validation Accuracy: 0.9654, Loss: 0.0189
Epoch   3 Batch  522/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9680, Loss: 0.0138
Epoch   3 Batch  523/538 - Train Accuracy: 0.9793, Validation Accuracy: 0.9677, Loss: 0.0182
Epoch   3 Batch  524/538 - Train Accuracy: 0.9668, Validation Accuracy: 0.9661, Loss: 0.0138
Epoch   3 Batch  525/538 - Train Accuracy: 0.9771, Validation Accuracy: 0.9632, Loss: 0.0161
Epoch   3 Batch  526/538 - Train Accuracy: 0.9723, Validation Accuracy: 0.9700, Loss: 0.0160
Epoch   3 Batch  527/538 - Train Accuracy: 0.9771, Validation Accuracy: 0.9645, Loss: 0.0156
Epoch   3 Batch  528/538 - Train Accuracy: 0.9714, Validation Accuracy: 0.9657, Loss: 0.0216
Epoch   3 Batch  529/538 - Train Accuracy: 0.9678, Validation Accuracy: 0.9680, Loss: 0.0200
Epoch   3 Batch  530/538 - Train Accuracy: 0.9656, Validation Accuracy: 0.9682, Loss: 0.0190
Epoch   3 Batch  531/538 - Train Accuracy: 0.9682, Validation Accuracy: 0.9696, Loss: 0.0215
Epoch   3 Batch  532/538 - Train Accuracy: 0.9703, Validation Accuracy: 0.9725, Loss: 0.0130
Epoch   3 Batch  533/538 - Train Accuracy: 0.9680, Validation Accuracy: 0.9716, Loss: 0.0133
Epoch   3 Batch  534/538 - Train Accuracy: 0.9831, Validation Accuracy: 0.9693, Loss: 0.0122
Epoch   3 Batch  535/538 - Train Accuracy: 0.9669, Validation Accuracy: 0.9680, Loss: 0.0181
Epoch   3 Batch  536/538 - Train Accuracy: 0.9792, Validation Accuracy: 0.9737, Loss: 0.0180
Epoch   4 Batch    0/538 - Train Accuracy: 0.9854, Validation Accuracy: 0.9737, Loss: 0.0133
Epoch   4 Batch    1/538 - Train Accuracy: 0.9797, Validation Accuracy: 0.9723, Loss: 0.0185
Epoch   4 Batch    2/538 - Train Accuracy: 0.9846, Validation Accuracy: 0.9725, Loss: 0.0164
Epoch   4 Batch    3/538 - Train Accuracy: 0.9830, Validation Accuracy: 0.9684, Loss: 0.0146
Epoch   4 Batch    4/538 - Train Accuracy: 0.9771, Validation Accuracy: 0.9718, Loss: 0.0170
Epoch   4 Batch    5/538 - Train Accuracy: 0.9753, Validation Accuracy: 0.9703, Loss: 0.0201
Epoch   4 Batch    6/538 - Train Accuracy: 0.9635, Validation Accuracy: 0.9725, Loss: 0.0128
Epoch   4 Batch    7/538 - Train Accuracy: 0.9824, Validation Accuracy: 0.9751, Loss: 0.0135
Epoch   4 Batch    8/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9727, Loss: 0.0162
Epoch   4 Batch    9/538 - Train Accuracy: 0.9631, Validation Accuracy: 0.9679, Loss: 0.0153
Epoch   4 Batch   10/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9608, Loss: 0.0160
Epoch   4 Batch   11/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9551, Loss: 0.0175
Epoch   4 Batch   12/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9560, Loss: 0.0162
Epoch   4 Batch   13/538 - Train Accuracy: 0.9810, Validation Accuracy: 0.9572, Loss: 0.0153
Epoch   4 Batch   14/538 - Train Accuracy: 0.9697, Validation Accuracy: 0.9622, Loss: 0.0145
Epoch   4 Batch   15/538 - Train Accuracy: 0.9766, Validation Accuracy: 0.9636, Loss: 0.0148
Epoch   4 Batch   16/538 - Train Accuracy: 0.9842, Validation Accuracy: 0.9656, Loss: 0.0146
Epoch   4 Batch   17/538 - Train Accuracy: 0.9824, Validation Accuracy: 0.9748, Loss: 0.0157
Epoch   4 Batch   18/538 - Train Accuracy: 0.9633, Validation Accuracy: 0.9769, Loss: 0.0240
Epoch   4 Batch   19/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9787, Loss: 0.0174
Epoch   4 Batch   20/538 - Train Accuracy: 0.9816, Validation Accuracy: 0.9773, Loss: 0.0169
Epoch   4 Batch   21/538 - Train Accuracy: 0.9891, Validation Accuracy: 0.9783, Loss: 0.0103
Epoch   4 Batch   22/538 - Train Accuracy: 0.9652, Validation Accuracy: 0.9759, Loss: 0.0182
Epoch   4 Batch   23/538 - Train Accuracy: 0.9705, Validation Accuracy: 0.9703, Loss: 0.0192
Epoch   4 Batch   24/538 - Train Accuracy: 0.9790, Validation Accuracy: 0.9705, Loss: 0.0188
Epoch   4 Batch   25/538 - Train Accuracy: 0.9676, Validation Accuracy: 0.9650, Loss: 0.0187
Epoch   4 Batch   26/538 - Train Accuracy: 0.9641, Validation Accuracy: 0.9711, Loss: 0.0245
Epoch   4 Batch   27/538 - Train Accuracy: 0.9826, Validation Accuracy: 0.9698, Loss: 0.0133
Epoch   4 Batch   28/538 - Train Accuracy: 0.9796, Validation Accuracy: 0.9572, Loss: 0.0164
Epoch   4 Batch   29/538 - Train Accuracy: 0.9650, Validation Accuracy: 0.9537, Loss: 0.0139
Epoch   4 Batch   30/538 - Train Accuracy: 0.9607, Validation Accuracy: 0.9574, Loss: 0.0193
Epoch   4 Batch   31/538 - Train Accuracy: 0.9874, Validation Accuracy: 0.9572, Loss: 0.0128
Epoch   4 Batch   32/538 - Train Accuracy: 0.9838, Validation Accuracy: 0.9547, Loss: 0.0095
Epoch   4 Batch   33/538 - Train Accuracy: 0.9574, Validation Accuracy: 0.9592, Loss: 0.0203
Epoch   4 Batch   34/538 - Train Accuracy: 0.9615, Validation Accuracy: 0.9666, Loss: 0.0234
Epoch   4 Batch   35/538 - Train Accuracy: 0.9863, Validation Accuracy: 0.9680, Loss: 0.0130
Epoch   4 Batch   36/538 - Train Accuracy: 0.9788, Validation Accuracy: 0.9659, Loss: 0.0133
Epoch   4 Batch   37/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9695, Loss: 0.0200
Epoch   4 Batch   38/538 - Train Accuracy: 0.9664, Validation Accuracy: 0.9711, Loss: 0.0186
Epoch   4 Batch   39/538 - Train Accuracy: 0.9824, Validation Accuracy: 0.9702, Loss: 0.0131
Epoch   4 Batch   40/538 - Train Accuracy: 0.9815, Validation Accuracy: 0.9688, Loss: 0.0125
Epoch   4 Batch   41/538 - Train Accuracy: 0.9814, Validation Accuracy: 0.9725, Loss: 0.0170
Epoch   4 Batch   42/538 - Train Accuracy: 0.9748, Validation Accuracy: 0.9741, Loss: 0.0150
Epoch   4 Batch   43/538 - Train Accuracy: 0.9613, Validation Accuracy: 0.9672, Loss: 0.0170
Epoch   4 Batch   44/538 - Train Accuracy: 0.9736, Validation Accuracy: 0.9659, Loss: 0.0159
Epoch   4 Batch   45/538 - Train Accuracy: 0.9795, Validation Accuracy: 0.9672, Loss: 0.0190
Epoch   4 Batch   46/538 - Train Accuracy: 0.9803, Validation Accuracy: 0.9657, Loss: 0.0163
Epoch   4 Batch   47/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9648, Loss: 0.0162
Epoch   4 Batch   48/538 - Train Accuracy: 0.9708, Validation Accuracy: 0.9648, Loss: 0.0183
Epoch   4 Batch   49/538 - Train Accuracy: 0.9826, Validation Accuracy: 0.9645, Loss: 0.0141
Epoch   4 Batch   50/538 - Train Accuracy: 0.9664, Validation Accuracy: 0.9654, Loss: 0.0159
Epoch   4 Batch   51/538 - Train Accuracy: 0.9671, Validation Accuracy: 0.9698, Loss: 0.0201
Epoch   4 Batch   52/538 - Train Accuracy: 0.9730, Validation Accuracy: 0.9696, Loss: 0.0165
Epoch   4 Batch   53/538 - Train Accuracy: 0.9494, Validation Accuracy: 0.9679, Loss: 0.0179
Epoch   4 Batch   54/538 - Train Accuracy: 0.9801, Validation Accuracy: 0.9663, Loss: 0.0154
Epoch   4 Batch   55/538 - Train Accuracy: 0.9662, Validation Accuracy: 0.9661, Loss: 0.0164
Epoch   4 Batch   56/538 - Train Accuracy: 0.9704, Validation Accuracy: 0.9689, Loss: 0.0189
Epoch   4 Batch   57/538 - Train Accuracy: 0.9555, Validation Accuracy: 0.9689, Loss: 0.0228
Epoch   4 Batch   58/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9659, Loss: 0.0136
Epoch   4 Batch   59/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9727, Loss: 0.0188
Epoch   4 Batch   60/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9730, Loss: 0.0190
Epoch   4 Batch   61/538 - Train Accuracy: 0.9787, Validation Accuracy: 0.9737, Loss: 0.0164
Epoch   4 Batch   62/538 - Train Accuracy: 0.9741, Validation Accuracy: 0.9762, Loss: 0.0186
Epoch   4 Batch   63/538 - Train Accuracy: 0.9766, Validation Accuracy: 0.9751, Loss: 0.0169
Epoch   4 Batch   64/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9744, Loss: 0.0151
Epoch   4 Batch   65/538 - Train Accuracy: 0.9762, Validation Accuracy: 0.9716, Loss: 0.0169
Epoch   4 Batch   66/538 - Train Accuracy: 0.9833, Validation Accuracy: 0.9680, Loss: 0.0131
Epoch   4 Batch   67/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9616, Loss: 0.0176
Epoch   4 Batch   68/538 - Train Accuracy: 0.9745, Validation Accuracy: 0.9620, Loss: 0.0125
Epoch   4 Batch   69/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9567, Loss: 0.0143
Epoch   4 Batch   70/538 - Train Accuracy: 0.9734, Validation Accuracy: 0.9574, Loss: 0.0130
Epoch   4 Batch   71/538 - Train Accuracy: 0.9787, Validation Accuracy: 0.9599, Loss: 0.0198
Epoch   4 Batch   72/538 - Train Accuracy: 0.9829, Validation Accuracy: 0.9643, Loss: 0.0239
Epoch   4 Batch   73/538 - Train Accuracy: 0.9795, Validation Accuracy: 0.9613, Loss: 0.0188
Epoch   4 Batch   74/538 - Train Accuracy: 0.9823, Validation Accuracy: 0.9634, Loss: 0.0142
Epoch   4 Batch   75/538 - Train Accuracy: 0.9736, Validation Accuracy: 0.9634, Loss: 0.0173
Epoch   4 Batch   76/538 - Train Accuracy: 0.9709, Validation Accuracy: 0.9659, Loss: 0.0180
Epoch   4 Batch   77/538 - Train Accuracy: 0.9682, Validation Accuracy: 0.9686, Loss: 0.0170
Epoch   4 Batch   78/538 - Train Accuracy: 0.9688, Validation Accuracy: 0.9702, Loss: 0.0176
Epoch   4 Batch   79/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9775, Loss: 0.0135
Epoch   4 Batch   80/538 - Train Accuracy: 0.9832, Validation Accuracy: 0.9769, Loss: 0.0144
Epoch   4 Batch   81/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9750, Loss: 0.0185
Epoch   4 Batch   82/538 - Train Accuracy: 0.9635, Validation Accuracy: 0.9744, Loss: 0.0183
Epoch   4 Batch   83/538 - Train Accuracy: 0.9723, Validation Accuracy: 0.9668, Loss: 0.0162
Epoch   4 Batch   84/538 - Train Accuracy: 0.9652, Validation Accuracy: 0.9675, Loss: 0.0199
Epoch   4 Batch   85/538 - Train Accuracy: 0.9901, Validation Accuracy: 0.9673, Loss: 0.0129
Epoch   4 Batch   86/538 - Train Accuracy: 0.9738, Validation Accuracy: 0.9661, Loss: 0.0135
Epoch   4 Batch   87/538 - Train Accuracy: 0.9654, Validation Accuracy: 0.9632, Loss: 0.0158
Epoch   4 Batch   88/538 - Train Accuracy: 0.9740, Validation Accuracy: 0.9616, Loss: 0.0173
Epoch   4 Batch   89/538 - Train Accuracy: 0.9744, Validation Accuracy: 0.9709, Loss: 0.0127
Epoch   4 Batch   90/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9709, Loss: 0.0207
Epoch   4 Batch   91/538 - Train Accuracy: 0.9664, Validation Accuracy: 0.9709, Loss: 0.0204
Epoch   4 Batch   92/538 - Train Accuracy: 0.9727, Validation Accuracy: 0.9709, Loss: 0.0174
Epoch   4 Batch   93/538 - Train Accuracy: 0.9773, Validation Accuracy: 0.9696, Loss: 0.0151
Epoch   4 Batch   94/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9721, Loss: 0.0140
Epoch   4 Batch   95/538 - Train Accuracy: 0.9696, Validation Accuracy: 0.9723, Loss: 0.0157
Epoch   4 Batch   96/538 - Train Accuracy: 0.9842, Validation Accuracy: 0.9744, Loss: 0.0135
Epoch   4 Batch   97/538 - Train Accuracy: 0.9740, Validation Accuracy: 0.9759, Loss: 0.0135
Epoch   4 Batch   98/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9817, Loss: 0.0189
Epoch   4 Batch   99/538 - Train Accuracy: 0.9752, Validation Accuracy: 0.9822, Loss: 0.0143
Epoch   4 Batch  100/538 - Train Accuracy: 0.9889, Validation Accuracy: 0.9767, Loss: 0.0137
Epoch   4 Batch  101/538 - Train Accuracy: 0.9744, Validation Accuracy: 0.9790, Loss: 0.0225
Epoch   4 Batch  102/538 - Train Accuracy: 0.9559, Validation Accuracy: 0.9819, Loss: 0.0211
Epoch   4 Batch  103/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9785, Loss: 0.0176
Epoch   4 Batch  104/538 - Train Accuracy: 0.9859, Validation Accuracy: 0.9746, Loss: 0.0144
Epoch   4 Batch  105/538 - Train Accuracy: 0.9775, Validation Accuracy: 0.9711, Loss: 0.0128
Epoch   4 Batch  106/538 - Train Accuracy: 0.9688, Validation Accuracy: 0.9684, Loss: 0.0137
Epoch   4 Batch  107/538 - Train Accuracy: 0.9703, Validation Accuracy: 0.9695, Loss: 0.0213
Epoch   4 Batch  108/538 - Train Accuracy: 0.9730, Validation Accuracy: 0.9609, Loss: 0.0174
Epoch   4 Batch  109/538 - Train Accuracy: 0.9803, Validation Accuracy: 0.9632, Loss: 0.0144
Epoch   4 Batch  110/538 - Train Accuracy: 0.9719, Validation Accuracy: 0.9663, Loss: 0.0153
Epoch   4 Batch  111/538 - Train Accuracy: 0.9734, Validation Accuracy: 0.9757, Loss: 0.0135
Epoch   4 Batch  112/538 - Train Accuracy: 0.9646, Validation Accuracy: 0.9771, Loss: 0.0181
Epoch   4 Batch  113/538 - Train Accuracy: 0.9623, Validation Accuracy: 0.9778, Loss: 0.0183
Epoch   4 Batch  114/538 - Train Accuracy: 0.9704, Validation Accuracy: 0.9780, Loss: 0.0146
Epoch   4 Batch  115/538 - Train Accuracy: 0.9801, Validation Accuracy: 0.9822, Loss: 0.0157
Epoch   4 Batch  116/538 - Train Accuracy: 0.9674, Validation Accuracy: 0.9744, Loss: 0.0196
Epoch   4 Batch  117/538 - Train Accuracy: 0.9786, Validation Accuracy: 0.9712, Loss: 0.0171
Epoch   4 Batch  118/538 - Train Accuracy: 0.9836, Validation Accuracy: 0.9700, Loss: 0.0178
Epoch   4 Batch  119/538 - Train Accuracy: 0.9885, Validation Accuracy: 0.9705, Loss: 0.0110
Epoch   4 Batch  120/538 - Train Accuracy: 0.9709, Validation Accuracy: 0.9703, Loss: 0.0156
Epoch   4 Batch  121/538 - Train Accuracy: 0.9830, Validation Accuracy: 0.9645, Loss: 0.0172
Epoch   4 Batch  122/538 - Train Accuracy: 0.9721, Validation Accuracy: 0.9675, Loss: 0.0184
Epoch   4 Batch  123/538 - Train Accuracy: 0.9699, Validation Accuracy: 0.9686, Loss: 0.0145
Epoch   4 Batch  124/538 - Train Accuracy: 0.9650, Validation Accuracy: 0.9677, Loss: 0.0160
Epoch   4 Batch  125/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9661, Loss: 0.0176
Epoch   4 Batch  126/538 - Train Accuracy: 0.9615, Validation Accuracy: 0.9661, Loss: 0.0190
Epoch   4 Batch  127/538 - Train Accuracy: 0.9678, Validation Accuracy: 0.9682, Loss: 0.0214
Epoch   4 Batch  128/538 - Train Accuracy: 0.9756, Validation Accuracy: 0.9673, Loss: 0.0175
Epoch   4 Batch  129/538 - Train Accuracy: 0.9792, Validation Accuracy: 0.9657, Loss: 0.0125
Epoch   4 Batch  130/538 - Train Accuracy: 0.9678, Validation Accuracy: 0.9636, Loss: 0.0161
Epoch   4 Batch  131/538 - Train Accuracy: 0.9805, Validation Accuracy: 0.9684, Loss: 0.0153
Epoch   4 Batch  132/538 - Train Accuracy: 0.9808, Validation Accuracy: 0.9693, Loss: 0.0136
Epoch   4 Batch  133/538 - Train Accuracy: 0.9654, Validation Accuracy: 0.9730, Loss: 0.0185
Epoch   4 Batch  134/538 - Train Accuracy: 0.9785, Validation Accuracy: 0.9718, Loss: 0.0223
Epoch   4 Batch  135/538 - Train Accuracy: 0.9745, Validation Accuracy: 0.9716, Loss: 0.0214
Epoch   4 Batch  136/538 - Train Accuracy: 0.9714, Validation Accuracy: 0.9700, Loss: 0.0153
Epoch   4 Batch  137/538 - Train Accuracy: 0.9667, Validation Accuracy: 0.9725, Loss: 0.0197
Epoch   4 Batch  138/538 - Train Accuracy: 0.9784, Validation Accuracy: 0.9702, Loss: 0.0150
Epoch   4 Batch  139/538 - Train Accuracy: 0.9668, Validation Accuracy: 0.9696, Loss: 0.0184
Epoch   4 Batch  140/538 - Train Accuracy: 0.9719, Validation Accuracy: 0.9716, Loss: 0.0204
Epoch   4 Batch  141/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9739, Loss: 0.0161
Epoch   4 Batch  142/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9682, Loss: 0.0150
Epoch   4 Batch  143/538 - Train Accuracy: 0.9746, Validation Accuracy: 0.9661, Loss: 0.0216
Epoch   4 Batch  144/538 - Train Accuracy: 0.9857, Validation Accuracy: 0.9670, Loss: 0.0198
Epoch   4 Batch  145/538 - Train Accuracy: 0.9706, Validation Accuracy: 0.9661, Loss: 0.0228
Epoch   4 Batch  146/538 - Train Accuracy: 0.9672, Validation Accuracy: 0.9661, Loss: 0.0157
Epoch   4 Batch  147/538 - Train Accuracy: 0.9676, Validation Accuracy: 0.9659, Loss: 0.0181
Epoch   4 Batch  148/538 - Train Accuracy: 0.9607, Validation Accuracy: 0.9664, Loss: 0.0209
Epoch   4 Batch  149/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9648, Loss: 0.0150
Epoch   4 Batch  150/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9748, Loss: 0.0149
Epoch   4 Batch  151/538 - Train Accuracy: 0.9686, Validation Accuracy: 0.9757, Loss: 0.0220
Epoch   4 Batch  152/538 - Train Accuracy: 0.9821, Validation Accuracy: 0.9743, Loss: 0.0171
Epoch   4 Batch  153/538 - Train Accuracy: 0.9741, Validation Accuracy: 0.9702, Loss: 0.0172
Epoch   4 Batch  154/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9682, Loss: 0.0135
Epoch   4 Batch  155/538 - Train Accuracy: 0.9719, Validation Accuracy: 0.9695, Loss: 0.0176
Epoch   4 Batch  156/538 - Train Accuracy: 0.9859, Validation Accuracy: 0.9691, Loss: 0.0158
Epoch   4 Batch  157/538 - Train Accuracy: 0.9851, Validation Accuracy: 0.9719, Loss: 0.0167
Epoch   4 Batch  158/538 - Train Accuracy: 0.9814, Validation Accuracy: 0.9702, Loss: 0.0145
Epoch   4 Batch  159/538 - Train Accuracy: 0.9748, Validation Accuracy: 0.9716, Loss: 0.0206
Epoch   4 Batch  160/538 - Train Accuracy: 0.9725, Validation Accuracy: 0.9703, Loss: 0.0160
Epoch   4 Batch  161/538 - Train Accuracy: 0.9727, Validation Accuracy: 0.9650, Loss: 0.0154
Epoch   4 Batch  162/538 - Train Accuracy: 0.9816, Validation Accuracy: 0.9656, Loss: 0.0157
Epoch   4 Batch  163/538 - Train Accuracy: 0.9682, Validation Accuracy: 0.9652, Loss: 0.0209
Epoch   4 Batch  164/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9675, Loss: 0.0164
Epoch   4 Batch  165/538 - Train Accuracy: 0.9810, Validation Accuracy: 0.9691, Loss: 0.0125
Epoch   4 Batch  166/538 - Train Accuracy: 0.9863, Validation Accuracy: 0.9684, Loss: 0.0119
Epoch   4 Batch  167/538 - Train Accuracy: 0.9719, Validation Accuracy: 0.9730, Loss: 0.0261
Epoch   4 Batch  168/538 - Train Accuracy: 0.9762, Validation Accuracy: 0.9711, Loss: 0.0203
Epoch   4 Batch  169/538 - Train Accuracy: 0.9955, Validation Accuracy: 0.9668, Loss: 0.0133
Epoch   4 Batch  170/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9615, Loss: 0.0189
Epoch   4 Batch  171/538 - Train Accuracy: 0.9709, Validation Accuracy: 0.9588, Loss: 0.0196
Epoch   4 Batch  172/538 - Train Accuracy: 0.9766, Validation Accuracy: 0.9599, Loss: 0.0135
Epoch   4 Batch  173/538 - Train Accuracy: 0.9890, Validation Accuracy: 0.9648, Loss: 0.0126
Epoch   4 Batch  174/538 - Train Accuracy: 0.9766, Validation Accuracy: 0.9600, Loss: 0.0144
Epoch   4 Batch  175/538 - Train Accuracy: 0.9809, Validation Accuracy: 0.9522, Loss: 0.0146
Epoch   4 Batch  176/538 - Train Accuracy: 0.9727, Validation Accuracy: 0.9471, Loss: 0.0191
Epoch   4 Batch  177/538 - Train Accuracy: 0.9660, Validation Accuracy: 0.9515, Loss: 0.0145
Epoch   4 Batch  178/538 - Train Accuracy: 0.9654, Validation Accuracy: 0.9444, Loss: 0.0182
Epoch   4 Batch  179/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9545, Loss: 0.0143
Epoch   4 Batch  180/538 - Train Accuracy: 0.9680, Validation Accuracy: 0.9585, Loss: 0.0177
Epoch   4 Batch  181/538 - Train Accuracy: 0.9627, Validation Accuracy: 0.9585, Loss: 0.0245
Epoch   4 Batch  182/538 - Train Accuracy: 0.9836, Validation Accuracy: 0.9609, Loss: 0.0135
Epoch   4 Batch  183/538 - Train Accuracy: 0.9834, Validation Accuracy: 0.9631, Loss: 0.0146
Epoch   4 Batch  184/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9624, Loss: 0.0164
Epoch   4 Batch  185/538 - Train Accuracy: 0.9859, Validation Accuracy: 0.9627, Loss: 0.0131
Epoch   4 Batch  186/538 - Train Accuracy: 0.9808, Validation Accuracy: 0.9602, Loss: 0.0145
Epoch   4 Batch  187/538 - Train Accuracy: 0.9853, Validation Accuracy: 0.9648, Loss: 0.0157
Epoch   4 Batch  188/538 - Train Accuracy: 0.9783, Validation Accuracy: 0.9673, Loss: 0.0128
Epoch   4 Batch  189/538 - Train Accuracy: 0.9748, Validation Accuracy: 0.9714, Loss: 0.0160
Epoch   4 Batch  190/538 - Train Accuracy: 0.9598, Validation Accuracy: 0.9739, Loss: 0.0246
Epoch   4 Batch  191/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9709, Loss: 0.0152
Epoch   4 Batch  192/538 - Train Accuracy: 0.9764, Validation Accuracy: 0.9705, Loss: 0.0146
Epoch   4 Batch  193/538 - Train Accuracy: 0.9728, Validation Accuracy: 0.9707, Loss: 0.0160
Epoch   4 Batch  194/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9666, Loss: 0.0193
Epoch   4 Batch  195/538 - Train Accuracy: 0.9864, Validation Accuracy: 0.9563, Loss: 0.0228
Epoch   4 Batch  196/538 - Train Accuracy: 0.9730, Validation Accuracy: 0.9554, Loss: 0.0134
Epoch   4 Batch  197/538 - Train Accuracy: 0.9810, Validation Accuracy: 0.9647, Loss: 0.0162
Epoch   4 Batch  198/538 - Train Accuracy: 0.9710, Validation Accuracy: 0.9634, Loss: 0.0164
Epoch   4 Batch  199/538 - Train Accuracy: 0.9678, Validation Accuracy: 0.9634, Loss: 0.0157
Epoch   4 Batch  200/538 - Train Accuracy: 0.9740, Validation Accuracy: 0.9641, Loss: 0.0150
Epoch   4 Batch  201/538 - Train Accuracy: 0.9591, Validation Accuracy: 0.9647, Loss: 0.0219
Epoch   4 Batch  202/538 - Train Accuracy: 0.9766, Validation Accuracy: 0.9636, Loss: 0.0166
Epoch   4 Batch  203/538 - Train Accuracy: 0.9736, Validation Accuracy: 0.9688, Loss: 0.0165
Epoch   4 Batch  204/538 - Train Accuracy: 0.9580, Validation Accuracy: 0.9711, Loss: 0.0281
Epoch   4 Batch  205/538 - Train Accuracy: 0.9684, Validation Accuracy: 0.9576, Loss: 0.0166
Epoch   4 Batch  206/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9551, Loss: 0.0158
Epoch   4 Batch  207/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9450, Loss: 0.0180
Epoch   4 Batch  208/538 - Train Accuracy: 0.9717, Validation Accuracy: 0.9505, Loss: 0.0243
Epoch   4 Batch  209/538 - Train Accuracy: 0.9736, Validation Accuracy: 0.9540, Loss: 0.0180
Epoch   4 Batch  210/538 - Train Accuracy: 0.9794, Validation Accuracy: 0.9682, Loss: 0.0153
Epoch   4 Batch  211/538 - Train Accuracy: 0.9822, Validation Accuracy: 0.9721, Loss: 0.0166
Epoch   4 Batch  212/538 - Train Accuracy: 0.9844, Validation Accuracy: 0.9709, Loss: 0.0137
Epoch   4 Batch  213/538 - Train Accuracy: 0.9807, Validation Accuracy: 0.9705, Loss: 0.0152
Epoch   4 Batch  214/538 - Train Accuracy: 0.9809, Validation Accuracy: 0.9679, Loss: 0.0127
Epoch   4 Batch  215/538 - Train Accuracy: 0.9727, Validation Accuracy: 0.9609, Loss: 0.0158
Epoch   4 Batch  216/538 - Train Accuracy: 0.9678, Validation Accuracy: 0.9609, Loss: 0.0176
Epoch   4 Batch  217/538 - Train Accuracy: 0.9821, Validation Accuracy: 0.9650, Loss: 0.0181
Epoch   4 Batch  218/538 - Train Accuracy: 0.9723, Validation Accuracy: 0.9616, Loss: 0.0168
Epoch   4 Batch  219/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9654, Loss: 0.0160
Epoch   4 Batch  220/538 - Train Accuracy: 0.9695, Validation Accuracy: 0.9652, Loss: 0.0197
Epoch   4 Batch  221/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9625, Loss: 0.0125
Epoch   4 Batch  222/538 - Train Accuracy: 0.9701, Validation Accuracy: 0.9640, Loss: 0.0133
Epoch   4 Batch  223/538 - Train Accuracy: 0.9785, Validation Accuracy: 0.9638, Loss: 0.0159
Epoch   4 Batch  224/538 - Train Accuracy: 0.9703, Validation Accuracy: 0.9709, Loss: 0.0184
Epoch   4 Batch  225/538 - Train Accuracy: 0.9797, Validation Accuracy: 0.9711, Loss: 0.0150
Epoch   4 Batch  226/538 - Train Accuracy: 0.9585, Validation Accuracy: 0.9636, Loss: 0.0192
Epoch   4 Batch  227/538 - Train Accuracy: 0.9686, Validation Accuracy: 0.9641, Loss: 0.0165
Epoch   4 Batch  228/538 - Train Accuracy: 0.9753, Validation Accuracy: 0.9668, Loss: 0.0184
Epoch   4 Batch  229/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9638, Loss: 0.0152
Epoch   4 Batch  230/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9608, Loss: 0.0161
Epoch   4 Batch  231/538 - Train Accuracy: 0.9729, Validation Accuracy: 0.9652, Loss: 0.0174
Epoch   4 Batch  232/538 - Train Accuracy: 0.9670, Validation Accuracy: 0.9677, Loss: 0.0175
Epoch   4 Batch  233/538 - Train Accuracy: 0.9844, Validation Accuracy: 0.9664, Loss: 0.0147
Epoch   4 Batch  234/538 - Train Accuracy: 0.9855, Validation Accuracy: 0.9641, Loss: 0.0126
Epoch   4 Batch  235/538 - Train Accuracy: 0.9736, Validation Accuracy: 0.9679, Loss: 0.0154
Epoch   4 Batch  236/538 - Train Accuracy: 0.9834, Validation Accuracy: 0.9679, Loss: 0.0137
Epoch   4 Batch  237/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9668, Loss: 0.0108
Epoch   4 Batch  238/538 - Train Accuracy: 0.9704, Validation Accuracy: 0.9648, Loss: 0.0177
Epoch   4 Batch  239/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9673, Loss: 0.0133
Epoch   4 Batch  240/538 - Train Accuracy: 0.9670, Validation Accuracy: 0.9718, Loss: 0.0170
Epoch   4 Batch  241/538 - Train Accuracy: 0.9607, Validation Accuracy: 0.9659, Loss: 0.0230
Epoch   4 Batch  242/538 - Train Accuracy: 0.9793, Validation Accuracy: 0.9627, Loss: 0.0147
Epoch   4 Batch  243/538 - Train Accuracy: 0.9677, Validation Accuracy: 0.9597, Loss: 0.0158
Epoch   4 Batch  244/538 - Train Accuracy: 0.9669, Validation Accuracy: 0.9652, Loss: 0.0144
Epoch   4 Batch  245/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9634, Loss: 0.0200
Epoch   4 Batch  246/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9593, Loss: 0.0118
Epoch   4 Batch  247/538 - Train Accuracy: 0.9773, Validation Accuracy: 0.9636, Loss: 0.0176
Epoch   4 Batch  248/538 - Train Accuracy: 0.9668, Validation Accuracy: 0.9661, Loss: 0.0222
Epoch   4 Batch  249/538 - Train Accuracy: 0.9834, Validation Accuracy: 0.9696, Loss: 0.0126
Epoch   4 Batch  250/538 - Train Accuracy: 0.9795, Validation Accuracy: 0.9673, Loss: 0.0180
Epoch   4 Batch  251/538 - Train Accuracy: 0.9881, Validation Accuracy: 0.9659, Loss: 0.0125
Epoch   4 Batch  252/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9668, Loss: 0.0161
Epoch   4 Batch  253/538 - Train Accuracy: 0.9728, Validation Accuracy: 0.9656, Loss: 0.0143
Epoch   4 Batch  254/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9586, Loss: 0.0215
Epoch   4 Batch  255/538 - Train Accuracy: 0.9902, Validation Accuracy: 0.9576, Loss: 0.0120
Epoch   4 Batch  256/538 - Train Accuracy: 0.9719, Validation Accuracy: 0.9561, Loss: 0.0170
Epoch   4 Batch  257/538 - Train Accuracy: 0.9769, Validation Accuracy: 0.9522, Loss: 0.0170
Epoch   4 Batch  258/538 - Train Accuracy: 0.9608, Validation Accuracy: 0.9627, Loss: 0.0200
Epoch   4 Batch  259/538 - Train Accuracy: 0.9903, Validation Accuracy: 0.9569, Loss: 0.0139
Epoch   4 Batch  260/538 - Train Accuracy: 0.9611, Validation Accuracy: 0.9533, Loss: 0.0188
Epoch   4 Batch  261/538 - Train Accuracy: 0.9693, Validation Accuracy: 0.9531, Loss: 0.0211
Epoch   4 Batch  262/538 - Train Accuracy: 0.9723, Validation Accuracy: 0.9538, Loss: 0.0184
Epoch   4 Batch  263/538 - Train Accuracy: 0.9592, Validation Accuracy: 0.9521, Loss: 0.0179
Epoch   4 Batch  264/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9551, Loss: 0.0192
Epoch   4 Batch  265/538 - Train Accuracy: 0.9635, Validation Accuracy: 0.9641, Loss: 0.0204
Epoch   4 Batch  266/538 - Train Accuracy: 0.9695, Validation Accuracy: 0.9668, Loss: 0.0175
Epoch   4 Batch  267/538 - Train Accuracy: 0.9695, Validation Accuracy: 0.9693, Loss: 0.0162
Epoch   4 Batch  268/538 - Train Accuracy: 0.9803, Validation Accuracy: 0.9668, Loss: 0.0120
Epoch   4 Batch  269/538 - Train Accuracy: 0.9826, Validation Accuracy: 0.9622, Loss: 0.0165
Epoch   4 Batch  270/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9599, Loss: 0.0165
Epoch   4 Batch  271/538 - Train Accuracy: 0.9775, Validation Accuracy: 0.9574, Loss: 0.0123
Epoch   4 Batch  272/538 - Train Accuracy: 0.9748, Validation Accuracy: 0.9590, Loss: 0.0166
Epoch   4 Batch  273/538 - Train Accuracy: 0.9729, Validation Accuracy: 0.9586, Loss: 0.0165
Epoch   4 Batch  274/538 - Train Accuracy: 0.9537, Validation Accuracy: 0.9435, Loss: 0.0186
Epoch   4 Batch  275/538 - Train Accuracy: 0.9566, Validation Accuracy: 0.9482, Loss: 0.0209
Epoch   4 Batch  276/538 - Train Accuracy: 0.9645, Validation Accuracy: 0.9487, Loss: 0.0214
Epoch   4 Batch  277/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9517, Loss: 0.0121
Epoch   4 Batch  278/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9540, Loss: 0.0142
Epoch   4 Batch  279/538 - Train Accuracy: 0.9590, Validation Accuracy: 0.9545, Loss: 0.0165
Epoch   4 Batch  280/538 - Train Accuracy: 0.9792, Validation Accuracy: 0.9616, Loss: 0.0132
Epoch   4 Batch  281/538 - Train Accuracy: 0.9713, Validation Accuracy: 0.9624, Loss: 0.0172
Epoch   4 Batch  282/538 - Train Accuracy: 0.9756, Validation Accuracy: 0.9664, Loss: 0.0180
Epoch   4 Batch  283/538 - Train Accuracy: 0.9881, Validation Accuracy: 0.9705, Loss: 0.0162
Epoch   4 Batch  284/538 - Train Accuracy: 0.9621, Validation Accuracy: 0.9748, Loss: 0.0183
Epoch   4 Batch  285/538 - Train Accuracy: 0.9647, Validation Accuracy: 0.9725, Loss: 0.0138
Epoch   4 Batch  286/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9703, Loss: 0.0240
Epoch   4 Batch  287/538 - Train Accuracy: 0.9849, Validation Accuracy: 0.9693, Loss: 0.0113
Epoch   4 Batch  288/538 - Train Accuracy: 0.9676, Validation Accuracy: 0.9688, Loss: 0.0159
Epoch   4 Batch  289/538 - Train Accuracy: 0.9719, Validation Accuracy: 0.9712, Loss: 0.0159
Epoch   4 Batch  290/538 - Train Accuracy: 0.9879, Validation Accuracy: 0.9648, Loss: 0.0133
Epoch   4 Batch  291/538 - Train Accuracy: 0.9896, Validation Accuracy: 0.9620, Loss: 0.0149
Epoch   4 Batch  292/538 - Train Accuracy: 0.9825, Validation Accuracy: 0.9616, Loss: 0.0098
Epoch   4 Batch  293/538 - Train Accuracy: 0.9736, Validation Accuracy: 0.9691, Loss: 0.0171
Epoch   4 Batch  294/538 - Train Accuracy: 0.9860, Validation Accuracy: 0.9679, Loss: 0.0152
Epoch   4 Batch  295/538 - Train Accuracy: 0.9703, Validation Accuracy: 0.9718, Loss: 0.0142
Epoch   4 Batch  296/538 - Train Accuracy: 0.9609, Validation Accuracy: 0.9702, Loss: 0.0236
Epoch   4 Batch  297/538 - Train Accuracy: 0.9844, Validation Accuracy: 0.9680, Loss: 0.0142
Epoch   4 Batch  298/538 - Train Accuracy: 0.9851, Validation Accuracy: 0.9684, Loss: 0.0149
Epoch   4 Batch  299/538 - Train Accuracy: 0.9712, Validation Accuracy: 0.9664, Loss: 0.0188
Epoch   4 Batch  300/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9695, Loss: 0.0154
Epoch   4 Batch  301/538 - Train Accuracy: 0.9624, Validation Accuracy: 0.9686, Loss: 0.0189
Epoch   4 Batch  302/538 - Train Accuracy: 0.9784, Validation Accuracy: 0.9643, Loss: 0.0208
Epoch   4 Batch  303/538 - Train Accuracy: 0.9769, Validation Accuracy: 0.9650, Loss: 0.0163
Epoch   4 Batch  304/538 - Train Accuracy: 0.9775, Validation Accuracy: 0.9661, Loss: 0.0196
Epoch   4 Batch  305/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9657, Loss: 0.0139
Epoch   4 Batch  306/538 - Train Accuracy: 0.9728, Validation Accuracy: 0.9679, Loss: 0.0150
Epoch   4 Batch  307/538 - Train Accuracy: 0.9816, Validation Accuracy: 0.9636, Loss: 0.0126
Epoch   4 Batch  308/538 - Train Accuracy: 0.9786, Validation Accuracy: 0.9684, Loss: 0.0135
Epoch   4 Batch  309/538 - Train Accuracy: 0.9795, Validation Accuracy: 0.9688, Loss: 0.0145
Epoch   4 Batch  310/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9675, Loss: 0.0224
Epoch   4 Batch  311/538 - Train Accuracy: 0.9725, Validation Accuracy: 0.9618, Loss: 0.0159
Epoch   4 Batch  312/538 - Train Accuracy: 0.9734, Validation Accuracy: 0.9629, Loss: 0.0143
Epoch   4 Batch  313/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9679, Loss: 0.0169
Epoch   4 Batch  314/538 - Train Accuracy: 0.9873, Validation Accuracy: 0.9668, Loss: 0.0141
Epoch   4 Batch  315/538 - Train Accuracy: 0.9738, Validation Accuracy: 0.9657, Loss: 0.0144
Epoch   4 Batch  316/538 - Train Accuracy: 0.9706, Validation Accuracy: 0.9680, Loss: 0.0124
Epoch   4 Batch  317/538 - Train Accuracy: 0.9744, Validation Accuracy: 0.9663, Loss: 0.0157
Epoch   4 Batch  318/538 - Train Accuracy: 0.9710, Validation Accuracy: 0.9659, Loss: 0.0137
Epoch   4 Batch  319/538 - Train Accuracy: 0.9767, Validation Accuracy: 0.9673, Loss: 0.0203
Epoch   4 Batch  320/538 - Train Accuracy: 0.9730, Validation Accuracy: 0.9618, Loss: 0.0143
Epoch   4 Batch  321/538 - Train Accuracy: 0.9654, Validation Accuracy: 0.9613, Loss: 0.0142
Epoch   4 Batch  322/538 - Train Accuracy: 0.9816, Validation Accuracy: 0.9572, Loss: 0.0179
Epoch   4 Batch  323/538 - Train Accuracy: 0.9847, Validation Accuracy: 0.9586, Loss: 0.0133
Epoch   4 Batch  324/538 - Train Accuracy: 0.9881, Validation Accuracy: 0.9664, Loss: 0.0137
Epoch   4 Batch  325/538 - Train Accuracy: 0.9734, Validation Accuracy: 0.9668, Loss: 0.0153
Epoch   4 Batch  326/538 - Train Accuracy: 0.9783, Validation Accuracy: 0.9679, Loss: 0.0156
Epoch   4 Batch  327/538 - Train Accuracy: 0.9787, Validation Accuracy: 0.9638, Loss: 0.0159
Epoch   4 Batch  328/538 - Train Accuracy: 0.9874, Validation Accuracy: 0.9636, Loss: 0.0128
Epoch   4 Batch  329/538 - Train Accuracy: 0.9782, Validation Accuracy: 0.9629, Loss: 0.0127
Epoch   4 Batch  330/538 - Train Accuracy: 0.9838, Validation Accuracy: 0.9581, Loss: 0.0168
Epoch   4 Batch  331/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9634, Loss: 0.0191
Epoch   4 Batch  332/538 - Train Accuracy: 0.9793, Validation Accuracy: 0.9663, Loss: 0.0173
Epoch   4 Batch  333/538 - Train Accuracy: 0.9788, Validation Accuracy: 0.9712, Loss: 0.0200
Epoch   4 Batch  334/538 - Train Accuracy: 0.9870, Validation Accuracy: 0.9703, Loss: 0.0129
Epoch   4 Batch  335/538 - Train Accuracy: 0.9782, Validation Accuracy: 0.9743, Loss: 0.0144
Epoch   4 Batch  336/538 - Train Accuracy: 0.9790, Validation Accuracy: 0.9727, Loss: 0.0138
Epoch   4 Batch  337/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9679, Loss: 0.0157
Epoch   4 Batch  338/538 - Train Accuracy: 0.9794, Validation Accuracy: 0.9666, Loss: 0.0150
Epoch   4 Batch  339/538 - Train Accuracy: 0.9686, Validation Accuracy: 0.9686, Loss: 0.0149
Epoch   4 Batch  340/538 - Train Accuracy: 0.9789, Validation Accuracy: 0.9672, Loss: 0.0148
Epoch   4 Batch  341/538 - Train Accuracy: 0.9828, Validation Accuracy: 0.9677, Loss: 0.0145
Epoch   4 Batch  342/538 - Train Accuracy: 0.9652, Validation Accuracy: 0.9718, Loss: 0.0167
Epoch   4 Batch  343/538 - Train Accuracy: 0.9850, Validation Accuracy: 0.9696, Loss: 0.0160
Epoch   4 Batch  344/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9702, Loss: 0.0142
Epoch   4 Batch  345/538 - Train Accuracy: 0.9836, Validation Accuracy: 0.9721, Loss: 0.0145
Epoch   4 Batch  346/538 - Train Accuracy: 0.9688, Validation Accuracy: 0.9723, Loss: 0.0189
Epoch   4 Batch  347/538 - Train Accuracy: 0.9816, Validation Accuracy: 0.9702, Loss: 0.0162
Epoch   4 Batch  348/538 - Train Accuracy: 0.9786, Validation Accuracy: 0.9799, Loss: 0.0114
Epoch   4 Batch  349/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9730, Loss: 0.0118
Epoch   4 Batch  350/538 - Train Accuracy: 0.9833, Validation Accuracy: 0.9712, Loss: 0.0171
Epoch   4 Batch  351/538 - Train Accuracy: 0.9734, Validation Accuracy: 0.9719, Loss: 0.0166
Epoch   4 Batch  352/538 - Train Accuracy: 0.9704, Validation Accuracy: 0.9698, Loss: 0.0321
Epoch   4 Batch  353/538 - Train Accuracy: 0.9748, Validation Accuracy: 0.9711, Loss: 0.0159
Epoch   4 Batch  354/538 - Train Accuracy: 0.9906, Validation Accuracy: 0.9721, Loss: 0.0131
Epoch   4 Batch  355/538 - Train Accuracy: 0.9861, Validation Accuracy: 0.9680, Loss: 0.0147
Epoch   4 Batch  356/538 - Train Accuracy: 0.9881, Validation Accuracy: 0.9675, Loss: 0.0114
Epoch   4 Batch  357/538 - Train Accuracy: 0.9740, Validation Accuracy: 0.9707, Loss: 0.0154
Epoch   4 Batch  358/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9682, Loss: 0.0112
Epoch   4 Batch  359/538 - Train Accuracy: 0.9769, Validation Accuracy: 0.9695, Loss: 0.0158
Epoch   4 Batch  360/538 - Train Accuracy: 0.9750, Validation Accuracy: 0.9686, Loss: 0.0137
Epoch   4 Batch  361/538 - Train Accuracy: 0.9816, Validation Accuracy: 0.9714, Loss: 0.0152
Epoch   4 Batch  362/538 - Train Accuracy: 0.9810, Validation Accuracy: 0.9625, Loss: 0.0126
Epoch   4 Batch  363/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9625, Loss: 0.0156
Epoch   4 Batch  364/538 - Train Accuracy: 0.9713, Validation Accuracy: 0.9652, Loss: 0.0178
Epoch   4 Batch  365/538 - Train Accuracy: 0.9728, Validation Accuracy: 0.9656, Loss: 0.0149
Epoch   4 Batch  366/538 - Train Accuracy: 0.9764, Validation Accuracy: 0.9680, Loss: 0.0159
Epoch   4 Batch  367/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9577, Loss: 0.0127
Epoch   4 Batch  368/538 - Train Accuracy: 0.9897, Validation Accuracy: 0.9590, Loss: 0.0127
Epoch   4 Batch  369/538 - Train Accuracy: 0.9736, Validation Accuracy: 0.9581, Loss: 0.0141
Epoch   4 Batch  370/538 - Train Accuracy: 0.9723, Validation Accuracy: 0.9554, Loss: 0.0149
Epoch   4 Batch  371/538 - Train Accuracy: 0.9901, Validation Accuracy: 0.9558, Loss: 0.0130
Epoch   4 Batch  372/538 - Train Accuracy: 0.9742, Validation Accuracy: 0.9577, Loss: 0.0175
Epoch   4 Batch  373/538 - Train Accuracy: 0.9750, Validation Accuracy: 0.9588, Loss: 0.0125
Epoch   4 Batch  374/538 - Train Accuracy: 0.9736, Validation Accuracy: 0.9588, Loss: 0.0139
Epoch   4 Batch  375/538 - Train Accuracy: 0.9844, Validation Accuracy: 0.9599, Loss: 0.0136
Epoch   4 Batch  376/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9531, Loss: 0.0154
Epoch   4 Batch  377/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9586, Loss: 0.0183
Epoch   4 Batch  378/538 - Train Accuracy: 0.9786, Validation Accuracy: 0.9567, Loss: 0.0108
Epoch   4 Batch  379/538 - Train Accuracy: 0.9766, Validation Accuracy: 0.9553, Loss: 0.0143
Epoch   4 Batch  380/538 - Train Accuracy: 0.9852, Validation Accuracy: 0.9606, Loss: 0.0131
Epoch   4 Batch  381/538 - Train Accuracy: 0.9834, Validation Accuracy: 0.9602, Loss: 0.0127
Epoch   4 Batch  382/538 - Train Accuracy: 0.9646, Validation Accuracy: 0.9608, Loss: 0.0216
Epoch   4 Batch  383/538 - Train Accuracy: 0.9824, Validation Accuracy: 0.9629, Loss: 0.0137
Epoch   4 Batch  384/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9654, Loss: 0.0151
Epoch   4 Batch  385/538 - Train Accuracy: 0.9766, Validation Accuracy: 0.9632, Loss: 0.0149
Epoch   4 Batch  386/538 - Train Accuracy: 0.9832, Validation Accuracy: 0.9654, Loss: 0.0153
Epoch   4 Batch  387/538 - Train Accuracy: 0.9801, Validation Accuracy: 0.9703, Loss: 0.0135
Epoch   4 Batch  388/538 - Train Accuracy: 0.9797, Validation Accuracy: 0.9698, Loss: 0.0144
Epoch   4 Batch  389/538 - Train Accuracy: 0.9623, Validation Accuracy: 0.9615, Loss: 0.0161
Epoch   4 Batch  390/538 - Train Accuracy: 0.9665, Validation Accuracy: 0.9558, Loss: 0.0139
Epoch   4 Batch  391/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9556, Loss: 0.0152
Epoch   4 Batch  392/538 - Train Accuracy: 0.9821, Validation Accuracy: 0.9638, Loss: 0.0124
Epoch   4 Batch  393/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9696, Loss: 0.0168
Epoch   4 Batch  394/538 - Train Accuracy: 0.9744, Validation Accuracy: 0.9737, Loss: 0.0187
Epoch   4 Batch  395/538 - Train Accuracy: 0.9848, Validation Accuracy: 0.9702, Loss: 0.0149
Epoch   4 Batch  396/538 - Train Accuracy: 0.9730, Validation Accuracy: 0.9703, Loss: 0.0136
Epoch   4 Batch  397/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9728, Loss: 0.0149
Epoch   4 Batch  398/538 - Train Accuracy: 0.9734, Validation Accuracy: 0.9709, Loss: 0.0148
Epoch   4 Batch  399/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9734, Loss: 0.0169
Epoch   4 Batch  400/538 - Train Accuracy: 0.9862, Validation Accuracy: 0.9750, Loss: 0.0151
Epoch   4 Batch  401/538 - Train Accuracy: 0.9928, Validation Accuracy: 0.9712, Loss: 0.0101
Epoch   4 Batch  402/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9689, Loss: 0.0140
Epoch   4 Batch  403/538 - Train Accuracy: 0.9684, Validation Accuracy: 0.9705, Loss: 0.0167
Epoch   4 Batch  404/538 - Train Accuracy: 0.9727, Validation Accuracy: 0.9702, Loss: 0.0164
Epoch   4 Batch  405/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9664, Loss: 0.0124
Epoch   4 Batch  406/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9664, Loss: 0.0140
Epoch   4 Batch  407/538 - Train Accuracy: 0.9793, Validation Accuracy: 0.9613, Loss: 0.0162
Epoch   4 Batch  408/538 - Train Accuracy: 0.9631, Validation Accuracy: 0.9585, Loss: 0.0180
Epoch   4 Batch  409/538 - Train Accuracy: 0.9740, Validation Accuracy: 0.9620, Loss: 0.0141
Epoch   4 Batch  410/538 - Train Accuracy: 0.9764, Validation Accuracy: 0.9636, Loss: 0.0146
Epoch   4 Batch  411/538 - Train Accuracy: 0.9775, Validation Accuracy: 0.9664, Loss: 0.0182
Epoch   4 Batch  412/538 - Train Accuracy: 0.9862, Validation Accuracy: 0.9631, Loss: 0.0106
Epoch   4 Batch  413/538 - Train Accuracy: 0.9711, Validation Accuracy: 0.9608, Loss: 0.0142
Epoch   4 Batch  414/538 - Train Accuracy: 0.9566, Validation Accuracy: 0.9673, Loss: 0.0227
Epoch   4 Batch  415/538 - Train Accuracy: 0.9643, Validation Accuracy: 0.9693, Loss: 0.0160
Epoch   4 Batch  416/538 - Train Accuracy: 0.9810, Validation Accuracy: 0.9682, Loss: 0.0166
Epoch   4 Batch  417/538 - Train Accuracy: 0.9838, Validation Accuracy: 0.9638, Loss: 0.0133
Epoch   4 Batch  418/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9643, Loss: 0.0179
Epoch   4 Batch  419/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9647, Loss: 0.0148
Epoch   4 Batch  420/538 - Train Accuracy: 0.9797, Validation Accuracy: 0.9663, Loss: 0.0176
Epoch   4 Batch  421/538 - Train Accuracy: 0.9719, Validation Accuracy: 0.9597, Loss: 0.0118
Epoch   4 Batch  422/538 - Train Accuracy: 0.9764, Validation Accuracy: 0.9593, Loss: 0.0162
Epoch   4 Batch  423/538 - Train Accuracy: 0.9730, Validation Accuracy: 0.9538, Loss: 0.0174
Epoch   4 Batch  424/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9618, Loss: 0.0211
Epoch   4 Batch  425/538 - Train Accuracy: 0.9756, Validation Accuracy: 0.9680, Loss: 0.0220
Epoch   4 Batch  426/538 - Train Accuracy: 0.9676, Validation Accuracy: 0.9673, Loss: 0.0174
Epoch   4 Batch  427/538 - Train Accuracy: 0.9783, Validation Accuracy: 0.9632, Loss: 0.0160
Epoch   4 Batch  428/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9613, Loss: 0.0105
Epoch   4 Batch  429/538 - Train Accuracy: 0.9827, Validation Accuracy: 0.9666, Loss: 0.0142
Epoch   4 Batch  430/538 - Train Accuracy: 0.9732, Validation Accuracy: 0.9718, Loss: 0.0164
Epoch   4 Batch  431/538 - Train Accuracy: 0.9582, Validation Accuracy: 0.9691, Loss: 0.0182
Epoch   4 Batch  432/538 - Train Accuracy: 0.9672, Validation Accuracy: 0.9705, Loss: 0.0179
Epoch   4 Batch  433/538 - Train Accuracy: 0.9605, Validation Accuracy: 0.9688, Loss: 0.0326
Epoch   4 Batch  434/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9643, Loss: 0.0136
Epoch   4 Batch  435/538 - Train Accuracy: 0.9707, Validation Accuracy: 0.9620, Loss: 0.0169
Epoch   4 Batch  436/538 - Train Accuracy: 0.9611, Validation Accuracy: 0.9583, Loss: 0.0188
Epoch   4 Batch  437/538 - Train Accuracy: 0.9842, Validation Accuracy: 0.9595, Loss: 0.0131
Epoch   4 Batch  438/538 - Train Accuracy: 0.9771, Validation Accuracy: 0.9608, Loss: 0.0123
Epoch   4 Batch  439/538 - Train Accuracy: 0.9906, Validation Accuracy: 0.9668, Loss: 0.0148
Epoch   4 Batch  440/538 - Train Accuracy: 0.9764, Validation Accuracy: 0.9661, Loss: 0.0144
Epoch   4 Batch  441/538 - Train Accuracy: 0.9709, Validation Accuracy: 0.9663, Loss: 0.0202
Epoch   4 Batch  442/538 - Train Accuracy: 0.9794, Validation Accuracy: 0.9672, Loss: 0.0146
Epoch   4 Batch  443/538 - Train Accuracy: 0.9747, Validation Accuracy: 0.9680, Loss: 0.0156
Epoch   4 Batch  444/538 - Train Accuracy: 0.9734, Validation Accuracy: 0.9625, Loss: 0.0132
Epoch   4 Batch  445/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9613, Loss: 0.0119
Epoch   4 Batch  446/538 - Train Accuracy: 0.9732, Validation Accuracy: 0.9636, Loss: 0.0136
Epoch   4 Batch  447/538 - Train Accuracy: 0.9787, Validation Accuracy: 0.9604, Loss: 0.0161
Epoch   4 Batch  448/538 - Train Accuracy: 0.9674, Validation Accuracy: 0.9634, Loss: 0.0164
Epoch   4 Batch  449/538 - Train Accuracy: 0.9859, Validation Accuracy: 0.9684, Loss: 0.0160
Epoch   4 Batch  450/538 - Train Accuracy: 0.9643, Validation Accuracy: 0.9711, Loss: 0.0242
Epoch   4 Batch  451/538 - Train Accuracy: 0.9639, Validation Accuracy: 0.9700, Loss: 0.0146
Epoch   4 Batch  452/538 - Train Accuracy: 0.9713, Validation Accuracy: 0.9721, Loss: 0.0142
Epoch   4 Batch  453/538 - Train Accuracy: 0.9711, Validation Accuracy: 0.9719, Loss: 0.0168
Epoch   4 Batch  454/538 - Train Accuracy: 0.9773, Validation Accuracy: 0.9599, Loss: 0.0181
Epoch   4 Batch  455/538 - Train Accuracy: 0.9835, Validation Accuracy: 0.9522, Loss: 0.0160
Epoch   4 Batch  456/538 - Train Accuracy: 0.9749, Validation Accuracy: 0.9512, Loss: 0.0254
Epoch   4 Batch  457/538 - Train Accuracy: 0.9764, Validation Accuracy: 0.9540, Loss: 0.0125
Epoch   4 Batch  458/538 - Train Accuracy: 0.9795, Validation Accuracy: 0.9657, Loss: 0.0149
Epoch   4 Batch  459/538 - Train Accuracy: 0.9805, Validation Accuracy: 0.9703, Loss: 0.0111
Epoch   4 Batch  460/538 - Train Accuracy: 0.9686, Validation Accuracy: 0.9682, Loss: 0.0159
Epoch   4 Batch  461/538 - Train Accuracy: 0.9764, Validation Accuracy: 0.9680, Loss: 0.0169
Epoch   4 Batch  462/538 - Train Accuracy: 0.9767, Validation Accuracy: 0.9654, Loss: 0.0140
Epoch   4 Batch  463/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9647, Loss: 0.0182
Epoch   4 Batch  464/538 - Train Accuracy: 0.9846, Validation Accuracy: 0.9615, Loss: 0.0143
Epoch   4 Batch  465/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9648, Loss: 0.0158
Epoch   4 Batch  466/538 - Train Accuracy: 0.9721, Validation Accuracy: 0.9634, Loss: 0.0148
Epoch   4 Batch  467/538 - Train Accuracy: 0.9719, Validation Accuracy: 0.9638, Loss: 0.0156
Epoch   4 Batch  468/538 - Train Accuracy: 0.9875, Validation Accuracy: 0.9675, Loss: 0.0201
Epoch   4 Batch  469/538 - Train Accuracy: 0.9762, Validation Accuracy: 0.9663, Loss: 0.0166
Epoch   4 Batch  470/538 - Train Accuracy: 0.9734, Validation Accuracy: 0.9666, Loss: 0.0165
Epoch   4 Batch  471/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9650, Loss: 0.0098
Epoch   4 Batch  472/538 - Train Accuracy: 0.9959, Validation Accuracy: 0.9656, Loss: 0.0094
Epoch   4 Batch  473/538 - Train Accuracy: 0.9748, Validation Accuracy: 0.9606, Loss: 0.0154
Epoch   4 Batch  474/538 - Train Accuracy: 0.9855, Validation Accuracy: 0.9608, Loss: 0.0130
Epoch   4 Batch  475/538 - Train Accuracy: 0.9827, Validation Accuracy: 0.9602, Loss: 0.0140
Epoch   4 Batch  476/538 - Train Accuracy: 0.9750, Validation Accuracy: 0.9686, Loss: 0.0158
Epoch   4 Batch  477/538 - Train Accuracy: 0.9791, Validation Accuracy: 0.9656, Loss: 0.0158
Epoch   4 Batch  478/538 - Train Accuracy: 0.9887, Validation Accuracy: 0.9703, Loss: 0.0101
Epoch   4 Batch  479/538 - Train Accuracy: 0.9766, Validation Accuracy: 0.9675, Loss: 0.0170
Epoch   4 Batch  480/538 - Train Accuracy: 0.9864, Validation Accuracy: 0.9588, Loss: 0.0144
Epoch   4 Batch  481/538 - Train Accuracy: 0.9767, Validation Accuracy: 0.9595, Loss: 0.0150
Epoch   4 Batch  482/538 - Train Accuracy: 0.9738, Validation Accuracy: 0.9647, Loss: 0.0134
Epoch   4 Batch  483/538 - Train Accuracy: 0.9691, Validation Accuracy: 0.9698, Loss: 0.0162
Epoch   4 Batch  484/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9700, Loss: 0.0168
Epoch   4 Batch  485/538 - Train Accuracy: 0.9788, Validation Accuracy: 0.9732, Loss: 0.0195
Epoch   4 Batch  486/538 - Train Accuracy: 0.9875, Validation Accuracy: 0.9718, Loss: 0.0106
Epoch   4 Batch  487/538 - Train Accuracy: 0.9775, Validation Accuracy: 0.9743, Loss: 0.0099
Epoch   4 Batch  488/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9743, Loss: 0.0132
Epoch   4 Batch  489/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9743, Loss: 0.0163
Epoch   4 Batch  490/538 - Train Accuracy: 0.9680, Validation Accuracy: 0.9696, Loss: 0.0143
Epoch   4 Batch  491/538 - Train Accuracy: 0.9727, Validation Accuracy: 0.9647, Loss: 0.0160
Epoch   4 Batch  492/538 - Train Accuracy: 0.9855, Validation Accuracy: 0.9592, Loss: 0.0138
Epoch   4 Batch  493/538 - Train Accuracy: 0.9702, Validation Accuracy: 0.9613, Loss: 0.0167
Epoch   4 Batch  494/538 - Train Accuracy: 0.9730, Validation Accuracy: 0.9689, Loss: 0.0170
Epoch   4 Batch  495/538 - Train Accuracy: 0.9787, Validation Accuracy: 0.9712, Loss: 0.0177
Epoch   4 Batch  496/538 - Train Accuracy: 0.9787, Validation Accuracy: 0.9709, Loss: 0.0113
Epoch   4 Batch  497/538 - Train Accuracy: 0.9875, Validation Accuracy: 0.9721, Loss: 0.0115
Epoch   4 Batch  498/538 - Train Accuracy: 0.9855, Validation Accuracy: 0.9709, Loss: 0.0126
Epoch   4 Batch  499/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9714, Loss: 0.0155
Epoch   4 Batch  500/538 - Train Accuracy: 0.9794, Validation Accuracy: 0.9753, Loss: 0.0117
Epoch   4 Batch  501/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9755, Loss: 0.0141
Epoch   4 Batch  502/538 - Train Accuracy: 0.9711, Validation Accuracy: 0.9764, Loss: 0.0153
Epoch   4 Batch  503/538 - Train Accuracy: 0.9862, Validation Accuracy: 0.9762, Loss: 0.0166
Epoch   4 Batch  504/538 - Train Accuracy: 0.9857, Validation Accuracy: 0.9746, Loss: 0.0114
Epoch   4 Batch  505/538 - Train Accuracy: 0.9788, Validation Accuracy: 0.9721, Loss: 0.0108
Epoch   4 Batch  506/538 - Train Accuracy: 0.9792, Validation Accuracy: 0.9691, Loss: 0.0129
Epoch   4 Batch  507/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9719, Loss: 0.0151
Epoch   4 Batch  508/538 - Train Accuracy: 0.9810, Validation Accuracy: 0.9744, Loss: 0.0125
Epoch   4 Batch  509/538 - Train Accuracy: 0.9791, Validation Accuracy: 0.9744, Loss: 0.0174
Epoch   4 Batch  510/538 - Train Accuracy: 0.9827, Validation Accuracy: 0.9686, Loss: 0.0137
Epoch   4 Batch  511/538 - Train Accuracy: 0.9792, Validation Accuracy: 0.9684, Loss: 0.0179
Epoch   4 Batch  512/538 - Train Accuracy: 0.9786, Validation Accuracy: 0.9728, Loss: 0.0176
Epoch   4 Batch  513/538 - Train Accuracy: 0.9701, Validation Accuracy: 0.9721, Loss: 0.0126
Epoch   4 Batch  514/538 - Train Accuracy: 0.9867, Validation Accuracy: 0.9712, Loss: 0.0137
Epoch   4 Batch  515/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9739, Loss: 0.0163
Epoch   4 Batch  516/538 - Train Accuracy: 0.9771, Validation Accuracy: 0.9707, Loss: 0.0146
Epoch   4 Batch  517/538 - Train Accuracy: 0.9782, Validation Accuracy: 0.9725, Loss: 0.0124
Epoch   4 Batch  518/538 - Train Accuracy: 0.9771, Validation Accuracy: 0.9625, Loss: 0.0169
Epoch   4 Batch  519/538 - Train Accuracy: 0.9797, Validation Accuracy: 0.9599, Loss: 0.0143
Epoch   4 Batch  520/538 - Train Accuracy: 0.9676, Validation Accuracy: 0.9659, Loss: 0.0208
Epoch   4 Batch  521/538 - Train Accuracy: 0.9828, Validation Accuracy: 0.9705, Loss: 0.0157
Epoch   4 Batch  522/538 - Train Accuracy: 0.9721, Validation Accuracy: 0.9735, Loss: 0.0110
Epoch   4 Batch  523/538 - Train Accuracy: 0.9854, Validation Accuracy: 0.9755, Loss: 0.0138
Epoch   4 Batch  524/538 - Train Accuracy: 0.9842, Validation Accuracy: 0.9744, Loss: 0.0105
Epoch   4 Batch  525/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9721, Loss: 0.0129
Epoch   4 Batch  526/538 - Train Accuracy: 0.9667, Validation Accuracy: 0.9718, Loss: 0.0156
Epoch   4 Batch  527/538 - Train Accuracy: 0.9879, Validation Accuracy: 0.9709, Loss: 0.0127
Epoch   4 Batch  528/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9716, Loss: 0.0155
Epoch   4 Batch  529/538 - Train Accuracy: 0.9766, Validation Accuracy: 0.9702, Loss: 0.0146
Epoch   4 Batch  530/538 - Train Accuracy: 0.9631, Validation Accuracy: 0.9739, Loss: 0.0163
Epoch   4 Batch  531/538 - Train Accuracy: 0.9756, Validation Accuracy: 0.9709, Loss: 0.0185
Epoch   4 Batch  532/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9773, Loss: 0.0124
Epoch   4 Batch  533/538 - Train Accuracy: 0.9734, Validation Accuracy: 0.9838, Loss: 0.0111
Epoch   4 Batch  534/538 - Train Accuracy: 0.9792, Validation Accuracy: 0.9815, Loss: 0.0105
Epoch   4 Batch  535/538 - Train Accuracy: 0.9805, Validation Accuracy: 0.9805, Loss: 0.0135
Epoch   4 Batch  536/538 - Train Accuracy: 0.9846, Validation Accuracy: 0.9780, Loss: 0.0162
Epoch   5 Batch    0/538 - Train Accuracy: 0.9801, Validation Accuracy: 0.9796, Loss: 0.0130
Epoch   5 Batch    1/538 - Train Accuracy: 0.9805, Validation Accuracy: 0.9783, Loss: 0.0172
Epoch   5 Batch    2/538 - Train Accuracy: 0.9852, Validation Accuracy: 0.9769, Loss: 0.0145
Epoch   5 Batch    3/538 - Train Accuracy: 0.9869, Validation Accuracy: 0.9794, Loss: 0.0116
Epoch   5 Batch    4/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9748, Loss: 0.0139
Epoch   5 Batch    5/538 - Train Accuracy: 0.9792, Validation Accuracy: 0.9739, Loss: 0.0179
Epoch   5 Batch    6/538 - Train Accuracy: 0.9782, Validation Accuracy: 0.9739, Loss: 0.0103
Epoch   5 Batch    7/538 - Train Accuracy: 0.9836, Validation Accuracy: 0.9707, Loss: 0.0136
Epoch   5 Batch    8/538 - Train Accuracy: 0.9855, Validation Accuracy: 0.9702, Loss: 0.0127
Epoch   5 Batch    9/538 - Train Accuracy: 0.9732, Validation Accuracy: 0.9730, Loss: 0.0134
Epoch   5 Batch   10/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9732, Loss: 0.0126
Epoch   5 Batch   11/538 - Train Accuracy: 0.9775, Validation Accuracy: 0.9728, Loss: 0.0140
Epoch   5 Batch   12/538 - Train Accuracy: 0.9895, Validation Accuracy: 0.9677, Loss: 0.0129
Epoch   5 Batch   13/538 - Train Accuracy: 0.9892, Validation Accuracy: 0.9656, Loss: 0.0103
Epoch   5 Batch   14/538 - Train Accuracy: 0.9748, Validation Accuracy: 0.9652, Loss: 0.0118
Epoch   5 Batch   15/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9712, Loss: 0.0122
Epoch   5 Batch   16/538 - Train Accuracy: 0.9857, Validation Accuracy: 0.9686, Loss: 0.0137
Epoch   5 Batch   17/538 - Train Accuracy: 0.9855, Validation Accuracy: 0.9675, Loss: 0.0137
Epoch   5 Batch   18/538 - Train Accuracy: 0.9814, Validation Accuracy: 0.9666, Loss: 0.0214
Epoch   5 Batch   19/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9659, Loss: 0.0133
Epoch   5 Batch   20/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9707, Loss: 0.0158
Epoch   5 Batch   21/538 - Train Accuracy: 0.9846, Validation Accuracy: 0.9743, Loss: 0.0090
Epoch   5 Batch   22/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9727, Loss: 0.0180
Epoch   5 Batch   23/538 - Train Accuracy: 0.9748, Validation Accuracy: 0.9762, Loss: 0.0168
Epoch   5 Batch   24/538 - Train Accuracy: 0.9738, Validation Accuracy: 0.9735, Loss: 0.0172
Epoch   5 Batch   25/538 - Train Accuracy: 0.9711, Validation Accuracy: 0.9691, Loss: 0.0179
Epoch   5 Batch   26/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9675, Loss: 0.0172
Epoch   5 Batch   27/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9682, Loss: 0.0120
Epoch   5 Batch   28/538 - Train Accuracy: 0.9846, Validation Accuracy: 0.9657, Loss: 0.0137
Epoch   5 Batch   29/538 - Train Accuracy: 0.9723, Validation Accuracy: 0.9627, Loss: 0.0105
Epoch   5 Batch   30/538 - Train Accuracy: 0.9635, Validation Accuracy: 0.9586, Loss: 0.0190
Epoch   5 Batch   31/538 - Train Accuracy: 0.9896, Validation Accuracy: 0.9613, Loss: 0.0101
Epoch   5 Batch   32/538 - Train Accuracy: 0.9900, Validation Accuracy: 0.9666, Loss: 0.0085
Epoch   5 Batch   33/538 - Train Accuracy: 0.9678, Validation Accuracy: 0.9679, Loss: 0.0186
Epoch   5 Batch   34/538 - Train Accuracy: 0.9729, Validation Accuracy: 0.9677, Loss: 0.0186
Epoch   5 Batch   35/538 - Train Accuracy: 0.9824, Validation Accuracy: 0.9673, Loss: 0.0129
Epoch   5 Batch   36/538 - Train Accuracy: 0.9918, Validation Accuracy: 0.9703, Loss: 0.0110
Epoch   5 Batch   37/538 - Train Accuracy: 0.9701, Validation Accuracy: 0.9723, Loss: 0.0195
Epoch   5 Batch   38/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9727, Loss: 0.0166
Epoch   5 Batch   39/538 - Train Accuracy: 0.9824, Validation Accuracy: 0.9741, Loss: 0.0132
Epoch   5 Batch   40/538 - Train Accuracy: 0.9767, Validation Accuracy: 0.9744, Loss: 0.0107
Epoch   5 Batch   41/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9703, Loss: 0.0153
Epoch   5 Batch   42/538 - Train Accuracy: 0.9699, Validation Accuracy: 0.9703, Loss: 0.0139
Epoch   5 Batch   43/538 - Train Accuracy: 0.9631, Validation Accuracy: 0.9709, Loss: 0.0145
Epoch   5 Batch   44/538 - Train Accuracy: 0.9803, Validation Accuracy: 0.9743, Loss: 0.0123
Epoch   5 Batch   45/538 - Train Accuracy: 0.9674, Validation Accuracy: 0.9725, Loss: 0.0148
Epoch   5 Batch   46/538 - Train Accuracy: 0.9863, Validation Accuracy: 0.9711, Loss: 0.0114
Epoch   5 Batch   47/538 - Train Accuracy: 0.9764, Validation Accuracy: 0.9689, Loss: 0.0157
Epoch   5 Batch   48/538 - Train Accuracy: 0.9717, Validation Accuracy: 0.9737, Loss: 0.0164
Epoch   5 Batch   49/538 - Train Accuracy: 0.9844, Validation Accuracy: 0.9670, Loss: 0.0134
Epoch   5 Batch   50/538 - Train Accuracy: 0.9732, Validation Accuracy: 0.9656, Loss: 0.0160
Epoch   5 Batch   51/538 - Train Accuracy: 0.9856, Validation Accuracy: 0.9672, Loss: 0.0177
Epoch   5 Batch   52/538 - Train Accuracy: 0.9881, Validation Accuracy: 0.9650, Loss: 0.0126
Epoch   5 Batch   53/538 - Train Accuracy: 0.9615, Validation Accuracy: 0.9622, Loss: 0.0167
Epoch   5 Batch   54/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9688, Loss: 0.0123
Epoch   5 Batch   55/538 - Train Accuracy: 0.9789, Validation Accuracy: 0.9753, Loss: 0.0138
Epoch   5 Batch   56/538 - Train Accuracy: 0.9803, Validation Accuracy: 0.9721, Loss: 0.0167
Epoch   5 Batch   57/538 - Train Accuracy: 0.9596, Validation Accuracy: 0.9721, Loss: 0.0183
Epoch   5 Batch   58/538 - Train Accuracy: 0.9865, Validation Accuracy: 0.9721, Loss: 0.0125
Epoch   5 Batch   59/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9719, Loss: 0.0138
Epoch   5 Batch   60/538 - Train Accuracy: 0.9852, Validation Accuracy: 0.9769, Loss: 0.0154
Epoch   5 Batch   61/538 - Train Accuracy: 0.9889, Validation Accuracy: 0.9702, Loss: 0.0146
Epoch   5 Batch   62/538 - Train Accuracy: 0.9727, Validation Accuracy: 0.9688, Loss: 0.0171
Epoch   5 Batch   63/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9734, Loss: 0.0154
Epoch   5 Batch   64/538 - Train Accuracy: 0.9786, Validation Accuracy: 0.9698, Loss: 0.0136
Epoch   5 Batch   65/538 - Train Accuracy: 0.9662, Validation Accuracy: 0.9711, Loss: 0.0140
Epoch   5 Batch   66/538 - Train Accuracy: 0.9807, Validation Accuracy: 0.9707, Loss: 0.0108
Epoch   5 Batch   67/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9719, Loss: 0.0153
Epoch   5 Batch   68/538 - Train Accuracy: 0.9738, Validation Accuracy: 0.9728, Loss: 0.0132
Epoch   5 Batch   69/538 - Train Accuracy: 0.9822, Validation Accuracy: 0.9725, Loss: 0.0122
Epoch   5 Batch   70/538 - Train Accuracy: 0.9756, Validation Accuracy: 0.9698, Loss: 0.0105
Epoch   5 Batch   71/538 - Train Accuracy: 0.9762, Validation Accuracy: 0.9675, Loss: 0.0161
Epoch   5 Batch   72/538 - Train Accuracy: 0.9767, Validation Accuracy: 0.9636, Loss: 0.0247
Epoch   5 Batch   73/538 - Train Accuracy: 0.9680, Validation Accuracy: 0.9664, Loss: 0.0174
Epoch   5 Batch   74/538 - Train Accuracy: 0.9879, Validation Accuracy: 0.9672, Loss: 0.0117
Epoch   5 Batch   75/538 - Train Accuracy: 0.9773, Validation Accuracy: 0.9585, Loss: 0.0145
Epoch   5 Batch   76/538 - Train Accuracy: 0.9719, Validation Accuracy: 0.9529, Loss: 0.0161
Epoch   5 Batch   77/538 - Train Accuracy: 0.9771, Validation Accuracy: 0.9563, Loss: 0.0133
Epoch   5 Batch   78/538 - Train Accuracy: 0.9738, Validation Accuracy: 0.9693, Loss: 0.0158
Epoch   5 Batch   79/538 - Train Accuracy: 0.9719, Validation Accuracy: 0.9723, Loss: 0.0124
Epoch   5 Batch   80/538 - Train Accuracy: 0.9824, Validation Accuracy: 0.9695, Loss: 0.0114
Epoch   5 Batch   81/538 - Train Accuracy: 0.9787, Validation Accuracy: 0.9737, Loss: 0.0162
Epoch   5 Batch   82/538 - Train Accuracy: 0.9736, Validation Accuracy: 0.9716, Loss: 0.0158
Epoch   5 Batch   83/538 - Train Accuracy: 0.9752, Validation Accuracy: 0.9718, Loss: 0.0163
Epoch   5 Batch   84/538 - Train Accuracy: 0.9732, Validation Accuracy: 0.9705, Loss: 0.0175
Epoch   5 Batch   85/538 - Train Accuracy: 0.9918, Validation Accuracy: 0.9680, Loss: 0.0126
Epoch   5 Batch   86/538 - Train Accuracy: 0.9801, Validation Accuracy: 0.9652, Loss: 0.0117
Epoch   5 Batch   87/538 - Train Accuracy: 0.9707, Validation Accuracy: 0.9615, Loss: 0.0141
Epoch   5 Batch   88/538 - Train Accuracy: 0.9680, Validation Accuracy: 0.9560, Loss: 0.0161
Epoch   5 Batch   89/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9544, Loss: 0.0122
Epoch   5 Batch   90/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9602, Loss: 0.0180
Epoch   5 Batch   91/538 - Train Accuracy: 0.9695, Validation Accuracy: 0.9629, Loss: 0.0199
Epoch   5 Batch   92/538 - Train Accuracy: 0.9697, Validation Accuracy: 0.9650, Loss: 0.0162
Epoch   5 Batch   93/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9650, Loss: 0.0119
Epoch   5 Batch   94/538 - Train Accuracy: 0.9816, Validation Accuracy: 0.9650, Loss: 0.0121
Epoch   5 Batch   95/538 - Train Accuracy: 0.9716, Validation Accuracy: 0.9645, Loss: 0.0150
Epoch   5 Batch   96/538 - Train Accuracy: 0.9846, Validation Accuracy: 0.9616, Loss: 0.0101
Epoch   5 Batch   97/538 - Train Accuracy: 0.9814, Validation Accuracy: 0.9741, Loss: 0.0108
Epoch   5 Batch   98/538 - Train Accuracy: 0.9749, Validation Accuracy: 0.9743, Loss: 0.0175
Epoch   5 Batch   99/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9748, Loss: 0.0116
Epoch   5 Batch  100/538 - Train Accuracy: 0.9852, Validation Accuracy: 0.9732, Loss: 0.0116
Epoch   5 Batch  101/538 - Train Accuracy: 0.9725, Validation Accuracy: 0.9677, Loss: 0.0203
Epoch   5 Batch  102/538 - Train Accuracy: 0.9551, Validation Accuracy: 0.9679, Loss: 0.0199
Epoch   5 Batch  103/538 - Train Accuracy: 0.9823, Validation Accuracy: 0.9714, Loss: 0.0134
Epoch   5 Batch  104/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9686, Loss: 0.0113
Epoch   5 Batch  105/538 - Train Accuracy: 0.9855, Validation Accuracy: 0.9695, Loss: 0.0102
Epoch   5 Batch  106/538 - Train Accuracy: 0.9738, Validation Accuracy: 0.9650, Loss: 0.0121
Epoch   5 Batch  107/538 - Train Accuracy: 0.9773, Validation Accuracy: 0.9691, Loss: 0.0171
Epoch   5 Batch  108/538 - Train Accuracy: 0.9773, Validation Accuracy: 0.9695, Loss: 0.0154
Epoch   5 Batch  109/538 - Train Accuracy: 0.9854, Validation Accuracy: 0.9657, Loss: 0.0135
Epoch   5 Batch  110/538 - Train Accuracy: 0.9785, Validation Accuracy: 0.9657, Loss: 0.0133
Epoch   5 Batch  111/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9668, Loss: 0.0129
Epoch   5 Batch  112/538 - Train Accuracy: 0.9691, Validation Accuracy: 0.9668, Loss: 0.0165
Epoch   5 Batch  113/538 - Train Accuracy: 0.9662, Validation Accuracy: 0.9737, Loss: 0.0173
Epoch   5 Batch  114/538 - Train Accuracy: 0.9795, Validation Accuracy: 0.9778, Loss: 0.0124
Epoch   5 Batch  115/538 - Train Accuracy: 0.9912, Validation Accuracy: 0.9805, Loss: 0.0123
Epoch   5 Batch  116/538 - Train Accuracy: 0.9825, Validation Accuracy: 0.9803, Loss: 0.0160
Epoch   5 Batch  117/538 - Train Accuracy: 0.9846, Validation Accuracy: 0.9766, Loss: 0.0151
Epoch   5 Batch  118/538 - Train Accuracy: 0.9859, Validation Accuracy: 0.9760, Loss: 0.0170
Epoch   5 Batch  119/538 - Train Accuracy: 0.9922, Validation Accuracy: 0.9730, Loss: 0.0103
Epoch   5 Batch  120/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9682, Loss: 0.0110
Epoch   5 Batch  121/538 - Train Accuracy: 0.9803, Validation Accuracy: 0.9632, Loss: 0.0157
Epoch   5 Batch  122/538 - Train Accuracy: 0.9678, Validation Accuracy: 0.9615, Loss: 0.0171
Epoch   5 Batch  123/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9602, Loss: 0.0133
Epoch   5 Batch  124/538 - Train Accuracy: 0.9782, Validation Accuracy: 0.9634, Loss: 0.0124
Epoch   5 Batch  125/538 - Train Accuracy: 0.9808, Validation Accuracy: 0.9645, Loss: 0.0171
Epoch   5 Batch  126/538 - Train Accuracy: 0.9606, Validation Accuracy: 0.9716, Loss: 0.0153
Epoch   5 Batch  127/538 - Train Accuracy: 0.9814, Validation Accuracy: 0.9695, Loss: 0.0164
Epoch   5 Batch  128/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9679, Loss: 0.0146
Epoch   5 Batch  129/538 - Train Accuracy: 0.9913, Validation Accuracy: 0.9661, Loss: 0.0110
Epoch   5 Batch  130/538 - Train Accuracy: 0.9764, Validation Accuracy: 0.9636, Loss: 0.0136
Epoch   5 Batch  131/538 - Train Accuracy: 0.9887, Validation Accuracy: 0.9643, Loss: 0.0123
Epoch   5 Batch  132/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9608, Loss: 0.0136
Epoch   5 Batch  133/538 - Train Accuracy: 0.9744, Validation Accuracy: 0.9577, Loss: 0.0169
Epoch   5 Batch  134/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9608, Loss: 0.0174
Epoch   5 Batch  135/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9560, Loss: 0.0188
Epoch   5 Batch  136/538 - Train Accuracy: 0.9645, Validation Accuracy: 0.9661, Loss: 0.0150
Epoch   5 Batch  137/538 - Train Accuracy: 0.9833, Validation Accuracy: 0.9620, Loss: 0.0161
Epoch   5 Batch  138/538 - Train Accuracy: 0.9853, Validation Accuracy: 0.9586, Loss: 0.0125
Epoch   5 Batch  139/538 - Train Accuracy: 0.9838, Validation Accuracy: 0.9609, Loss: 0.0161
Epoch   5 Batch  140/538 - Train Accuracy: 0.9742, Validation Accuracy: 0.9641, Loss: 0.0194
Epoch   5 Batch  141/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9679, Loss: 0.0127
Epoch   5 Batch  142/538 - Train Accuracy: 0.9792, Validation Accuracy: 0.9686, Loss: 0.0153
Epoch   5 Batch  143/538 - Train Accuracy: 0.9701, Validation Accuracy: 0.9679, Loss: 0.0201
Epoch   5 Batch  144/538 - Train Accuracy: 0.9869, Validation Accuracy: 0.9648, Loss: 0.0181
Epoch   5 Batch  145/538 - Train Accuracy: 0.9753, Validation Accuracy: 0.9657, Loss: 0.0196
Epoch   5 Batch  146/538 - Train Accuracy: 0.9808, Validation Accuracy: 0.9668, Loss: 0.0139
Epoch   5 Batch  147/538 - Train Accuracy: 0.9831, Validation Accuracy: 0.9652, Loss: 0.0190
Epoch   5 Batch  148/538 - Train Accuracy: 0.9662, Validation Accuracy: 0.9664, Loss: 0.0177
Epoch   5 Batch  149/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9686, Loss: 0.0128
Epoch   5 Batch  150/538 - Train Accuracy: 0.9797, Validation Accuracy: 0.9648, Loss: 0.0152
Epoch   5 Batch  151/538 - Train Accuracy: 0.9714, Validation Accuracy: 0.9624, Loss: 0.0211
Epoch   5 Batch  152/538 - Train Accuracy: 0.9756, Validation Accuracy: 0.9712, Loss: 0.0192
Epoch   5 Batch  153/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9712, Loss: 0.0139
Epoch   5 Batch  154/538 - Train Accuracy: 0.9691, Validation Accuracy: 0.9743, Loss: 0.0134
Epoch   5 Batch  155/538 - Train Accuracy: 0.9756, Validation Accuracy: 0.9728, Loss: 0.0146
Epoch   5 Batch  156/538 - Train Accuracy: 0.9893, Validation Accuracy: 0.9705, Loss: 0.0157
Epoch   5 Batch  157/538 - Train Accuracy: 0.9834, Validation Accuracy: 0.9696, Loss: 0.0179
Epoch   5 Batch  158/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9652, Loss: 0.0149
Epoch   5 Batch  159/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9727, Loss: 0.0195
Epoch   5 Batch  160/538 - Train Accuracy: 0.9727, Validation Accuracy: 0.9750, Loss: 0.0148
Epoch   5 Batch  161/538 - Train Accuracy: 0.9691, Validation Accuracy: 0.9718, Loss: 0.0147
Epoch   5 Batch  162/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9693, Loss: 0.0154
Epoch   5 Batch  163/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9689, Loss: 0.0179
Epoch   5 Batch  164/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9712, Loss: 0.0176
Epoch   5 Batch  165/538 - Train Accuracy: 0.9810, Validation Accuracy: 0.9691, Loss: 0.0120
Epoch   5 Batch  166/538 - Train Accuracy: 0.9789, Validation Accuracy: 0.9743, Loss: 0.0120
Epoch   5 Batch  167/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9769, Loss: 0.0237
Epoch   5 Batch  168/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9748, Loss: 0.0145
Epoch   5 Batch  169/538 - Train Accuracy: 0.9865, Validation Accuracy: 0.9730, Loss: 0.0132
Epoch   5 Batch  170/538 - Train Accuracy: 0.9775, Validation Accuracy: 0.9730, Loss: 0.0184
Epoch   5 Batch  171/538 - Train Accuracy: 0.9709, Validation Accuracy: 0.9654, Loss: 0.0189
Epoch   5 Batch  172/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9643, Loss: 0.0134
Epoch   5 Batch  173/538 - Train Accuracy: 0.9881, Validation Accuracy: 0.9675, Loss: 0.0100
Epoch   5 Batch  174/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9670, Loss: 0.0138
Epoch   5 Batch  175/538 - Train Accuracy: 0.9857, Validation Accuracy: 0.9638, Loss: 0.0147
Epoch   5 Batch  176/538 - Train Accuracy: 0.9771, Validation Accuracy: 0.9467, Loss: 0.0168
Epoch   5 Batch  177/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9498, Loss: 0.0139
Epoch   5 Batch  178/538 - Train Accuracy: 0.9667, Validation Accuracy: 0.9542, Loss: 0.0188
Epoch   5 Batch  179/538 - Train Accuracy: 0.9787, Validation Accuracy: 0.9618, Loss: 0.0138
Epoch   5 Batch  180/538 - Train Accuracy: 0.9723, Validation Accuracy: 0.9650, Loss: 0.0165
Epoch   5 Batch  181/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9648, Loss: 0.0200
Epoch   5 Batch  182/538 - Train Accuracy: 0.9801, Validation Accuracy: 0.9654, Loss: 0.0134
Epoch   5 Batch  183/538 - Train Accuracy: 0.9792, Validation Accuracy: 0.9709, Loss: 0.0146
Epoch   5 Batch  184/538 - Train Accuracy: 0.9823, Validation Accuracy: 0.9677, Loss: 0.0167
Epoch   5 Batch  185/538 - Train Accuracy: 0.9906, Validation Accuracy: 0.9647, Loss: 0.0106
Epoch   5 Batch  186/538 - Train Accuracy: 0.9885, Validation Accuracy: 0.9588, Loss: 0.0120
Epoch   5 Batch  187/538 - Train Accuracy: 0.9778, Validation Accuracy: 0.9561, Loss: 0.0162
Epoch   5 Batch  188/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9586, Loss: 0.0123
Epoch   5 Batch  189/538 - Train Accuracy: 0.9750, Validation Accuracy: 0.9634, Loss: 0.0143
Epoch   5 Batch  190/538 - Train Accuracy: 0.9704, Validation Accuracy: 0.9606, Loss: 0.0200
Epoch   5 Batch  191/538 - Train Accuracy: 0.9846, Validation Accuracy: 0.9590, Loss: 0.0139
Epoch   5 Batch  192/538 - Train Accuracy: 0.9740, Validation Accuracy: 0.9627, Loss: 0.0120
Epoch   5 Batch  193/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9641, Loss: 0.0146
Epoch   5 Batch  194/538 - Train Accuracy: 0.9650, Validation Accuracy: 0.9668, Loss: 0.0190
Epoch   5 Batch  195/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9700, Loss: 0.0214
Epoch   5 Batch  196/538 - Train Accuracy: 0.9749, Validation Accuracy: 0.9663, Loss: 0.0131
Epoch   5 Batch  197/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9689, Loss: 0.0137
Epoch   5 Batch  198/538 - Train Accuracy: 0.9689, Validation Accuracy: 0.9631, Loss: 0.0177
Epoch   5 Batch  199/538 - Train Accuracy: 0.9709, Validation Accuracy: 0.9563, Loss: 0.0147
Epoch   5 Batch  200/538 - Train Accuracy: 0.9768, Validation Accuracy: 0.9585, Loss: 0.0121
Epoch   5 Batch  201/538 - Train Accuracy: 0.9769, Validation Accuracy: 0.9613, Loss: 0.0203
Epoch   5 Batch  202/538 - Train Accuracy: 0.9823, Validation Accuracy: 0.9648, Loss: 0.0132
Epoch   5 Batch  203/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9622, Loss: 0.0142
Epoch   5 Batch  204/538 - Train Accuracy: 0.9699, Validation Accuracy: 0.9624, Loss: 0.0243
Epoch   5 Batch  205/538 - Train Accuracy: 0.9637, Validation Accuracy: 0.9599, Loss: 0.0155
Epoch   5 Batch  206/538 - Train Accuracy: 0.9730, Validation Accuracy: 0.9618, Loss: 0.0125
Epoch   5 Batch  207/538 - Train Accuracy: 0.9838, Validation Accuracy: 0.9599, Loss: 0.0149
Epoch   5 Batch  208/538 - Train Accuracy: 0.9713, Validation Accuracy: 0.9604, Loss: 0.0196
Epoch   5 Batch  209/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9620, Loss: 0.0142
Epoch   5 Batch  210/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9645, Loss: 0.0154
Epoch   5 Batch  211/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9629, Loss: 0.0151
Epoch   5 Batch  212/538 - Train Accuracy: 0.9875, Validation Accuracy: 0.9551, Loss: 0.0108
Epoch   5 Batch  213/538 - Train Accuracy: 0.9790, Validation Accuracy: 0.9599, Loss: 0.0161
Epoch   5 Batch  214/538 - Train Accuracy: 0.9879, Validation Accuracy: 0.9652, Loss: 0.0110
Epoch   5 Batch  215/538 - Train Accuracy: 0.9766, Validation Accuracy: 0.9652, Loss: 0.0121
Epoch   5 Batch  216/538 - Train Accuracy: 0.9773, Validation Accuracy: 0.9730, Loss: 0.0169
Epoch   5 Batch  217/538 - Train Accuracy: 0.9881, Validation Accuracy: 0.9716, Loss: 0.0151
Epoch   5 Batch  218/538 - Train Accuracy: 0.9803, Validation Accuracy: 0.9775, Loss: 0.0111
Epoch   5 Batch  219/538 - Train Accuracy: 0.9857, Validation Accuracy: 0.9739, Loss: 0.0168
Epoch   5 Batch  220/538 - Train Accuracy: 0.9608, Validation Accuracy: 0.9698, Loss: 0.0183
Epoch   5 Batch  221/538 - Train Accuracy: 0.9803, Validation Accuracy: 0.9696, Loss: 0.0119
Epoch   5 Batch  222/538 - Train Accuracy: 0.9851, Validation Accuracy: 0.9650, Loss: 0.0106
Epoch   5 Batch  223/538 - Train Accuracy: 0.9793, Validation Accuracy: 0.9647, Loss: 0.0141
Epoch   5 Batch  224/538 - Train Accuracy: 0.9680, Validation Accuracy: 0.9643, Loss: 0.0181
Epoch   5 Batch  225/538 - Train Accuracy: 0.9710, Validation Accuracy: 0.9574, Loss: 0.0150
Epoch   5 Batch  226/538 - Train Accuracy: 0.9701, Validation Accuracy: 0.9604, Loss: 0.0168
Epoch   5 Batch  227/538 - Train Accuracy: 0.9757, Validation Accuracy: 0.9650, Loss: 0.0159
Epoch   5 Batch  228/538 - Train Accuracy: 0.9764, Validation Accuracy: 0.9632, Loss: 0.0155
Epoch   5 Batch  229/538 - Train Accuracy: 0.9866, Validation Accuracy: 0.9588, Loss: 0.0128
Epoch   5 Batch  230/538 - Train Accuracy: 0.9680, Validation Accuracy: 0.9577, Loss: 0.0154
Epoch   5 Batch  231/538 - Train Accuracy: 0.9688, Validation Accuracy: 0.9634, Loss: 0.0186
Epoch   5 Batch  232/538 - Train Accuracy: 0.9635, Validation Accuracy: 0.9588, Loss: 0.0179
Epoch   5 Batch  233/538 - Train Accuracy: 0.9808, Validation Accuracy: 0.9590, Loss: 0.0127
Epoch   5 Batch  234/538 - Train Accuracy: 0.9775, Validation Accuracy: 0.9569, Loss: 0.0113
Epoch   5 Batch  235/538 - Train Accuracy: 0.9730, Validation Accuracy: 0.9622, Loss: 0.0166
Epoch   5 Batch  236/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9624, Loss: 0.0146
Epoch   5 Batch  237/538 - Train Accuracy: 0.9775, Validation Accuracy: 0.9659, Loss: 0.0097
Epoch   5 Batch  238/538 - Train Accuracy: 0.9719, Validation Accuracy: 0.9673, Loss: 0.0168
Epoch   5 Batch  239/538 - Train Accuracy: 0.9807, Validation Accuracy: 0.9632, Loss: 0.0138
Epoch   5 Batch  240/538 - Train Accuracy: 0.9693, Validation Accuracy: 0.9666, Loss: 0.0160
Epoch   5 Batch  241/538 - Train Accuracy: 0.9738, Validation Accuracy: 0.9631, Loss: 0.0218
Epoch   5 Batch  242/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9679, Loss: 0.0127
Epoch   5 Batch  243/538 - Train Accuracy: 0.9831, Validation Accuracy: 0.9618, Loss: 0.0130
Epoch   5 Batch  244/538 - Train Accuracy: 0.9693, Validation Accuracy: 0.9647, Loss: 0.0131
Epoch   5 Batch  245/538 - Train Accuracy: 0.9676, Validation Accuracy: 0.9663, Loss: 0.0207
Epoch   5 Batch  246/538 - Train Accuracy: 0.9702, Validation Accuracy: 0.9675, Loss: 0.0136
Epoch   5 Batch  247/538 - Train Accuracy: 0.9686, Validation Accuracy: 0.9673, Loss: 0.0144
Epoch   5 Batch  248/538 - Train Accuracy: 0.9738, Validation Accuracy: 0.9672, Loss: 0.0192
Epoch   5 Batch  249/538 - Train Accuracy: 0.9660, Validation Accuracy: 0.9679, Loss: 0.0125
Epoch   5 Batch  250/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9707, Loss: 0.0148
Epoch   5 Batch  251/538 - Train Accuracy: 0.9787, Validation Accuracy: 0.9709, Loss: 0.0120
Epoch   5 Batch  252/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9700, Loss: 0.0137
Epoch   5 Batch  253/538 - Train Accuracy: 0.9790, Validation Accuracy: 0.9750, Loss: 0.0132
Epoch   5 Batch  254/538 - Train Accuracy: 0.9732, Validation Accuracy: 0.9725, Loss: 0.0167
Epoch   5 Batch  255/538 - Train Accuracy: 0.9906, Validation Accuracy: 0.9693, Loss: 0.0115
Epoch   5 Batch  256/538 - Train Accuracy: 0.9762, Validation Accuracy: 0.9675, Loss: 0.0123
Epoch   5 Batch  257/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9600, Loss: 0.0138
Epoch   5 Batch  258/538 - Train Accuracy: 0.9727, Validation Accuracy: 0.9652, Loss: 0.0182
Epoch   5 Batch  259/538 - Train Accuracy: 0.9797, Validation Accuracy: 0.9608, Loss: 0.0119
Epoch   5 Batch  260/538 - Train Accuracy: 0.9635, Validation Accuracy: 0.9570, Loss: 0.0150
Epoch   5 Batch  261/538 - Train Accuracy: 0.9891, Validation Accuracy: 0.9526, Loss: 0.0144
Epoch   5 Batch  262/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9572, Loss: 0.0182
Epoch   5 Batch  263/538 - Train Accuracy: 0.9697, Validation Accuracy: 0.9586, Loss: 0.0173
Epoch   5 Batch  264/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9611, Loss: 0.0164
Epoch   5 Batch  265/538 - Train Accuracy: 0.9639, Validation Accuracy: 0.9657, Loss: 0.0180
Epoch   5 Batch  266/538 - Train Accuracy: 0.9775, Validation Accuracy: 0.9673, Loss: 0.0150
Epoch   5 Batch  267/538 - Train Accuracy: 0.9791, Validation Accuracy: 0.9661, Loss: 0.0148
Epoch   5 Batch  268/538 - Train Accuracy: 0.9883, Validation Accuracy: 0.9679, Loss: 0.0093
Epoch   5 Batch  269/538 - Train Accuracy: 0.9816, Validation Accuracy: 0.9735, Loss: 0.0127
Epoch   5 Batch  270/538 - Train Accuracy: 0.9666, Validation Accuracy: 0.9725, Loss: 0.0150
Epoch   5 Batch  271/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9702, Loss: 0.0090
Epoch   5 Batch  272/538 - Train Accuracy: 0.9883, Validation Accuracy: 0.9647, Loss: 0.0115
Epoch   5 Batch  273/538 - Train Accuracy: 0.9727, Validation Accuracy: 0.9647, Loss: 0.0153
Epoch   5 Batch  274/538 - Train Accuracy: 0.9684, Validation Accuracy: 0.9648, Loss: 0.0148
Epoch   5 Batch  275/538 - Train Accuracy: 0.9674, Validation Accuracy: 0.9712, Loss: 0.0177
Epoch   5 Batch  276/538 - Train Accuracy: 0.9826, Validation Accuracy: 0.9675, Loss: 0.0179
Epoch   5 Batch  277/538 - Train Accuracy: 0.9842, Validation Accuracy: 0.9677, Loss: 0.0121
Epoch   5 Batch  278/538 - Train Accuracy: 0.9842, Validation Accuracy: 0.9647, Loss: 0.0119
Epoch   5 Batch  279/538 - Train Accuracy: 0.9889, Validation Accuracy: 0.9700, Loss: 0.0104
Epoch   5 Batch  280/538 - Train Accuracy: 0.9857, Validation Accuracy: 0.9725, Loss: 0.0115
Epoch   5 Batch  281/538 - Train Accuracy: 0.9746, Validation Accuracy: 0.9732, Loss: 0.0176
Epoch   5 Batch  282/538 - Train Accuracy: 0.9784, Validation Accuracy: 0.9682, Loss: 0.0170
Epoch   5 Batch  283/538 - Train Accuracy: 0.9875, Validation Accuracy: 0.9707, Loss: 0.0156
Epoch   5 Batch  284/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9727, Loss: 0.0137
Epoch   5 Batch  285/538 - Train Accuracy: 0.9790, Validation Accuracy: 0.9688, Loss: 0.0127
Epoch   5 Batch  286/538 - Train Accuracy: 0.9752, Validation Accuracy: 0.9686, Loss: 0.0176
Epoch   5 Batch  287/538 - Train Accuracy: 0.9916, Validation Accuracy: 0.9688, Loss: 0.0102
Epoch   5 Batch  288/538 - Train Accuracy: 0.9725, Validation Accuracy: 0.9597, Loss: 0.0119
Epoch   5 Batch  289/538 - Train Accuracy: 0.9784, Validation Accuracy: 0.9648, Loss: 0.0138
Epoch   5 Batch  290/538 - Train Accuracy: 0.9879, Validation Accuracy: 0.9647, Loss: 0.0117
Epoch   5 Batch  291/538 - Train Accuracy: 0.9838, Validation Accuracy: 0.9675, Loss: 0.0142
Epoch   5 Batch  292/538 - Train Accuracy: 0.9894, Validation Accuracy: 0.9680, Loss: 0.0079
Epoch   5 Batch  293/538 - Train Accuracy: 0.9732, Validation Accuracy: 0.9634, Loss: 0.0154
Epoch   5 Batch  294/538 - Train Accuracy: 0.9782, Validation Accuracy: 0.9673, Loss: 0.0138
Epoch   5 Batch  295/538 - Train Accuracy: 0.9783, Validation Accuracy: 0.9670, Loss: 0.0150
Epoch   5 Batch  296/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9718, Loss: 0.0223
Epoch   5 Batch  297/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9695, Loss: 0.0129
Epoch   5 Batch  298/538 - Train Accuracy: 0.9749, Validation Accuracy: 0.9714, Loss: 0.0133
Epoch   5 Batch  299/538 - Train Accuracy: 0.9699, Validation Accuracy: 0.9693, Loss: 0.0198
Epoch   5 Batch  300/538 - Train Accuracy: 0.9756, Validation Accuracy: 0.9712, Loss: 0.0134
Epoch   5 Batch  301/538 - Train Accuracy: 0.9704, Validation Accuracy: 0.9686, Loss: 0.0164
Epoch   5 Batch  302/538 - Train Accuracy: 0.9751, Validation Accuracy: 0.9629, Loss: 0.0175
Epoch   5 Batch  303/538 - Train Accuracy: 0.9780, Validation Accuracy: 0.9650, Loss: 0.0158
Epoch   5 Batch  304/538 - Train Accuracy: 0.9744, Validation Accuracy: 0.9634, Loss: 0.0175
Epoch   5 Batch  305/538 - Train Accuracy: 0.9738, Validation Accuracy: 0.9586, Loss: 0.0133
Epoch   5 Batch  306/538 - Train Accuracy: 0.9769, Validation Accuracy: 0.9599, Loss: 0.0167
Epoch   5 Batch  307/538 - Train Accuracy: 0.9787, Validation Accuracy: 0.9588, Loss: 0.0141
Epoch   5 Batch  308/538 - Train Accuracy: 0.9790, Validation Accuracy: 0.9577, Loss: 0.0145
Epoch   5 Batch  309/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9586, Loss: 0.0150
Epoch   5 Batch  310/538 - Train Accuracy: 0.9793, Validation Accuracy: 0.9588, Loss: 0.0205
Epoch   5 Batch  311/538 - Train Accuracy: 0.9807, Validation Accuracy: 0.9613, Loss: 0.0137
Epoch   5 Batch  312/538 - Train Accuracy: 0.9785, Validation Accuracy: 0.9661, Loss: 0.0127
Epoch   5 Batch  313/538 - Train Accuracy: 0.9703, Validation Accuracy: 0.9648, Loss: 0.0182
Epoch   5 Batch  314/538 - Train Accuracy: 0.9885, Validation Accuracy: 0.9679, Loss: 0.0124
Epoch   5 Batch  315/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9638, Loss: 0.0146
Epoch   5 Batch  316/538 - Train Accuracy: 0.9717, Validation Accuracy: 0.9650, Loss: 0.0121
Epoch   5 Batch  317/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9672, Loss: 0.0143
Epoch   5 Batch  318/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9659, Loss: 0.0158
Epoch   5 Batch  319/538 - Train Accuracy: 0.9741, Validation Accuracy: 0.9703, Loss: 0.0180
Epoch   5 Batch  320/538 - Train Accuracy: 0.9795, Validation Accuracy: 0.9686, Loss: 0.0109
Epoch   5 Batch  321/538 - Train Accuracy: 0.9736, Validation Accuracy: 0.9709, Loss: 0.0114
Epoch   5 Batch  322/538 - Train Accuracy: 0.9775, Validation Accuracy: 0.9698, Loss: 0.0147
Epoch   5 Batch  323/538 - Train Accuracy: 0.9807, Validation Accuracy: 0.9719, Loss: 0.0134
Epoch   5 Batch  324/538 - Train Accuracy: 0.9859, Validation Accuracy: 0.9719, Loss: 0.0106
Epoch   5 Batch  325/538 - Train Accuracy: 0.9743, Validation Accuracy: 0.9727, Loss: 0.0155
Epoch   5 Batch  326/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9741, Loss: 0.0128
Epoch   5 Batch  327/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9741, Loss: 0.0136
Epoch   5 Batch  328/538 - Train Accuracy: 0.9879, Validation Accuracy: 0.9721, Loss: 0.0093
Epoch   5 Batch  329/538 - Train Accuracy: 0.9911, Validation Accuracy: 0.9776, Loss: 0.0087
Epoch   5 Batch  330/538 - Train Accuracy: 0.9913, Validation Accuracy: 0.9734, Loss: 0.0124
Epoch   5 Batch  331/538 - Train Accuracy: 0.9832, Validation Accuracy: 0.9737, Loss: 0.0138
Epoch   5 Batch  332/538 - Train Accuracy: 0.9854, Validation Accuracy: 0.9766, Loss: 0.0131
Epoch   5 Batch  333/538 - Train Accuracy: 0.9805, Validation Accuracy: 0.9766, Loss: 0.0163
Epoch   5 Batch  334/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9748, Loss: 0.0125
Epoch   5 Batch  335/538 - Train Accuracy: 0.9740, Validation Accuracy: 0.9748, Loss: 0.0134
Epoch   5 Batch  336/538 - Train Accuracy: 0.9844, Validation Accuracy: 0.9785, Loss: 0.0145
Epoch   5 Batch  337/538 - Train Accuracy: 0.9836, Validation Accuracy: 0.9773, Loss: 0.0133
Epoch   5 Batch  338/538 - Train Accuracy: 0.9894, Validation Accuracy: 0.9760, Loss: 0.0117
Epoch   5 Batch  339/538 - Train Accuracy: 0.9695, Validation Accuracy: 0.9828, Loss: 0.0119
Epoch   5 Batch  340/538 - Train Accuracy: 0.9732, Validation Accuracy: 0.9822, Loss: 0.0114
Epoch   5 Batch  341/538 - Train Accuracy: 0.9861, Validation Accuracy: 0.9821, Loss: 0.0132
Epoch   5 Batch  342/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9801, Loss: 0.0137
Epoch   5 Batch  343/538 - Train Accuracy: 0.9906, Validation Accuracy: 0.9796, Loss: 0.0112
Epoch   5 Batch  344/538 - Train Accuracy: 0.9709, Validation Accuracy: 0.9780, Loss: 0.0124
Epoch   5 Batch  345/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9766, Loss: 0.0117
Epoch   5 Batch  346/538 - Train Accuracy: 0.9702, Validation Accuracy: 0.9766, Loss: 0.0167
Epoch   5 Batch  347/538 - Train Accuracy: 0.9797, Validation Accuracy: 0.9759, Loss: 0.0142
Epoch   5 Batch  348/538 - Train Accuracy: 0.9749, Validation Accuracy: 0.9751, Loss: 0.0097
Epoch   5 Batch  349/538 - Train Accuracy: 0.9824, Validation Accuracy: 0.9739, Loss: 0.0095
Epoch   5 Batch  350/538 - Train Accuracy: 0.9784, Validation Accuracy: 0.9743, Loss: 0.0135
Epoch   5 Batch  351/538 - Train Accuracy: 0.9795, Validation Accuracy: 0.9732, Loss: 0.0145
Epoch   5 Batch  352/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9728, Loss: 0.0267
Epoch   5 Batch  353/538 - Train Accuracy: 0.9814, Validation Accuracy: 0.9721, Loss: 0.0140
Epoch   5 Batch  354/538 - Train Accuracy: 0.9809, Validation Accuracy: 0.9728, Loss: 0.0131
Epoch   5 Batch  355/538 - Train Accuracy: 0.9854, Validation Accuracy: 0.9732, Loss: 0.0129
Epoch   5 Batch  356/538 - Train Accuracy: 0.9824, Validation Accuracy: 0.9673, Loss: 0.0086
Epoch   5 Batch  357/538 - Train Accuracy: 0.9744, Validation Accuracy: 0.9664, Loss: 0.0124
Epoch   5 Batch  358/538 - Train Accuracy: 0.9871, Validation Accuracy: 0.9648, Loss: 0.0113
Epoch   5 Batch  359/538 - Train Accuracy: 0.9825, Validation Accuracy: 0.9702, Loss: 0.0122
Epoch   5 Batch  360/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9723, Loss: 0.0115
Epoch   5 Batch  361/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9711, Loss: 0.0153
Epoch   5 Batch  362/538 - Train Accuracy: 0.9872, Validation Accuracy: 0.9638, Loss: 0.0099
Epoch   5 Batch  363/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9636, Loss: 0.0142
Epoch   5 Batch  364/538 - Train Accuracy: 0.9768, Validation Accuracy: 0.9677, Loss: 0.0169
Epoch   5 Batch  365/538 - Train Accuracy: 0.9712, Validation Accuracy: 0.9648, Loss: 0.0127
Epoch   5 Batch  366/538 - Train Accuracy: 0.9809, Validation Accuracy: 0.9613, Loss: 0.0133
Epoch   5 Batch  367/538 - Train Accuracy: 0.9832, Validation Accuracy: 0.9672, Loss: 0.0103
Epoch   5 Batch  368/538 - Train Accuracy: 0.9884, Validation Accuracy: 0.9672, Loss: 0.0104
Epoch   5 Batch  369/538 - Train Accuracy: 0.9742, Validation Accuracy: 0.9609, Loss: 0.0125
Epoch   5 Batch  370/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9588, Loss: 0.0143
Epoch   5 Batch  371/538 - Train Accuracy: 0.9874, Validation Accuracy: 0.9615, Loss: 0.0109
Epoch   5 Batch  372/538 - Train Accuracy: 0.9740, Validation Accuracy: 0.9606, Loss: 0.0137
Epoch   5 Batch  373/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9663, Loss: 0.0093
Epoch   5 Batch  374/538 - Train Accuracy: 0.9686, Validation Accuracy: 0.9632, Loss: 0.0144
Epoch   5 Batch  375/538 - Train Accuracy: 0.9741, Validation Accuracy: 0.9618, Loss: 0.0125
Epoch   5 Batch  376/538 - Train Accuracy: 0.9838, Validation Accuracy: 0.9647, Loss: 0.0121
Epoch   5 Batch  377/538 - Train Accuracy: 0.9828, Validation Accuracy: 0.9638, Loss: 0.0144
Epoch   5 Batch  378/538 - Train Accuracy: 0.9831, Validation Accuracy: 0.9647, Loss: 0.0096
Epoch   5 Batch  379/538 - Train Accuracy: 0.9870, Validation Accuracy: 0.9675, Loss: 0.0132
Epoch   5 Batch  380/538 - Train Accuracy: 0.9844, Validation Accuracy: 0.9656, Loss: 0.0123
Epoch   5 Batch  381/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9616, Loss: 0.0136
Epoch   5 Batch  382/538 - Train Accuracy: 0.9732, Validation Accuracy: 0.9602, Loss: 0.0182
Epoch   5 Batch  383/538 - Train Accuracy: 0.9850, Validation Accuracy: 0.9654, Loss: 0.0109
Epoch   5 Batch  384/538 - Train Accuracy: 0.9829, Validation Accuracy: 0.9657, Loss: 0.0127
Epoch   5 Batch  385/538 - Train Accuracy: 0.9805, Validation Accuracy: 0.9656, Loss: 0.0124
Epoch   5 Batch  386/538 - Train Accuracy: 0.9768, Validation Accuracy: 0.9659, Loss: 0.0120
Epoch   5 Batch  387/538 - Train Accuracy: 0.9838, Validation Accuracy: 0.9629, Loss: 0.0117
Epoch   5 Batch  388/538 - Train Accuracy: 0.9911, Validation Accuracy: 0.9622, Loss: 0.0111
Epoch   5 Batch  389/538 - Train Accuracy: 0.9787, Validation Accuracy: 0.9581, Loss: 0.0173
Epoch   5 Batch  390/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9561, Loss: 0.0118
Epoch   5 Batch  391/538 - Train Accuracy: 0.9743, Validation Accuracy: 0.9592, Loss: 0.0133
Epoch   5 Batch  392/538 - Train Accuracy: 0.9805, Validation Accuracy: 0.9613, Loss: 0.0103
Epoch   5 Batch  393/538 - Train Accuracy: 0.9834, Validation Accuracy: 0.9597, Loss: 0.0134
Epoch   5 Batch  394/538 - Train Accuracy: 0.9646, Validation Accuracy: 0.9652, Loss: 0.0167
Epoch   5 Batch  395/538 - Train Accuracy: 0.9846, Validation Accuracy: 0.9725, Loss: 0.0160
Epoch   5 Batch  396/538 - Train Accuracy: 0.9816, Validation Accuracy: 0.9739, Loss: 0.0134
Epoch   5 Batch  397/538 - Train Accuracy: 0.9828, Validation Accuracy: 0.9698, Loss: 0.0117
Epoch   5 Batch  398/538 - Train Accuracy: 0.9785, Validation Accuracy: 0.9721, Loss: 0.0144
Epoch   5 Batch  399/538 - Train Accuracy: 0.9744, Validation Accuracy: 0.9769, Loss: 0.0158
Epoch   5 Batch  400/538 - Train Accuracy: 0.9831, Validation Accuracy: 0.9767, Loss: 0.0120
Epoch   5 Batch  401/538 - Train Accuracy: 0.9967, Validation Accuracy: 0.9746, Loss: 0.0087
Epoch   5 Batch  402/538 - Train Accuracy: 0.9873, Validation Accuracy: 0.9746, Loss: 0.0133
Epoch   5 Batch  403/538 - Train Accuracy: 0.9852, Validation Accuracy: 0.9771, Loss: 0.0143
Epoch   5 Batch  404/538 - Train Accuracy: 0.9699, Validation Accuracy: 0.9725, Loss: 0.0161
Epoch   5 Batch  405/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9718, Loss: 0.0122
Epoch   5 Batch  406/538 - Train Accuracy: 0.9741, Validation Accuracy: 0.9632, Loss: 0.0156
Epoch   5 Batch  407/538 - Train Accuracy: 0.9756, Validation Accuracy: 0.9672, Loss: 0.0165
Epoch   5 Batch  408/538 - Train Accuracy: 0.9748, Validation Accuracy: 0.9659, Loss: 0.0168
Epoch   5 Batch  409/538 - Train Accuracy: 0.9791, Validation Accuracy: 0.9666, Loss: 0.0115
Epoch   5 Batch  410/538 - Train Accuracy: 0.9852, Validation Accuracy: 0.9666, Loss: 0.0121
Epoch   5 Batch  411/538 - Train Accuracy: 0.9769, Validation Accuracy: 0.9711, Loss: 0.0151
Epoch   5 Batch  412/538 - Train Accuracy: 0.9872, Validation Accuracy: 0.9657, Loss: 0.0086
Epoch   5 Batch  413/538 - Train Accuracy: 0.9766, Validation Accuracy: 0.9684, Loss: 0.0144
Epoch   5 Batch  414/538 - Train Accuracy: 0.9631, Validation Accuracy: 0.9663, Loss: 0.0192
Epoch   5 Batch  415/538 - Train Accuracy: 0.9752, Validation Accuracy: 0.9656, Loss: 0.0123
Epoch   5 Batch  416/538 - Train Accuracy: 0.9890, Validation Accuracy: 0.9703, Loss: 0.0134
Epoch   5 Batch  417/538 - Train Accuracy: 0.9914, Validation Accuracy: 0.9657, Loss: 0.0116
Epoch   5 Batch  418/538 - Train Accuracy: 0.9824, Validation Accuracy: 0.9668, Loss: 0.0164
Epoch   5 Batch  419/538 - Train Accuracy: 0.9885, Validation Accuracy: 0.9693, Loss: 0.0143
Epoch   5 Batch  420/538 - Train Accuracy: 0.9814, Validation Accuracy: 0.9663, Loss: 0.0153
Epoch   5 Batch  421/538 - Train Accuracy: 0.9786, Validation Accuracy: 0.9680, Loss: 0.0101
Epoch   5 Batch  422/538 - Train Accuracy: 0.9705, Validation Accuracy: 0.9661, Loss: 0.0165
Epoch   5 Batch  423/538 - Train Accuracy: 0.9740, Validation Accuracy: 0.9673, Loss: 0.0145
Epoch   5 Batch  424/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9673, Loss: 0.0191
Epoch   5 Batch  425/538 - Train Accuracy: 0.9691, Validation Accuracy: 0.9645, Loss: 0.0229
Epoch   5 Batch  426/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9650, Loss: 0.0150
Epoch   5 Batch  427/538 - Train Accuracy: 0.9773, Validation Accuracy: 0.9613, Loss: 0.0153
Epoch   5 Batch  428/538 - Train Accuracy: 0.9853, Validation Accuracy: 0.9622, Loss: 0.0096
Epoch   5 Batch  429/538 - Train Accuracy: 0.9890, Validation Accuracy: 0.9595, Loss: 0.0122
Epoch   5 Batch  430/538 - Train Accuracy: 0.9748, Validation Accuracy: 0.9585, Loss: 0.0146
Epoch   5 Batch  431/538 - Train Accuracy: 0.9717, Validation Accuracy: 0.9567, Loss: 0.0146
Epoch   5 Batch  432/538 - Train Accuracy: 0.9737, Validation Accuracy: 0.9524, Loss: 0.0144
Epoch   5 Batch  433/538 - Train Accuracy: 0.9660, Validation Accuracy: 0.9554, Loss: 0.0291
Epoch   5 Batch  434/538 - Train Accuracy: 0.9828, Validation Accuracy: 0.9581, Loss: 0.0113
Epoch   5 Batch  435/538 - Train Accuracy: 0.9811, Validation Accuracy: 0.9545, Loss: 0.0139
Epoch   5 Batch  436/538 - Train Accuracy: 0.9639, Validation Accuracy: 0.9593, Loss: 0.0170
Epoch   5 Batch  437/538 - Train Accuracy: 0.9877, Validation Accuracy: 0.9588, Loss: 0.0126
Epoch   5 Batch  438/538 - Train Accuracy: 0.9793, Validation Accuracy: 0.9657, Loss: 0.0105
Epoch   5 Batch  439/538 - Train Accuracy: 0.9871, Validation Accuracy: 0.9703, Loss: 0.0139
Epoch   5 Batch  440/538 - Train Accuracy: 0.9811, Validation Accuracy: 0.9689, Loss: 0.0146
Epoch   5 Batch  441/538 - Train Accuracy: 0.9785, Validation Accuracy: 0.9716, Loss: 0.0182
Epoch   5 Batch  442/538 - Train Accuracy: 0.9743, Validation Accuracy: 0.9714, Loss: 0.0126
Epoch   5 Batch  443/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9688, Loss: 0.0141
Epoch   5 Batch  444/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9650, Loss: 0.0126
Epoch   5 Batch  445/538 - Train Accuracy: 0.9861, Validation Accuracy: 0.9654, Loss: 0.0107
Epoch   5 Batch  446/538 - Train Accuracy: 0.9701, Validation Accuracy: 0.9679, Loss: 0.0118
Epoch   5 Batch  447/538 - Train Accuracy: 0.9789, Validation Accuracy: 0.9712, Loss: 0.0125
Epoch   5 Batch  448/538 - Train Accuracy: 0.9732, Validation Accuracy: 0.9719, Loss: 0.0165
Epoch   5 Batch  449/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9728, Loss: 0.0149
Epoch   5 Batch  450/538 - Train Accuracy: 0.9725, Validation Accuracy: 0.9790, Loss: 0.0181
Epoch   5 Batch  451/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9739, Loss: 0.0115
Epoch   5 Batch  452/538 - Train Accuracy: 0.9830, Validation Accuracy: 0.9766, Loss: 0.0124
Epoch   5 Batch  453/538 - Train Accuracy: 0.9748, Validation Accuracy: 0.9769, Loss: 0.0154
Epoch   5 Batch  454/538 - Train Accuracy: 0.9741, Validation Accuracy: 0.9760, Loss: 0.0146
Epoch   5 Batch  455/538 - Train Accuracy: 0.9872, Validation Accuracy: 0.9762, Loss: 0.0141
Epoch   5 Batch  456/538 - Train Accuracy: 0.9870, Validation Accuracy: 0.9759, Loss: 0.0215
Epoch   5 Batch  457/538 - Train Accuracy: 0.9764, Validation Accuracy: 0.9782, Loss: 0.0112
Epoch   5 Batch  458/538 - Train Accuracy: 0.9816, Validation Accuracy: 0.9787, Loss: 0.0117
Epoch   5 Batch  459/538 - Train Accuracy: 0.9896, Validation Accuracy: 0.9769, Loss: 0.0095
Epoch   5 Batch  460/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9718, Loss: 0.0122
Epoch   5 Batch  461/538 - Train Accuracy: 0.9776, Validation Accuracy: 0.9696, Loss: 0.0142
Epoch   5 Batch  462/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9640, Loss: 0.0109
Epoch   5 Batch  463/538 - Train Accuracy: 0.9621, Validation Accuracy: 0.9664, Loss: 0.0184
Epoch   5 Batch  464/538 - Train Accuracy: 0.9783, Validation Accuracy: 0.9641, Loss: 0.0102
Epoch   5 Batch  465/538 - Train Accuracy: 0.9875, Validation Accuracy: 0.9664, Loss: 0.0139
Epoch   5 Batch  466/538 - Train Accuracy: 0.9750, Validation Accuracy: 0.9700, Loss: 0.0138
Epoch   5 Batch  467/538 - Train Accuracy: 0.9792, Validation Accuracy: 0.9718, Loss: 0.0150
Epoch   5 Batch  468/538 - Train Accuracy: 0.9830, Validation Accuracy: 0.9748, Loss: 0.0163
Epoch   5 Batch  469/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9709, Loss: 0.0117
Epoch   5 Batch  470/538 - Train Accuracy: 0.9702, Validation Accuracy: 0.9709, Loss: 0.0139
Epoch   5 Batch  471/538 - Train Accuracy: 0.9913, Validation Accuracy: 0.9719, Loss: 0.0084
Epoch   5 Batch  472/538 - Train Accuracy: 0.9963, Validation Accuracy: 0.9753, Loss: 0.0081
Epoch   5 Batch  473/538 - Train Accuracy: 0.9850, Validation Accuracy: 0.9750, Loss: 0.0117
Epoch   5 Batch  474/538 - Train Accuracy: 0.9773, Validation Accuracy: 0.9741, Loss: 0.0122
Epoch   5 Batch  475/538 - Train Accuracy: 0.9866, Validation Accuracy: 0.9759, Loss: 0.0106
Epoch   5 Batch  476/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9739, Loss: 0.0131
Epoch   5 Batch  477/538 - Train Accuracy: 0.9717, Validation Accuracy: 0.9739, Loss: 0.0178
Epoch   5 Batch  478/538 - Train Accuracy: 0.9829, Validation Accuracy: 0.9751, Loss: 0.0117
Epoch   5 Batch  479/538 - Train Accuracy: 0.9717, Validation Accuracy: 0.9737, Loss: 0.0155
Epoch   5 Batch  480/538 - Train Accuracy: 0.9875, Validation Accuracy: 0.9613, Loss: 0.0106
Epoch   5 Batch  481/538 - Train Accuracy: 0.9827, Validation Accuracy: 0.9588, Loss: 0.0121
Epoch   5 Batch  482/538 - Train Accuracy: 0.9708, Validation Accuracy: 0.9600, Loss: 0.0098
Epoch   5 Batch  483/538 - Train Accuracy: 0.9807, Validation Accuracy: 0.9606, Loss: 0.0130
Epoch   5 Batch  484/538 - Train Accuracy: 0.9786, Validation Accuracy: 0.9608, Loss: 0.0155
Epoch   5 Batch  485/538 - Train Accuracy: 0.9808, Validation Accuracy: 0.9661, Loss: 0.0178
Epoch   5 Batch  486/538 - Train Accuracy: 0.9920, Validation Accuracy: 0.9702, Loss: 0.0067
Epoch   5 Batch  487/538 - Train Accuracy: 0.9872, Validation Accuracy: 0.9700, Loss: 0.0088
Epoch   5 Batch  488/538 - Train Accuracy: 0.9803, Validation Accuracy: 0.9703, Loss: 0.0121
Epoch   5 Batch  489/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9711, Loss: 0.0141
Epoch   5 Batch  490/538 - Train Accuracy: 0.9725, Validation Accuracy: 0.9739, Loss: 0.0124
Epoch   5 Batch  491/538 - Train Accuracy: 0.9691, Validation Accuracy: 0.9741, Loss: 0.0142
Epoch   5 Batch  492/538 - Train Accuracy: 0.9861, Validation Accuracy: 0.9712, Loss: 0.0101
Epoch   5 Batch  493/538 - Train Accuracy: 0.9693, Validation Accuracy: 0.9766, Loss: 0.0145
Epoch   5 Batch  494/538 - Train Accuracy: 0.9711, Validation Accuracy: 0.9762, Loss: 0.0152
Epoch   5 Batch  495/538 - Train Accuracy: 0.9740, Validation Accuracy: 0.9743, Loss: 0.0165
Epoch   5 Batch  496/538 - Train Accuracy: 0.9832, Validation Accuracy: 0.9714, Loss: 0.0093
Epoch   5 Batch  497/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9712, Loss: 0.0110
Epoch   5 Batch  498/538 - Train Accuracy: 0.9855, Validation Accuracy: 0.9725, Loss: 0.0133
Epoch   5 Batch  499/538 - Train Accuracy: 0.9751, Validation Accuracy: 0.9741, Loss: 0.0130
Epoch   5 Batch  500/538 - Train Accuracy: 0.9927, Validation Accuracy: 0.9739, Loss: 0.0083
Epoch   5 Batch  501/538 - Train Accuracy: 0.9824, Validation Accuracy: 0.9672, Loss: 0.0119
Epoch   5 Batch  502/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9666, Loss: 0.0115
Epoch   5 Batch  503/538 - Train Accuracy: 0.9833, Validation Accuracy: 0.9654, Loss: 0.0173
Epoch   5 Batch  504/538 - Train Accuracy: 0.9877, Validation Accuracy: 0.9670, Loss: 0.0106
Epoch   5 Batch  505/538 - Train Accuracy: 0.9834, Validation Accuracy: 0.9657, Loss: 0.0096
Epoch   5 Batch  506/538 - Train Accuracy: 0.9821, Validation Accuracy: 0.9675, Loss: 0.0128
Epoch   5 Batch  507/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9691, Loss: 0.0148
Epoch   5 Batch  508/538 - Train Accuracy: 0.9836, Validation Accuracy: 0.9703, Loss: 0.0097
Epoch   5 Batch  509/538 - Train Accuracy: 0.9844, Validation Accuracy: 0.9675, Loss: 0.0158
Epoch   5 Batch  510/538 - Train Accuracy: 0.9829, Validation Accuracy: 0.9688, Loss: 0.0112
Epoch   5 Batch  511/538 - Train Accuracy: 0.9707, Validation Accuracy: 0.9677, Loss: 0.0159
Epoch   5 Batch  512/538 - Train Accuracy: 0.9738, Validation Accuracy: 0.9673, Loss: 0.0152
Epoch   5 Batch  513/538 - Train Accuracy: 0.9665, Validation Accuracy: 0.9703, Loss: 0.0129
Epoch   5 Batch  514/538 - Train Accuracy: 0.9854, Validation Accuracy: 0.9705, Loss: 0.0130
Epoch   5 Batch  515/538 - Train Accuracy: 0.9762, Validation Accuracy: 0.9725, Loss: 0.0148
Epoch   5 Batch  516/538 - Train Accuracy: 0.9658, Validation Accuracy: 0.9698, Loss: 0.0156
Epoch   5 Batch  517/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9727, Loss: 0.0120
Epoch   5 Batch  518/538 - Train Accuracy: 0.9914, Validation Accuracy: 0.9668, Loss: 0.0140
Epoch   5 Batch  519/538 - Train Accuracy: 0.9795, Validation Accuracy: 0.9650, Loss: 0.0132
Epoch   5 Batch  520/538 - Train Accuracy: 0.9678, Validation Accuracy: 0.9648, Loss: 0.0175
Epoch   5 Batch  521/538 - Train Accuracy: 0.9875, Validation Accuracy: 0.9641, Loss: 0.0154
Epoch   5 Batch  522/538 - Train Accuracy: 0.9795, Validation Accuracy: 0.9688, Loss: 0.0093
Epoch   5 Batch  523/538 - Train Accuracy: 0.9934, Validation Accuracy: 0.9675, Loss: 0.0119
Epoch   5 Batch  524/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9700, Loss: 0.0100
Epoch   5 Batch  525/538 - Train Accuracy: 0.9829, Validation Accuracy: 0.9684, Loss: 0.0136
Epoch   5 Batch  526/538 - Train Accuracy: 0.9730, Validation Accuracy: 0.9698, Loss: 0.0136
Epoch   5 Batch  527/538 - Train Accuracy: 0.9873, Validation Accuracy: 0.9688, Loss: 0.0098
Epoch   5 Batch  528/538 - Train Accuracy: 0.9821, Validation Accuracy: 0.9680, Loss: 0.0150
Epoch   5 Batch  529/538 - Train Accuracy: 0.9850, Validation Accuracy: 0.9659, Loss: 0.0132
Epoch   5 Batch  530/538 - Train Accuracy: 0.9734, Validation Accuracy: 0.9716, Loss: 0.0123
Epoch   5 Batch  531/538 - Train Accuracy: 0.9627, Validation Accuracy: 0.9698, Loss: 0.0164
Epoch   5 Batch  532/538 - Train Accuracy: 0.9787, Validation Accuracy: 0.9746, Loss: 0.0112
Epoch   5 Batch  533/538 - Train Accuracy: 0.9746, Validation Accuracy: 0.9719, Loss: 0.0107
Epoch   5 Batch  534/538 - Train Accuracy: 0.9842, Validation Accuracy: 0.9744, Loss: 0.0085
Epoch   5 Batch  535/538 - Train Accuracy: 0.9881, Validation Accuracy: 0.9790, Loss: 0.0113
Epoch   5 Batch  536/538 - Train Accuracy: 0.9847, Validation Accuracy: 0.9776, Loss: 0.0149
Epoch   6 Batch    0/538 - Train Accuracy: 0.9795, Validation Accuracy: 0.9759, Loss: 0.0103
Epoch   6 Batch    1/538 - Train Accuracy: 0.9836, Validation Accuracy: 0.9798, Loss: 0.0152
Epoch   6 Batch    2/538 - Train Accuracy: 0.9814, Validation Accuracy: 0.9762, Loss: 0.0163
Epoch   6 Batch    3/538 - Train Accuracy: 0.9891, Validation Accuracy: 0.9760, Loss: 0.0108
Epoch   6 Batch    4/538 - Train Accuracy: 0.9801, Validation Accuracy: 0.9801, Loss: 0.0132
Epoch   6 Batch    5/538 - Train Accuracy: 0.9745, Validation Accuracy: 0.9812, Loss: 0.0168
Epoch   6 Batch    6/538 - Train Accuracy: 0.9784, Validation Accuracy: 0.9803, Loss: 0.0091
Epoch   6 Batch    7/538 - Train Accuracy: 0.9855, Validation Accuracy: 0.9817, Loss: 0.0119
Epoch   6 Batch    8/538 - Train Accuracy: 0.9867, Validation Accuracy: 0.9789, Loss: 0.0120
Epoch   6 Batch    9/538 - Train Accuracy: 0.9766, Validation Accuracy: 0.9766, Loss: 0.0131
Epoch   6 Batch   10/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9734, Loss: 0.0114
Epoch   6 Batch   11/538 - Train Accuracy: 0.9830, Validation Accuracy: 0.9709, Loss: 0.0126
Epoch   6 Batch   12/538 - Train Accuracy: 0.9830, Validation Accuracy: 0.9661, Loss: 0.0117
Epoch   6 Batch   13/538 - Train Accuracy: 0.9892, Validation Accuracy: 0.9636, Loss: 0.0107
Epoch   6 Batch   14/538 - Train Accuracy: 0.9750, Validation Accuracy: 0.9668, Loss: 0.0107
Epoch   6 Batch   15/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9657, Loss: 0.0108
Epoch   6 Batch   16/538 - Train Accuracy: 0.9877, Validation Accuracy: 0.9666, Loss: 0.0138
Epoch   6 Batch   17/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9688, Loss: 0.0125
Epoch   6 Batch   18/538 - Train Accuracy: 0.9830, Validation Accuracy: 0.9688, Loss: 0.0216
Epoch   6 Batch   19/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9700, Loss: 0.0138
Epoch   6 Batch   20/538 - Train Accuracy: 0.9827, Validation Accuracy: 0.9686, Loss: 0.0157
Epoch   6 Batch   21/538 - Train Accuracy: 0.9891, Validation Accuracy: 0.9680, Loss: 0.0087
Epoch   6 Batch   22/538 - Train Accuracy: 0.9738, Validation Accuracy: 0.9725, Loss: 0.0132
Epoch   6 Batch   23/538 - Train Accuracy: 0.9699, Validation Accuracy: 0.9750, Loss: 0.0151
Epoch   6 Batch   24/538 - Train Accuracy: 0.9868, Validation Accuracy: 0.9753, Loss: 0.0142
Epoch   6 Batch   25/538 - Train Accuracy: 0.9766, Validation Accuracy: 0.9803, Loss: 0.0148
Epoch   6 Batch   26/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9760, Loss: 0.0152
Epoch   6 Batch   27/538 - Train Accuracy: 0.9869, Validation Accuracy: 0.9735, Loss: 0.0092
Epoch   6 Batch   28/538 - Train Accuracy: 0.9918, Validation Accuracy: 0.9714, Loss: 0.0103
Epoch   6 Batch   29/538 - Train Accuracy: 0.9782, Validation Accuracy: 0.9716, Loss: 0.0100
Epoch   6 Batch   30/538 - Train Accuracy: 0.9746, Validation Accuracy: 0.9698, Loss: 0.0146
Epoch   6 Batch   31/538 - Train Accuracy: 0.9874, Validation Accuracy: 0.9684, Loss: 0.0106
Epoch   6 Batch   32/538 - Train Accuracy: 0.9866, Validation Accuracy: 0.9695, Loss: 0.0074
Epoch   6 Batch   33/538 - Train Accuracy: 0.9699, Validation Accuracy: 0.9743, Loss: 0.0176
Epoch   6 Batch   34/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9730, Loss: 0.0164
Epoch   6 Batch   35/538 - Train Accuracy: 0.9822, Validation Accuracy: 0.9727, Loss: 0.0103
Epoch   6 Batch   36/538 - Train Accuracy: 0.9903, Validation Accuracy: 0.9755, Loss: 0.0099
Epoch   6 Batch   37/538 - Train Accuracy: 0.9750, Validation Accuracy: 0.9737, Loss: 0.0156
Epoch   6 Batch   38/538 - Train Accuracy: 0.9869, Validation Accuracy: 0.9757, Loss: 0.0139
Epoch   6 Batch   39/538 - Train Accuracy: 0.9875, Validation Accuracy: 0.9782, Loss: 0.0108
Epoch   6 Batch   40/538 - Train Accuracy: 0.9824, Validation Accuracy: 0.9762, Loss: 0.0087
Epoch   6 Batch   41/538 - Train Accuracy: 0.9787, Validation Accuracy: 0.9743, Loss: 0.0136
Epoch   6 Batch   42/538 - Train Accuracy: 0.9768, Validation Accuracy: 0.9739, Loss: 0.0115
Epoch   6 Batch   43/538 - Train Accuracy: 0.9625, Validation Accuracy: 0.9757, Loss: 0.0142
Epoch   6 Batch   44/538 - Train Accuracy: 0.9826, Validation Accuracy: 0.9686, Loss: 0.0106
Epoch   6 Batch   45/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9787, Loss: 0.0101
Epoch   6 Batch   46/538 - Train Accuracy: 0.9814, Validation Accuracy: 0.9787, Loss: 0.0122
Epoch   6 Batch   47/538 - Train Accuracy: 0.9831, Validation Accuracy: 0.9792, Loss: 0.0125
Epoch   6 Batch   48/538 - Train Accuracy: 0.9805, Validation Accuracy: 0.9806, Loss: 0.0134
Epoch   6 Batch   49/538 - Train Accuracy: 0.9844, Validation Accuracy: 0.9817, Loss: 0.0095
Epoch   6 Batch   50/538 - Train Accuracy: 0.9742, Validation Accuracy: 0.9794, Loss: 0.0122
Epoch   6 Batch   51/538 - Train Accuracy: 0.9825, Validation Accuracy: 0.9773, Loss: 0.0174
Epoch   6 Batch   52/538 - Train Accuracy: 0.9867, Validation Accuracy: 0.9739, Loss: 0.0101
Epoch   6 Batch   53/538 - Train Accuracy: 0.9627, Validation Accuracy: 0.9759, Loss: 0.0155
Epoch   6 Batch   54/538 - Train Accuracy: 0.9834, Validation Accuracy: 0.9787, Loss: 0.0112
Epoch   6 Batch   55/538 - Train Accuracy: 0.9768, Validation Accuracy: 0.9757, Loss: 0.0118
Epoch   6 Batch   56/538 - Train Accuracy: 0.9786, Validation Accuracy: 0.9817, Loss: 0.0127
Epoch   6 Batch   57/538 - Train Accuracy: 0.9602, Validation Accuracy: 0.9790, Loss: 0.0169
Epoch   6 Batch   58/538 - Train Accuracy: 0.9891, Validation Accuracy: 0.9755, Loss: 0.0096
Epoch   6 Batch   59/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9755, Loss: 0.0137
Epoch   6 Batch   60/538 - Train Accuracy: 0.9904, Validation Accuracy: 0.9746, Loss: 0.0127
Epoch   6 Batch   61/538 - Train Accuracy: 0.9859, Validation Accuracy: 0.9771, Loss: 0.0116
Epoch   6 Batch   62/538 - Train Accuracy: 0.9732, Validation Accuracy: 0.9764, Loss: 0.0142
Epoch   6 Batch   63/538 - Train Accuracy: 0.9771, Validation Accuracy: 0.9751, Loss: 0.0121
Epoch   6 Batch   64/538 - Train Accuracy: 0.9792, Validation Accuracy: 0.9712, Loss: 0.0092
Epoch   6 Batch   65/538 - Train Accuracy: 0.9803, Validation Accuracy: 0.9757, Loss: 0.0124
Epoch   6 Batch   66/538 - Train Accuracy: 0.9851, Validation Accuracy: 0.9719, Loss: 0.0090
Epoch   6 Batch   67/538 - Train Accuracy: 0.9797, Validation Accuracy: 0.9732, Loss: 0.0113
Epoch   6 Batch   68/538 - Train Accuracy: 0.9808, Validation Accuracy: 0.9703, Loss: 0.0110
Epoch   6 Batch   69/538 - Train Accuracy: 0.9756, Validation Accuracy: 0.9728, Loss: 0.0134
Epoch   6 Batch   70/538 - Train Accuracy: 0.9764, Validation Accuracy: 0.9675, Loss: 0.0101
Epoch   6 Batch   71/538 - Train Accuracy: 0.9828, Validation Accuracy: 0.9688, Loss: 0.0127
Epoch   6 Batch   72/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9691, Loss: 0.0198
Epoch   6 Batch   73/538 - Train Accuracy: 0.9701, Validation Accuracy: 0.9696, Loss: 0.0138
Epoch   6 Batch   74/538 - Train Accuracy: 0.9907, Validation Accuracy: 0.9718, Loss: 0.0100
Epoch   6 Batch   75/538 - Train Accuracy: 0.9715, Validation Accuracy: 0.9716, Loss: 0.0148
Epoch   6 Batch   76/538 - Train Accuracy: 0.9783, Validation Accuracy: 0.9691, Loss: 0.0127
Epoch   6 Batch   77/538 - Train Accuracy: 0.9830, Validation Accuracy: 0.9711, Loss: 0.0101
Epoch   6 Batch   78/538 - Train Accuracy: 0.9805, Validation Accuracy: 0.9705, Loss: 0.0103
Epoch   6 Batch   79/538 - Train Accuracy: 0.9747, Validation Accuracy: 0.9741, Loss: 0.0092
Epoch   6 Batch   80/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9755, Loss: 0.0111
Epoch   6 Batch   81/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9730, Loss: 0.0158
Epoch   6 Batch   82/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9730, Loss: 0.0134
Epoch   6 Batch   83/538 - Train Accuracy: 0.9783, Validation Accuracy: 0.9688, Loss: 0.0138
Epoch   6 Batch   84/538 - Train Accuracy: 0.9751, Validation Accuracy: 0.9723, Loss: 0.0140
Epoch   6 Batch   85/538 - Train Accuracy: 0.9954, Validation Accuracy: 0.9739, Loss: 0.0092
Epoch   6 Batch   86/538 - Train Accuracy: 0.9791, Validation Accuracy: 0.9714, Loss: 0.0108
Epoch   6 Batch   87/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9776, Loss: 0.0135
Epoch   6 Batch   88/538 - Train Accuracy: 0.9803, Validation Accuracy: 0.9735, Loss: 0.0126
Epoch   6 Batch   89/538 - Train Accuracy: 0.9775, Validation Accuracy: 0.9707, Loss: 0.0115
Epoch   6 Batch   90/538 - Train Accuracy: 0.9764, Validation Accuracy: 0.9670, Loss: 0.0154
Epoch   6 Batch   91/538 - Train Accuracy: 0.9785, Validation Accuracy: 0.9673, Loss: 0.0161
Epoch   6 Batch   92/538 - Train Accuracy: 0.9736, Validation Accuracy: 0.9675, Loss: 0.0124
Epoch   6 Batch   93/538 - Train Accuracy: 0.9807, Validation Accuracy: 0.9723, Loss: 0.0107
Epoch   6 Batch   94/538 - Train Accuracy: 0.9766, Validation Accuracy: 0.9682, Loss: 0.0112
Epoch   6 Batch   95/538 - Train Accuracy: 0.9790, Validation Accuracy: 0.9654, Loss: 0.0098
Epoch   6 Batch   96/538 - Train Accuracy: 0.9697, Validation Accuracy: 0.9650, Loss: 0.0102
Epoch   6 Batch   97/538 - Train Accuracy: 0.9832, Validation Accuracy: 0.9680, Loss: 0.0105
Epoch   6 Batch   98/538 - Train Accuracy: 0.9792, Validation Accuracy: 0.9748, Loss: 0.0178
Epoch   6 Batch   99/538 - Train Accuracy: 0.9883, Validation Accuracy: 0.9750, Loss: 0.0108
Epoch   6 Batch  100/538 - Train Accuracy: 0.9836, Validation Accuracy: 0.9775, Loss: 0.0097
Epoch   6 Batch  101/538 - Train Accuracy: 0.9725, Validation Accuracy: 0.9767, Loss: 0.0177
Epoch   6 Batch  102/538 - Train Accuracy: 0.9713, Validation Accuracy: 0.9703, Loss: 0.0167
Epoch   6 Batch  103/538 - Train Accuracy: 0.9821, Validation Accuracy: 0.9698, Loss: 0.0116
Epoch   6 Batch  104/538 - Train Accuracy: 0.9849, Validation Accuracy: 0.9698, Loss: 0.0115
Epoch   6 Batch  105/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9686, Loss: 0.0084
Epoch   6 Batch  106/538 - Train Accuracy: 0.9785, Validation Accuracy: 0.9675, Loss: 0.0088
Epoch   6 Batch  107/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9748, Loss: 0.0148
Epoch   6 Batch  108/538 - Train Accuracy: 0.9795, Validation Accuracy: 0.9771, Loss: 0.0137
Epoch   6 Batch  109/538 - Train Accuracy: 0.9863, Validation Accuracy: 0.9716, Loss: 0.0131
Epoch   6 Batch  110/538 - Train Accuracy: 0.9822, Validation Accuracy: 0.9668, Loss: 0.0153
Epoch   6 Batch  111/538 - Train Accuracy: 0.9714, Validation Accuracy: 0.9693, Loss: 0.0117
Epoch   6 Batch  112/538 - Train Accuracy: 0.9791, Validation Accuracy: 0.9686, Loss: 0.0146
Epoch   6 Batch  113/538 - Train Accuracy: 0.9623, Validation Accuracy: 0.9636, Loss: 0.0178
Epoch   6 Batch  114/538 - Train Accuracy: 0.9833, Validation Accuracy: 0.9700, Loss: 0.0101
Epoch   6 Batch  115/538 - Train Accuracy: 0.9811, Validation Accuracy: 0.9705, Loss: 0.0121
Epoch   6 Batch  116/538 - Train Accuracy: 0.9792, Validation Accuracy: 0.9718, Loss: 0.0144
Epoch   6 Batch  117/538 - Train Accuracy: 0.9844, Validation Accuracy: 0.9696, Loss: 0.0128
Epoch   6 Batch  118/538 - Train Accuracy: 0.9740, Validation Accuracy: 0.9709, Loss: 0.0178
Epoch   6 Batch  119/538 - Train Accuracy: 0.9905, Validation Accuracy: 0.9686, Loss: 0.0085
Epoch   6 Batch  120/538 - Train Accuracy: 0.9830, Validation Accuracy: 0.9686, Loss: 0.0104
Epoch   6 Batch  121/538 - Train Accuracy: 0.9771, Validation Accuracy: 0.9682, Loss: 0.0129
Epoch   6 Batch  122/538 - Train Accuracy: 0.9753, Validation Accuracy: 0.9672, Loss: 0.0144
Epoch   6 Batch  123/538 - Train Accuracy: 0.9682, Validation Accuracy: 0.9618, Loss: 0.0155
Epoch   6 Batch  124/538 - Train Accuracy: 0.9776, Validation Accuracy: 0.9622, Loss: 0.0126
Epoch   6 Batch  125/538 - Train Accuracy: 0.9784, Validation Accuracy: 0.9613, Loss: 0.0163
Epoch   6 Batch  126/538 - Train Accuracy: 0.9734, Validation Accuracy: 0.9606, Loss: 0.0164
Epoch   6 Batch  127/538 - Train Accuracy: 0.9730, Validation Accuracy: 0.9627, Loss: 0.0184
Epoch   6 Batch  128/538 - Train Accuracy: 0.9868, Validation Accuracy: 0.9611, Loss: 0.0110
Epoch   6 Batch  129/538 - Train Accuracy: 0.9831, Validation Accuracy: 0.9688, Loss: 0.0115
Epoch   6 Batch  130/538 - Train Accuracy: 0.9844, Validation Accuracy: 0.9664, Loss: 0.0124
Epoch   6 Batch  131/538 - Train Accuracy: 0.9914, Validation Accuracy: 0.9682, Loss: 0.0132
Epoch   6 Batch  132/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9680, Loss: 0.0130
Epoch   6 Batch  133/538 - Train Accuracy: 0.9824, Validation Accuracy: 0.9739, Loss: 0.0150
Epoch   6 Batch  134/538 - Train Accuracy: 0.9734, Validation Accuracy: 0.9691, Loss: 0.0179
Epoch   6 Batch  135/538 - Train Accuracy: 0.9803, Validation Accuracy: 0.9712, Loss: 0.0173
Epoch   6 Batch  136/538 - Train Accuracy: 0.9816, Validation Accuracy: 0.9739, Loss: 0.0136
Epoch   6 Batch  137/538 - Train Accuracy: 0.9875, Validation Accuracy: 0.9709, Loss: 0.0129
Epoch   6 Batch  138/538 - Train Accuracy: 0.9887, Validation Accuracy: 0.9732, Loss: 0.0112
Epoch   6 Batch  139/538 - Train Accuracy: 0.9768, Validation Accuracy: 0.9753, Loss: 0.0146
Epoch   6 Batch  140/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9744, Loss: 0.0157
Epoch   6 Batch  141/538 - Train Accuracy: 0.9744, Validation Accuracy: 0.9762, Loss: 0.0134
Epoch   6 Batch  142/538 - Train Accuracy: 0.9808, Validation Accuracy: 0.9778, Loss: 0.0135
Epoch   6 Batch  143/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9790, Loss: 0.0153
Epoch   6 Batch  144/538 - Train Accuracy: 0.9834, Validation Accuracy: 0.9769, Loss: 0.0156
Epoch   6 Batch  145/538 - Train Accuracy: 0.9825, Validation Accuracy: 0.9760, Loss: 0.0164
Epoch   6 Batch  146/538 - Train Accuracy: 0.9817, Validation Accuracy: 0.9734, Loss: 0.0113
Epoch   6 Batch  147/538 - Train Accuracy: 0.9834, Validation Accuracy: 0.9743, Loss: 0.0122
Epoch   6 Batch  148/538 - Train Accuracy: 0.9742, Validation Accuracy: 0.9790, Loss: 0.0159
Epoch   6 Batch  149/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9757, Loss: 0.0114
Epoch   6 Batch  150/538 - Train Accuracy: 0.9822, Validation Accuracy: 0.9725, Loss: 0.0120
Epoch   6 Batch  151/538 - Train Accuracy: 0.9788, Validation Accuracy: 0.9748, Loss: 0.0166
Epoch   6 Batch  152/538 - Train Accuracy: 0.9784, Validation Accuracy: 0.9792, Loss: 0.0157
Epoch   6 Batch  153/538 - Train Accuracy: 0.9866, Validation Accuracy: 0.9798, Loss: 0.0107
Epoch   6 Batch  154/538 - Train Accuracy: 0.9805, Validation Accuracy: 0.9785, Loss: 0.0131
Epoch   6 Batch  155/538 - Train Accuracy: 0.9803, Validation Accuracy: 0.9750, Loss: 0.0140
Epoch   6 Batch  156/538 - Train Accuracy: 0.9877, Validation Accuracy: 0.9723, Loss: 0.0133
Epoch   6 Batch  157/538 - Train Accuracy: 0.9864, Validation Accuracy: 0.9680, Loss: 0.0144
Epoch   6 Batch  158/538 - Train Accuracy: 0.9922, Validation Accuracy: 0.9673, Loss: 0.0099
Epoch   6 Batch  159/538 - Train Accuracy: 0.9883, Validation Accuracy: 0.9677, Loss: 0.0155
Epoch   6 Batch  160/538 - Train Accuracy: 0.9788, Validation Accuracy: 0.9750, Loss: 0.0125
Epoch   6 Batch  161/538 - Train Accuracy: 0.9699, Validation Accuracy: 0.9753, Loss: 0.0118
Epoch   6 Batch  162/538 - Train Accuracy: 0.9901, Validation Accuracy: 0.9746, Loss: 0.0113
Epoch   6 Batch  163/538 - Train Accuracy: 0.9859, Validation Accuracy: 0.9746, Loss: 0.0155
Epoch   6 Batch  164/538 - Train Accuracy: 0.9834, Validation Accuracy: 0.9767, Loss: 0.0142
Epoch   6 Batch  165/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9718, Loss: 0.0102
Epoch   6 Batch  166/538 - Train Accuracy: 0.9850, Validation Accuracy: 0.9751, Loss: 0.0097
Epoch   6 Batch  167/538 - Train Accuracy: 0.9767, Validation Accuracy: 0.9760, Loss: 0.0190
Epoch   6 Batch  168/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9775, Loss: 0.0163
Epoch   6 Batch  169/538 - Train Accuracy: 0.9938, Validation Accuracy: 0.9775, Loss: 0.0103
Epoch   6 Batch  170/538 - Train Accuracy: 0.9821, Validation Accuracy: 0.9730, Loss: 0.0121
Epoch   6 Batch  171/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9732, Loss: 0.0135
Epoch   6 Batch  172/538 - Train Accuracy: 0.9751, Validation Accuracy: 0.9702, Loss: 0.0099
Epoch   6 Batch  173/538 - Train Accuracy: 0.9879, Validation Accuracy: 0.9698, Loss: 0.0089
Epoch   6 Batch  174/538 - Train Accuracy: 0.9732, Validation Accuracy: 0.9654, Loss: 0.0138
Epoch   6 Batch  175/538 - Train Accuracy: 0.9889, Validation Accuracy: 0.9652, Loss: 0.0101
Epoch   6 Batch  176/538 - Train Accuracy: 0.9752, Validation Accuracy: 0.9636, Loss: 0.0154
Epoch   6 Batch  177/538 - Train Accuracy: 0.9816, Validation Accuracy: 0.9638, Loss: 0.0118
Epoch   6 Batch  178/538 - Train Accuracy: 0.9643, Validation Accuracy: 0.9657, Loss: 0.0155
Epoch   6 Batch  179/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9702, Loss: 0.0121
Epoch   6 Batch  180/538 - Train Accuracy: 0.9725, Validation Accuracy: 0.9753, Loss: 0.0166
Epoch   6 Batch  181/538 - Train Accuracy: 0.9676, Validation Accuracy: 0.9741, Loss: 0.0177
Epoch   6 Batch  182/538 - Train Accuracy: 0.9719, Validation Accuracy: 0.9766, Loss: 0.0102
Epoch   6 Batch  183/538 - Train Accuracy: 0.9868, Validation Accuracy: 0.9711, Loss: 0.0118
Epoch   6 Batch  184/538 - Train Accuracy: 0.9877, Validation Accuracy: 0.9686, Loss: 0.0127
Epoch   6 Batch  185/538 - Train Accuracy: 0.9900, Validation Accuracy: 0.9711, Loss: 0.0078
Epoch   6 Batch  186/538 - Train Accuracy: 0.9823, Validation Accuracy: 0.9686, Loss: 0.0089
Epoch   6 Batch  187/538 - Train Accuracy: 0.9847, Validation Accuracy: 0.9691, Loss: 0.0126
Epoch   6 Batch  188/538 - Train Accuracy: 0.9859, Validation Accuracy: 0.9675, Loss: 0.0110
Epoch   6 Batch  189/538 - Train Accuracy: 0.9877, Validation Accuracy: 0.9657, Loss: 0.0147
Epoch   6 Batch  190/538 - Train Accuracy: 0.9732, Validation Accuracy: 0.9634, Loss: 0.0178
Epoch   6 Batch  191/538 - Train Accuracy: 0.9807, Validation Accuracy: 0.9684, Loss: 0.0140
Epoch   6 Batch  192/538 - Train Accuracy: 0.9738, Validation Accuracy: 0.9664, Loss: 0.0135
Epoch   6 Batch  193/538 - Train Accuracy: 0.9751, Validation Accuracy: 0.9629, Loss: 0.0125
Epoch   6 Batch  194/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9629, Loss: 0.0153
Epoch   6 Batch  195/538 - Train Accuracy: 0.9900, Validation Accuracy: 0.9688, Loss: 0.0150
Epoch   6 Batch  196/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9689, Loss: 0.0116
Epoch   6 Batch  197/538 - Train Accuracy: 0.9775, Validation Accuracy: 0.9648, Loss: 0.0106
Epoch   6 Batch  198/538 - Train Accuracy: 0.9682, Validation Accuracy: 0.9583, Loss: 0.0152
Epoch   6 Batch  199/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9615, Loss: 0.0117
Epoch   6 Batch  200/538 - Train Accuracy: 0.9746, Validation Accuracy: 0.9629, Loss: 0.0100
Epoch   6 Batch  201/538 - Train Accuracy: 0.9727, Validation Accuracy: 0.9627, Loss: 0.0176
Epoch   6 Batch  202/538 - Train Accuracy: 0.9836, Validation Accuracy: 0.9673, Loss: 0.0106
Epoch   6 Batch  203/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9698, Loss: 0.0129
Epoch   6 Batch  204/538 - Train Accuracy: 0.9756, Validation Accuracy: 0.9705, Loss: 0.0225
Epoch   6 Batch  205/538 - Train Accuracy: 0.9816, Validation Accuracy: 0.9709, Loss: 0.0118
Epoch   6 Batch  206/538 - Train Accuracy: 0.9914, Validation Accuracy: 0.9684, Loss: 0.0085
Epoch   6 Batch  207/538 - Train Accuracy: 0.9821, Validation Accuracy: 0.9632, Loss: 0.0143
Epoch   6 Batch  208/538 - Train Accuracy: 0.9803, Validation Accuracy: 0.9664, Loss: 0.0162
Epoch   6 Batch  209/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9659, Loss: 0.0132
Epoch   6 Batch  210/538 - Train Accuracy: 0.9924, Validation Accuracy: 0.9657, Loss: 0.0126
Epoch   6 Batch  211/538 - Train Accuracy: 0.9793, Validation Accuracy: 0.9625, Loss: 0.0129
Epoch   6 Batch  212/538 - Train Accuracy: 0.9836, Validation Accuracy: 0.9654, Loss: 0.0086
Epoch   6 Batch  213/538 - Train Accuracy: 0.9794, Validation Accuracy: 0.9654, Loss: 0.0149
Epoch   6 Batch  214/538 - Train Accuracy: 0.9863, Validation Accuracy: 0.9645, Loss: 0.0107
Epoch   6 Batch  215/538 - Train Accuracy: 0.9811, Validation Accuracy: 0.9616, Loss: 0.0102
Epoch   6 Batch  216/538 - Train Accuracy: 0.9844, Validation Accuracy: 0.9634, Loss: 0.0127
Epoch   6 Batch  217/538 - Train Accuracy: 0.9879, Validation Accuracy: 0.9616, Loss: 0.0138
Epoch   6 Batch  218/538 - Train Accuracy: 0.9924, Validation Accuracy: 0.9641, Loss: 0.0104
Epoch   6 Batch  219/538 - Train Accuracy: 0.9803, Validation Accuracy: 0.9728, Loss: 0.0126
Epoch   6 Batch  220/538 - Train Accuracy: 0.9684, Validation Accuracy: 0.9741, Loss: 0.0152
Epoch   6 Batch  221/538 - Train Accuracy: 0.9860, Validation Accuracy: 0.9686, Loss: 0.0113
Epoch   6 Batch  222/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9682, Loss: 0.0078
Epoch   6 Batch  223/538 - Train Accuracy: 0.9826, Validation Accuracy: 0.9673, Loss: 0.0134
Epoch   6 Batch  224/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9700, Loss: 0.0159
Epoch   6 Batch  225/538 - Train Accuracy: 0.9803, Validation Accuracy: 0.9675, Loss: 0.0115
Epoch   6 Batch  226/538 - Train Accuracy: 0.9725, Validation Accuracy: 0.9695, Loss: 0.0154
Epoch   6 Batch  227/538 - Train Accuracy: 0.9817, Validation Accuracy: 0.9707, Loss: 0.0148
Epoch   6 Batch  228/538 - Train Accuracy: 0.9764, Validation Accuracy: 0.9682, Loss: 0.0137
Epoch   6 Batch  229/538 - Train Accuracy: 0.9766, Validation Accuracy: 0.9796, Loss: 0.0132
Epoch   6 Batch  230/538 - Train Accuracy: 0.9744, Validation Accuracy: 0.9753, Loss: 0.0124
Epoch   6 Batch  231/538 - Train Accuracy: 0.9684, Validation Accuracy: 0.9776, Loss: 0.0170
Epoch   6 Batch  232/538 - Train Accuracy: 0.9711, Validation Accuracy: 0.9656, Loss: 0.0180
Epoch   6 Batch  233/538 - Train Accuracy: 0.9927, Validation Accuracy: 0.9643, Loss: 0.0084
Epoch   6 Batch  234/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9565, Loss: 0.0107
Epoch   6 Batch  235/538 - Train Accuracy: 0.9769, Validation Accuracy: 0.9540, Loss: 0.0127
Epoch   6 Batch  236/538 - Train Accuracy: 0.9682, Validation Accuracy: 0.9581, Loss: 0.0116
Epoch   6 Batch  237/538 - Train Accuracy: 0.9785, Validation Accuracy: 0.9627, Loss: 0.0098
Epoch   6 Batch  238/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9565, Loss: 0.0161
Epoch   6 Batch  239/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9533, Loss: 0.0136
Epoch   6 Batch  240/538 - Train Accuracy: 0.9631, Validation Accuracy: 0.9529, Loss: 0.0155
Epoch   6 Batch  241/538 - Train Accuracy: 0.9650, Validation Accuracy: 0.9553, Loss: 0.0223
Epoch   6 Batch  242/538 - Train Accuracy: 0.9836, Validation Accuracy: 0.9586, Loss: 0.0110
Epoch   6 Batch  243/538 - Train Accuracy: 0.9778, Validation Accuracy: 0.9624, Loss: 0.0141
Epoch   6 Batch  244/538 - Train Accuracy: 0.9714, Validation Accuracy: 0.9611, Loss: 0.0116
Epoch   6 Batch  245/538 - Train Accuracy: 0.9684, Validation Accuracy: 0.9595, Loss: 0.0191
Epoch   6 Batch  246/538 - Train Accuracy: 0.9788, Validation Accuracy: 0.9585, Loss: 0.0112
Epoch   6 Batch  247/538 - Train Accuracy: 0.9703, Validation Accuracy: 0.9583, Loss: 0.0139
Epoch   6 Batch  248/538 - Train Accuracy: 0.9666, Validation Accuracy: 0.9554, Loss: 0.0191
Epoch   6 Batch  249/538 - Train Accuracy: 0.9786, Validation Accuracy: 0.9583, Loss: 0.0103
Epoch   6 Batch  250/538 - Train Accuracy: 0.9801, Validation Accuracy: 0.9574, Loss: 0.0127
Epoch   6 Batch  251/538 - Train Accuracy: 0.9730, Validation Accuracy: 0.9629, Loss: 0.0134
Epoch   6 Batch  252/538 - Train Accuracy: 0.9849, Validation Accuracy: 0.9709, Loss: 0.0139
Epoch   6 Batch  253/538 - Train Accuracy: 0.9794, Validation Accuracy: 0.9695, Loss: 0.0110
Epoch   6 Batch  254/538 - Train Accuracy: 0.9811, Validation Accuracy: 0.9641, Loss: 0.0171
Epoch   6 Batch  255/538 - Train Accuracy: 0.9904, Validation Accuracy: 0.9632, Loss: 0.0111
Epoch   6 Batch  256/538 - Train Accuracy: 0.9881, Validation Accuracy: 0.9631, Loss: 0.0138
Epoch   6 Batch  257/538 - Train Accuracy: 0.9834, Validation Accuracy: 0.9656, Loss: 0.0119
Epoch   6 Batch  258/538 - Train Accuracy: 0.9717, Validation Accuracy: 0.9677, Loss: 0.0147
Epoch   6 Batch  259/538 - Train Accuracy: 0.9847, Validation Accuracy: 0.9711, Loss: 0.0107
Epoch   6 Batch  260/538 - Train Accuracy: 0.9736, Validation Accuracy: 0.9677, Loss: 0.0178
Epoch   6 Batch  261/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9632, Loss: 0.0149
Epoch   6 Batch  262/538 - Train Accuracy: 0.9805, Validation Accuracy: 0.9585, Loss: 0.0204
Epoch   6 Batch  263/538 - Train Accuracy: 0.9703, Validation Accuracy: 0.9636, Loss: 0.0151
Epoch   6 Batch  264/538 - Train Accuracy: 0.9795, Validation Accuracy: 0.9668, Loss: 0.0146
Epoch   6 Batch  265/538 - Train Accuracy: 0.9670, Validation Accuracy: 0.9693, Loss: 0.0184
Epoch   6 Batch  266/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9663, Loss: 0.0131
Epoch   6 Batch  267/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9688, Loss: 0.0151
Epoch   6 Batch  268/538 - Train Accuracy: 0.9732, Validation Accuracy: 0.9732, Loss: 0.0111
Epoch   6 Batch  269/538 - Train Accuracy: 0.9906, Validation Accuracy: 0.9684, Loss: 0.0135
Epoch   6 Batch  270/538 - Train Accuracy: 0.9898, Validation Accuracy: 0.9679, Loss: 0.0112
Epoch   6 Batch  271/538 - Train Accuracy: 0.9785, Validation Accuracy: 0.9721, Loss: 0.0094
Epoch   6 Batch  272/538 - Train Accuracy: 0.9846, Validation Accuracy: 0.9632, Loss: 0.0115
Epoch   6 Batch  273/538 - Train Accuracy: 0.9621, Validation Accuracy: 0.9604, Loss: 0.0163
Epoch   6 Batch  274/538 - Train Accuracy: 0.9611, Validation Accuracy: 0.9569, Loss: 0.0139
Epoch   6 Batch  275/538 - Train Accuracy: 0.9752, Validation Accuracy: 0.9538, Loss: 0.0168
Epoch   6 Batch  276/538 - Train Accuracy: 0.9855, Validation Accuracy: 0.9538, Loss: 0.0183
Epoch   6 Batch  277/538 - Train Accuracy: 0.9881, Validation Accuracy: 0.9677, Loss: 0.0082
Epoch   6 Batch  278/538 - Train Accuracy: 0.9764, Validation Accuracy: 0.9618, Loss: 0.0105
Epoch   6 Batch  279/538 - Train Accuracy: 0.9705, Validation Accuracy: 0.9585, Loss: 0.0136
Epoch   6 Batch  280/538 - Train Accuracy: 0.9888, Validation Accuracy: 0.9583, Loss: 0.0104
Epoch   6 Batch  281/538 - Train Accuracy: 0.9686, Validation Accuracy: 0.9567, Loss: 0.0181
Epoch   6 Batch  282/538 - Train Accuracy: 0.9771, Validation Accuracy: 0.9625, Loss: 0.0159
Epoch   6 Batch  283/538 - Train Accuracy: 0.9879, Validation Accuracy: 0.9670, Loss: 0.0153
Epoch   6 Batch  284/538 - Train Accuracy: 0.9807, Validation Accuracy: 0.9679, Loss: 0.0148
Epoch   6 Batch  285/538 - Train Accuracy: 0.9842, Validation Accuracy: 0.9688, Loss: 0.0112
Epoch   6 Batch  286/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9688, Loss: 0.0210
Epoch   6 Batch  287/538 - Train Accuracy: 0.9860, Validation Accuracy: 0.9716, Loss: 0.0093
Epoch   6 Batch  288/538 - Train Accuracy: 0.9855, Validation Accuracy: 0.9780, Loss: 0.0099
Epoch   6 Batch  289/538 - Train Accuracy: 0.9773, Validation Accuracy: 0.9760, Loss: 0.0153
Epoch   6 Batch  290/538 - Train Accuracy: 0.9857, Validation Accuracy: 0.9760, Loss: 0.0101
Epoch   6 Batch  291/538 - Train Accuracy: 0.9846, Validation Accuracy: 0.9744, Loss: 0.0127
Epoch   6 Batch  292/538 - Train Accuracy: 0.9900, Validation Accuracy: 0.9755, Loss: 0.0082
Epoch   6 Batch  293/538 - Train Accuracy: 0.9823, Validation Accuracy: 0.9773, Loss: 0.0134
Epoch   6 Batch  294/538 - Train Accuracy: 0.9819, Validation Accuracy: 0.9767, Loss: 0.0134
Epoch   6 Batch  295/538 - Train Accuracy: 0.9780, Validation Accuracy: 0.9785, Loss: 0.0142
Epoch   6 Batch  296/538 - Train Accuracy: 0.9807, Validation Accuracy: 0.9778, Loss: 0.0211
Epoch   6 Batch  297/538 - Train Accuracy: 0.9879, Validation Accuracy: 0.9773, Loss: 0.0122
Epoch   6 Batch  298/538 - Train Accuracy: 0.9825, Validation Accuracy: 0.9833, Loss: 0.0118
Epoch   6 Batch  299/538 - Train Accuracy: 0.9734, Validation Accuracy: 0.9799, Loss: 0.0161
Epoch   6 Batch  300/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9814, Loss: 0.0122
Epoch   6 Batch  301/538 - Train Accuracy: 0.9764, Validation Accuracy: 0.9771, Loss: 0.0153
Epoch   6 Batch  302/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9744, Loss: 0.0161
Epoch   6 Batch  303/538 - Train Accuracy: 0.9805, Validation Accuracy: 0.9743, Loss: 0.0163
Epoch   6 Batch  304/538 - Train Accuracy: 0.9863, Validation Accuracy: 0.9753, Loss: 0.0157
Epoch   6 Batch  305/538 - Train Accuracy: 0.9738, Validation Accuracy: 0.9737, Loss: 0.0132
Epoch   6 Batch  306/538 - Train Accuracy: 0.9827, Validation Accuracy: 0.9686, Loss: 0.0126
Epoch   6 Batch  307/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9680, Loss: 0.0124
Epoch   6 Batch  308/538 - Train Accuracy: 0.9901, Validation Accuracy: 0.9666, Loss: 0.0113
Epoch   6 Batch  309/538 - Train Accuracy: 0.9807, Validation Accuracy: 0.9654, Loss: 0.0114
Epoch   6 Batch  310/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9659, Loss: 0.0184
Epoch   6 Batch  311/538 - Train Accuracy: 0.9875, Validation Accuracy: 0.9661, Loss: 0.0128
Epoch   6 Batch  312/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9684, Loss: 0.0130
Epoch   6 Batch  313/538 - Train Accuracy: 0.9809, Validation Accuracy: 0.9636, Loss: 0.0125
Epoch   6 Batch  314/538 - Train Accuracy: 0.9871, Validation Accuracy: 0.9609, Loss: 0.0105
Epoch   6 Batch  315/538 - Train Accuracy: 0.9773, Validation Accuracy: 0.9622, Loss: 0.0109
Epoch   6 Batch  316/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9609, Loss: 0.0105
Epoch   6 Batch  317/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9604, Loss: 0.0136
Epoch   6 Batch  318/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9588, Loss: 0.0103
Epoch   6 Batch  319/538 - Train Accuracy: 0.9782, Validation Accuracy: 0.9629, Loss: 0.0137
Epoch   6 Batch  320/538 - Train Accuracy: 0.9887, Validation Accuracy: 0.9666, Loss: 0.0103
Epoch   6 Batch  321/538 - Train Accuracy: 0.9851, Validation Accuracy: 0.9705, Loss: 0.0100
Epoch   6 Batch  322/538 - Train Accuracy: 0.9857, Validation Accuracy: 0.9663, Loss: 0.0127
Epoch   6 Batch  323/538 - Train Accuracy: 0.9879, Validation Accuracy: 0.9629, Loss: 0.0093
Epoch   6 Batch  324/538 - Train Accuracy: 0.9891, Validation Accuracy: 0.9632, Loss: 0.0103
Epoch   6 Batch  325/538 - Train Accuracy: 0.9834, Validation Accuracy: 0.9661, Loss: 0.0138
Epoch   6 Batch  326/538 - Train Accuracy: 0.9846, Validation Accuracy: 0.9643, Loss: 0.0126
Epoch   6 Batch  327/538 - Train Accuracy: 0.9838, Validation Accuracy: 0.9647, Loss: 0.0112
Epoch   6 Batch  328/538 - Train Accuracy: 0.9914, Validation Accuracy: 0.9673, Loss: 0.0083
Epoch   6 Batch  329/538 - Train Accuracy: 0.9957, Validation Accuracy: 0.9672, Loss: 0.0081
Epoch   6 Batch  330/538 - Train Accuracy: 0.9807, Validation Accuracy: 0.9654, Loss: 0.0119
Epoch   6 Batch  331/538 - Train Accuracy: 0.9826, Validation Accuracy: 0.9698, Loss: 0.0147
Epoch   6 Batch  332/538 - Train Accuracy: 0.9855, Validation Accuracy: 0.9677, Loss: 0.0106
Epoch   6 Batch  333/538 - Train Accuracy: 0.9704, Validation Accuracy: 0.9675, Loss: 0.0134
Epoch   6 Batch  334/538 - Train Accuracy: 0.9806, Validation Accuracy: 0.9712, Loss: 0.0098
Epoch   6 Batch  335/538 - Train Accuracy: 0.9836, Validation Accuracy: 0.9721, Loss: 0.0123
Epoch   6 Batch  336/538 - Train Accuracy: 0.9872, Validation Accuracy: 0.9677, Loss: 0.0133
Epoch   6 Batch  337/538 - Train Accuracy: 0.9775, Validation Accuracy: 0.9688, Loss: 0.0146
Epoch   6 Batch  338/538 - Train Accuracy: 0.9868, Validation Accuracy: 0.9688, Loss: 0.0122
Epoch   6 Batch  339/538 - Train Accuracy: 0.9775, Validation Accuracy: 0.9691, Loss: 0.0122
Epoch   6 Batch  340/538 - Train Accuracy: 0.9785, Validation Accuracy: 0.9645, Loss: 0.0108
Epoch   6 Batch  341/538 - Train Accuracy: 0.9793, Validation Accuracy: 0.9656, Loss: 0.0127
Epoch   6 Batch  342/538 - Train Accuracy: 0.9782, Validation Accuracy: 0.9638, Loss: 0.0128
Epoch   6 Batch  343/538 - Train Accuracy: 0.9922, Validation Accuracy: 0.9695, Loss: 0.0118
Epoch   6 Batch  344/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9656, Loss: 0.0096
Epoch   6 Batch  345/538 - Train Accuracy: 0.9814, Validation Accuracy: 0.9629, Loss: 0.0126
Epoch   6 Batch  346/538 - Train Accuracy: 0.9721, Validation Accuracy: 0.9648, Loss: 0.0164
Epoch   6 Batch  347/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9666, Loss: 0.0108
Epoch   6 Batch  348/538 - Train Accuracy: 0.9807, Validation Accuracy: 0.9659, Loss: 0.0103
Epoch   6 Batch  349/538 - Train Accuracy: 0.9781, Validation Accuracy: 0.9659, Loss: 0.0093
Epoch   6 Batch  350/538 - Train Accuracy: 0.9829, Validation Accuracy: 0.9634, Loss: 0.0131
Epoch   6 Batch  351/538 - Train Accuracy: 0.9742, Validation Accuracy: 0.9705, Loss: 0.0140
Epoch   6 Batch  352/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9735, Loss: 0.0240
Epoch   6 Batch  353/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9760, Loss: 0.0132
Epoch   6 Batch  354/538 - Train Accuracy: 0.9832, Validation Accuracy: 0.9647, Loss: 0.0121
Epoch   6 Batch  355/538 - Train Accuracy: 0.9842, Validation Accuracy: 0.9641, Loss: 0.0160
Epoch   6 Batch  356/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9682, Loss: 0.0095
Epoch   6 Batch  357/538 - Train Accuracy: 0.9734, Validation Accuracy: 0.9700, Loss: 0.0114
Epoch   6 Batch  358/538 - Train Accuracy: 0.9877, Validation Accuracy: 0.9663, Loss: 0.0097
Epoch   6 Batch  359/538 - Train Accuracy: 0.9788, Validation Accuracy: 0.9672, Loss: 0.0112
Epoch   6 Batch  360/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9673, Loss: 0.0119
Epoch   6 Batch  361/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9700, Loss: 0.0127
Epoch   6 Batch  362/538 - Train Accuracy: 0.9803, Validation Accuracy: 0.9718, Loss: 0.0126
Epoch   6 Batch  363/538 - Train Accuracy: 0.9784, Validation Accuracy: 0.9695, Loss: 0.0138
Epoch   6 Batch  364/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9675, Loss: 0.0141
Epoch   6 Batch  365/538 - Train Accuracy: 0.9821, Validation Accuracy: 0.9650, Loss: 0.0106
Epoch   6 Batch  366/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9693, Loss: 0.0132
Epoch   6 Batch  367/538 - Train Accuracy: 0.9861, Validation Accuracy: 0.9686, Loss: 0.0099
Epoch   6 Batch  368/538 - Train Accuracy: 0.9873, Validation Accuracy: 0.9684, Loss: 0.0090
Epoch   6 Batch  369/538 - Train Accuracy: 0.9664, Validation Accuracy: 0.9688, Loss: 0.0157
Epoch   6 Batch  370/538 - Train Accuracy: 0.9752, Validation Accuracy: 0.9661, Loss: 0.0134
Epoch   6 Batch  371/538 - Train Accuracy: 0.9898, Validation Accuracy: 0.9661, Loss: 0.0107
Epoch   6 Batch  372/538 - Train Accuracy: 0.9762, Validation Accuracy: 0.9647, Loss: 0.0131
Epoch   6 Batch  373/538 - Train Accuracy: 0.9732, Validation Accuracy: 0.9680, Loss: 0.0123
Epoch   6 Batch  374/538 - Train Accuracy: 0.9775, Validation Accuracy: 0.9735, Loss: 0.0102
Epoch   6 Batch  375/538 - Train Accuracy: 0.9883, Validation Accuracy: 0.9716, Loss: 0.0112
Epoch   6 Batch  376/538 - Train Accuracy: 0.9824, Validation Accuracy: 0.9739, Loss: 0.0129
Epoch   6 Batch  377/538 - Train Accuracy: 0.9730, Validation Accuracy: 0.9698, Loss: 0.0152
Epoch   6 Batch  378/538 - Train Accuracy: 0.9831, Validation Accuracy: 0.9732, Loss: 0.0087
Epoch   6 Batch  379/538 - Train Accuracy: 0.9844, Validation Accuracy: 0.9700, Loss: 0.0118
Epoch   6 Batch  380/538 - Train Accuracy: 0.9746, Validation Accuracy: 0.9709, Loss: 0.0115
Epoch   6 Batch  381/538 - Train Accuracy: 0.9864, Validation Accuracy: 0.9666, Loss: 0.0086
Epoch   6 Batch  382/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9656, Loss: 0.0168
Epoch   6 Batch  383/538 - Train Accuracy: 0.9875, Validation Accuracy: 0.9638, Loss: 0.0114
Epoch   6 Batch  384/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9679, Loss: 0.0137
Epoch   6 Batch  385/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9666, Loss: 0.0110
Epoch   6 Batch  386/538 - Train Accuracy: 0.9820, Validation Accuracy: 0.9698, Loss: 0.0139
Epoch   6 Batch  387/538 - Train Accuracy: 0.9881, Validation Accuracy: 0.9698, Loss: 0.0122
Epoch   6 Batch  388/538 - Train Accuracy: 0.9857, Validation Accuracy: 0.9719, Loss: 0.0095
Epoch   6 Batch  389/538 - Train Accuracy: 0.9736, Validation Accuracy: 0.9673, Loss: 0.0147
Epoch   6 Batch  390/538 - Train Accuracy: 0.9805, Validation Accuracy: 0.9698, Loss: 0.0094
Epoch   6 Batch  391/538 - Train Accuracy: 0.9710, Validation Accuracy: 0.9636, Loss: 0.0118
Epoch   6 Batch  392/538 - Train Accuracy: 0.9790, Validation Accuracy: 0.9625, Loss: 0.0096
Epoch   6 Batch  393/538 - Train Accuracy: 0.9894, Validation Accuracy: 0.9682, Loss: 0.0137
Epoch   6 Batch  394/538 - Train Accuracy: 0.9652, Validation Accuracy: 0.9707, Loss: 0.0186
Epoch   6 Batch  395/538 - Train Accuracy: 0.9830, Validation Accuracy: 0.9693, Loss: 0.0124
Epoch   6 Batch  396/538 - Train Accuracy: 0.9863, Validation Accuracy: 0.9680, Loss: 0.0108
Epoch   6 Batch  397/538 - Train Accuracy: 0.9859, Validation Accuracy: 0.9672, Loss: 0.0105
Epoch   6 Batch  398/538 - Train Accuracy: 0.9783, Validation Accuracy: 0.9698, Loss: 0.0104
Epoch   6 Batch  399/538 - Train Accuracy: 0.9889, Validation Accuracy: 0.9684, Loss: 0.0116
Epoch   6 Batch  400/538 - Train Accuracy: 0.9846, Validation Accuracy: 0.9693, Loss: 0.0125
Epoch   6 Batch  401/538 - Train Accuracy: 0.9943, Validation Accuracy: 0.9693, Loss: 0.0074
Epoch   6 Batch  402/538 - Train Accuracy: 0.9867, Validation Accuracy: 0.9702, Loss: 0.0098
Epoch   6 Batch  403/538 - Train Accuracy: 0.9877, Validation Accuracy: 0.9755, Loss: 0.0123
Epoch   6 Batch  404/538 - Train Accuracy: 0.9749, Validation Accuracy: 0.9771, Loss: 0.0145
Epoch   6 Batch  405/538 - Train Accuracy: 0.9849, Validation Accuracy: 0.9751, Loss: 0.0118
Epoch   6 Batch  406/538 - Train Accuracy: 0.9766, Validation Accuracy: 0.9664, Loss: 0.0142
Epoch   6 Batch  407/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9680, Loss: 0.0152
Epoch   6 Batch  408/538 - Train Accuracy: 0.9768, Validation Accuracy: 0.9680, Loss: 0.0146
Epoch   6 Batch  409/538 - Train Accuracy: 0.9699, Validation Accuracy: 0.9620, Loss: 0.0116
Epoch   6 Batch  410/538 - Train Accuracy: 0.9850, Validation Accuracy: 0.9618, Loss: 0.0100
Epoch   6 Batch  411/538 - Train Accuracy: 0.9821, Validation Accuracy: 0.9634, Loss: 0.0147
Epoch   6 Batch  412/538 - Train Accuracy: 0.9922, Validation Accuracy: 0.9664, Loss: 0.0076
Epoch   6 Batch  413/538 - Train Accuracy: 0.9764, Validation Accuracy: 0.9664, Loss: 0.0117
Epoch   6 Batch  414/538 - Train Accuracy: 0.9734, Validation Accuracy: 0.9664, Loss: 0.0211
Epoch   6 Batch  415/538 - Train Accuracy: 0.9736, Validation Accuracy: 0.9659, Loss: 0.0111
Epoch   6 Batch  416/538 - Train Accuracy: 0.9856, Validation Accuracy: 0.9652, Loss: 0.0112
Epoch   6 Batch  417/538 - Train Accuracy: 0.9857, Validation Accuracy: 0.9640, Loss: 0.0112
Epoch   6 Batch  418/538 - Train Accuracy: 0.9795, Validation Accuracy: 0.9654, Loss: 0.0167
Epoch   6 Batch  419/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9650, Loss: 0.0131
Epoch   6 Batch  420/538 - Train Accuracy: 0.9701, Validation Accuracy: 0.9666, Loss: 0.0168
Epoch   6 Batch  421/538 - Train Accuracy: 0.9695, Validation Accuracy: 0.9645, Loss: 0.0103
Epoch   6 Batch  422/538 - Train Accuracy: 0.9814, Validation Accuracy: 0.9696, Loss: 0.0123
Epoch   6 Batch  423/538 - Train Accuracy: 0.9867, Validation Accuracy: 0.9741, Loss: 0.0131
Epoch   6 Batch  424/538 - Train Accuracy: 0.9827, Validation Accuracy: 0.9787, Loss: 0.0165
Epoch   6 Batch  425/538 - Train Accuracy: 0.9639, Validation Accuracy: 0.9764, Loss: 0.0209
Epoch   6 Batch  426/538 - Train Accuracy: 0.9773, Validation Accuracy: 0.9700, Loss: 0.0121
Epoch   6 Batch  427/538 - Train Accuracy: 0.9787, Validation Accuracy: 0.9688, Loss: 0.0113
Epoch   6 Batch  428/538 - Train Accuracy: 0.9896, Validation Accuracy: 0.9664, Loss: 0.0070
Epoch   6 Batch  429/538 - Train Accuracy: 0.9868, Validation Accuracy: 0.9719, Loss: 0.0127
Epoch   6 Batch  430/538 - Train Accuracy: 0.9668, Validation Accuracy: 0.9718, Loss: 0.0154
Epoch   6 Batch  431/538 - Train Accuracy: 0.9738, Validation Accuracy: 0.9705, Loss: 0.0138
Epoch   6 Batch  432/538 - Train Accuracy: 0.9741, Validation Accuracy: 0.9728, Loss: 0.0144
Epoch   6 Batch  433/538 - Train Accuracy: 0.9705, Validation Accuracy: 0.9673, Loss: 0.0261
Epoch   6 Batch  434/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9574, Loss: 0.0118
Epoch   6 Batch  435/538 - Train Accuracy: 0.9850, Validation Accuracy: 0.9524, Loss: 0.0134
Epoch   6 Batch  436/538 - Train Accuracy: 0.9605, Validation Accuracy: 0.9489, Loss: 0.0159
Epoch   6 Batch  437/538 - Train Accuracy: 0.9834, Validation Accuracy: 0.9526, Loss: 0.0122
Epoch   6 Batch  438/538 - Train Accuracy: 0.9789, Validation Accuracy: 0.9563, Loss: 0.0100
Epoch   6 Batch  439/538 - Train Accuracy: 0.9902, Validation Accuracy: 0.9679, Loss: 0.0127
Epoch   6 Batch  440/538 - Train Accuracy: 0.9855, Validation Accuracy: 0.9698, Loss: 0.0116
Epoch   6 Batch  441/538 - Train Accuracy: 0.9732, Validation Accuracy: 0.9748, Loss: 0.0156
Epoch   6 Batch  442/538 - Train Accuracy: 0.9815, Validation Accuracy: 0.9755, Loss: 0.0127
Epoch   6 Batch  443/538 - Train Accuracy: 0.9728, Validation Accuracy: 0.9716, Loss: 0.0142
Epoch   6 Batch  444/538 - Train Accuracy: 0.9773, Validation Accuracy: 0.9712, Loss: 0.0140
Epoch   6 Batch  445/538 - Train Accuracy: 0.9852, Validation Accuracy: 0.9705, Loss: 0.0101
Epoch   6 Batch  446/538 - Train Accuracy: 0.9914, Validation Accuracy: 0.9693, Loss: 0.0106
Epoch   6 Batch  447/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9659, Loss: 0.0101
Epoch   6 Batch  448/538 - Train Accuracy: 0.9831, Validation Accuracy: 0.9656, Loss: 0.0115
Epoch   6 Batch  449/538 - Train Accuracy: 0.9828, Validation Accuracy: 0.9737, Loss: 0.0143
Epoch   6 Batch  450/538 - Train Accuracy: 0.9635, Validation Accuracy: 0.9757, Loss: 0.0172
Epoch   6 Batch  451/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9721, Loss: 0.0116
Epoch   6 Batch  452/538 - Train Accuracy: 0.9777, Validation Accuracy: 0.9718, Loss: 0.0118
Epoch   6 Batch  453/538 - Train Accuracy: 0.9826, Validation Accuracy: 0.9677, Loss: 0.0121
Epoch   6 Batch  454/538 - Train Accuracy: 0.9808, Validation Accuracy: 0.9675, Loss: 0.0154
Epoch   6 Batch  455/538 - Train Accuracy: 0.9899, Validation Accuracy: 0.9647, Loss: 0.0101
Epoch   6 Batch  456/538 - Train Accuracy: 0.9797, Validation Accuracy: 0.9663, Loss: 0.0209
Epoch   6 Batch  457/538 - Train Accuracy: 0.9795, Validation Accuracy: 0.9696, Loss: 0.0099
Epoch   6 Batch  458/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9712, Loss: 0.0114
Epoch   6 Batch  459/538 - Train Accuracy: 0.9885, Validation Accuracy: 0.9703, Loss: 0.0080
Epoch   6 Batch  460/538 - Train Accuracy: 0.9786, Validation Accuracy: 0.9709, Loss: 0.0136
Epoch   6 Batch  461/538 - Train Accuracy: 0.9846, Validation Accuracy: 0.9730, Loss: 0.0133
Epoch   6 Batch  462/538 - Train Accuracy: 0.9818, Validation Accuracy: 0.9712, Loss: 0.0090
Epoch   6 Batch  463/538 - Train Accuracy: 0.9770, Validation Accuracy: 0.9703, Loss: 0.0138
Epoch   6 Batch  464/538 - Train Accuracy: 0.9857, Validation Accuracy: 0.9686, Loss: 0.0096
Epoch   6 Batch  465/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9695, Loss: 0.0125
Epoch   6 Batch  466/538 - Train Accuracy: 0.9723, Validation Accuracy: 0.9762, Loss: 0.0139
Epoch   6 Batch  467/538 - Train Accuracy: 0.9751, Validation Accuracy: 0.9760, Loss: 0.0136
Epoch   6 Batch  468/538 - Train Accuracy: 0.9848, Validation Accuracy: 0.9725, Loss: 0.0171
Epoch   6 Batch  469/538 - Train Accuracy: 0.9729, Validation Accuracy: 0.9691, Loss: 0.0128
Epoch   6 Batch  470/538 - Train Accuracy: 0.9740, Validation Accuracy: 0.9700, Loss: 0.0140
Epoch   6 Batch  471/538 - Train Accuracy: 0.9922, Validation Accuracy: 0.9711, Loss: 0.0090
Epoch   6 Batch  472/538 - Train Accuracy: 0.9961, Validation Accuracy: 0.9725, Loss: 0.0076
Epoch   6 Batch  473/538 - Train Accuracy: 0.9852, Validation Accuracy: 0.9764, Loss: 0.0107
Epoch   6 Batch  474/538 - Train Accuracy: 0.9797, Validation Accuracy: 0.9817, Loss: 0.0123
Epoch   6 Batch  475/538 - Train Accuracy: 0.9831, Validation Accuracy: 0.9792, Loss: 0.0114
Epoch   6 Batch  476/538 - Train Accuracy: 0.9844, Validation Accuracy: 0.9776, Loss: 0.0109
Epoch   6 Batch  477/538 - Train Accuracy: 0.9791, Validation Accuracy: 0.9831, Loss: 0.0159
Epoch   6 Batch  478/538 - Train Accuracy: 0.9942, Validation Accuracy: 0.9831, Loss: 0.0095
Epoch   6 Batch  479/538 - Train Accuracy: 0.9842, Validation Accuracy: 0.9837, Loss: 0.0138
Epoch   6 Batch  480/538 - Train Accuracy: 0.9857, Validation Accuracy: 0.9714, Loss: 0.0116
Epoch   6 Batch  481/538 - Train Accuracy: 0.9823, Validation Accuracy: 0.9705, Loss: 0.0121
Epoch   6 Batch  482/538 - Train Accuracy: 0.9742, Validation Accuracy: 0.9696, Loss: 0.0097
Epoch   6 Batch  483/538 - Train Accuracy: 0.9709, Validation Accuracy: 0.9659, Loss: 0.0134
Epoch   6 Batch  484/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9659, Loss: 0.0137
Epoch   6 Batch  485/538 - Train Accuracy: 0.9859, Validation Accuracy: 0.9673, Loss: 0.0156
Epoch   6 Batch  486/538 - Train Accuracy: 0.9870, Validation Accuracy: 0.9702, Loss: 0.0114
Epoch   6 Batch  487/538 - Train Accuracy: 0.9909, Validation Accuracy: 0.9753, Loss: 0.0085
Epoch   6 Batch  488/538 - Train Accuracy: 0.9801, Validation Accuracy: 0.9833, Loss: 0.0120
Epoch   6 Batch  489/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9744, Loss: 0.0107
Epoch   6 Batch  490/538 - Train Accuracy: 0.9749, Validation Accuracy: 0.9723, Loss: 0.0121
Epoch   6 Batch  491/538 - Train Accuracy: 0.9701, Validation Accuracy: 0.9691, Loss: 0.0113
Epoch   6 Batch  492/538 - Train Accuracy: 0.9840, Validation Accuracy: 0.9711, Loss: 0.0098
Epoch   6 Batch  493/538 - Train Accuracy: 0.9767, Validation Accuracy: 0.9689, Loss: 0.0144
Epoch   6 Batch  494/538 - Train Accuracy: 0.9799, Validation Accuracy: 0.9666, Loss: 0.0111
Epoch   6 Batch  495/538 - Train Accuracy: 0.9832, Validation Accuracy: 0.9668, Loss: 0.0156
Epoch   6 Batch  496/538 - Train Accuracy: 0.9826, Validation Accuracy: 0.9673, Loss: 0.0087
Epoch   6 Batch  497/538 - Train Accuracy: 0.9814, Validation Accuracy: 0.9654, Loss: 0.0109
Epoch   6 Batch  498/538 - Train Accuracy: 0.9850, Validation Accuracy: 0.9696, Loss: 0.0096
Epoch   6 Batch  499/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9753, Loss: 0.0132
Epoch   6 Batch  500/538 - Train Accuracy: 0.9883, Validation Accuracy: 0.9723, Loss: 0.0071
Epoch   6 Batch  501/538 - Train Accuracy: 0.9807, Validation Accuracy: 0.9734, Loss: 0.0133
Epoch   6 Batch  502/538 - Train Accuracy: 0.9758, Validation Accuracy: 0.9702, Loss: 0.0132
Epoch   6 Batch  503/538 - Train Accuracy: 0.9857, Validation Accuracy: 0.9622, Loss: 0.0151
Epoch   6 Batch  504/538 - Train Accuracy: 0.9844, Validation Accuracy: 0.9609, Loss: 0.0111
Epoch   6 Batch  505/538 - Train Accuracy: 0.9741, Validation Accuracy: 0.9661, Loss: 0.0097
Epoch   6 Batch  506/538 - Train Accuracy: 0.9816, Validation Accuracy: 0.9682, Loss: 0.0118
Epoch   6 Batch  507/538 - Train Accuracy: 0.9872, Validation Accuracy: 0.9716, Loss: 0.0123
Epoch   6 Batch  508/538 - Train Accuracy: 0.9838, Validation Accuracy: 0.9757, Loss: 0.0098
Epoch   6 Batch  509/538 - Train Accuracy: 0.9766, Validation Accuracy: 0.9734, Loss: 0.0150
Epoch   6 Batch  510/538 - Train Accuracy: 0.9805, Validation Accuracy: 0.9732, Loss: 0.0098
Epoch   6 Batch  511/538 - Train Accuracy: 0.9702, Validation Accuracy: 0.9732, Loss: 0.0150
Epoch   6 Batch  512/538 - Train Accuracy: 0.9860, Validation Accuracy: 0.9721, Loss: 0.0127
Epoch   6 Batch  513/538 - Train Accuracy: 0.9699, Validation Accuracy: 0.9716, Loss: 0.0131
Epoch   6 Batch  514/538 - Train Accuracy: 0.9812, Validation Accuracy: 0.9693, Loss: 0.0116
Epoch   6 Batch  515/538 - Train Accuracy: 0.9767, Validation Accuracy: 0.9654, Loss: 0.0144
Epoch   6 Batch  516/538 - Train Accuracy: 0.9779, Validation Accuracy: 0.9581, Loss: 0.0122
Epoch   6 Batch  517/538 - Train Accuracy: 0.9875, Validation Accuracy: 0.9597, Loss: 0.0100
Epoch   6 Batch  518/538 - Train Accuracy: 0.9869, Validation Accuracy: 0.9638, Loss: 0.0136
Epoch   6 Batch  519/538 - Train Accuracy: 0.9816, Validation Accuracy: 0.9622, Loss: 0.0115
Epoch   6 Batch  520/538 - Train Accuracy: 0.9760, Validation Accuracy: 0.9627, Loss: 0.0127
Epoch   6 Batch  521/538 - Train Accuracy: 0.9852, Validation Accuracy: 0.9670, Loss: 0.0116
Epoch   6 Batch  522/538 - Train Accuracy: 0.9816, Validation Accuracy: 0.9684, Loss: 0.0111
Epoch   6 Batch  523/538 - Train Accuracy: 0.9879, Validation Accuracy: 0.9632, Loss: 0.0097
Epoch   6 Batch  524/538 - Train Accuracy: 0.9723, Validation Accuracy: 0.9625, Loss: 0.0091
Epoch   6 Batch  525/538 - Train Accuracy: 0.9829, Validation Accuracy: 0.9625, Loss: 0.0129
Epoch   6 Batch  526/538 - Train Accuracy: 0.9728, Validation Accuracy: 0.9611, Loss: 0.0126
Epoch   6 Batch  527/538 - Train Accuracy: 0.9887, Validation Accuracy: 0.9627, Loss: 0.0091
Epoch   6 Batch  528/538 - Train Accuracy: 0.9780, Validation Accuracy: 0.9627, Loss: 0.0126
Epoch   6 Batch  529/538 - Train Accuracy: 0.9809, Validation Accuracy: 0.9668, Loss: 0.0132
Epoch   6 Batch  530/538 - Train Accuracy: 0.9756, Validation Accuracy: 0.9732, Loss: 0.0129
Epoch   6 Batch  531/538 - Train Accuracy: 0.9723, Validation Accuracy: 0.9730, Loss: 0.0132
Epoch   6 Batch  532/538 - Train Accuracy: 0.9773, Validation Accuracy: 0.9748, Loss: 0.0090
Epoch   6 Batch  533/538 - Train Accuracy: 0.9754, Validation Accuracy: 0.9757, Loss: 0.0095
Epoch   6 Batch  534/538 - Train Accuracy: 0.9883, Validation Accuracy: 0.9783, Loss: 0.0083
Epoch   6 Batch  535/538 - Train Accuracy: 0.9857, Validation Accuracy: 0.9773, Loss: 0.0106
Epoch   6 Batch  536/538 - Train Accuracy: 0.9874, Validation Accuracy: 0.9725, Loss: 0.0135
Model Trained and Saved
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Save-Parameters">Save Parameters<a class="anchor-link" href="#Save-Parameters">&#182;</a></h3><p>Save the <code>batch_size</code> and <code>save_path</code> parameters for inference.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Save parameters for checkpoint</span>
<span class="n">helper</span><span class="o">.</span><span class="n">save_params</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Checkpoint">Checkpoint<a class="anchor-link" href="#Checkpoint">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="p">(</span><span class="n">source_int_to_vocab</span><span class="p">,</span> <span class="n">target_int_to_vocab</span><span class="p">)</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">load_path</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_params</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sentence-to-Sequence">Sentence to Sequence<a class="anchor-link" href="#Sentence-to-Sequence">&#182;</a></h2><p>To feed a sentence into the model for translation, you first need to preprocess it.  Implement the function <code>sentence_to_seq()</code> to preprocess new sentences.</p>
<ul>
<li>Convert the sentence to lowercase</li>
<li>Convert words into ids using <code>vocab_to_int</code><ul>
<li>Convert words not in the vocabulary, to the <code>&lt;UNK&gt;</code> word id.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sentence_to_seq</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert a sentence to a sequence of ids</span>
<span class="sd">    :param sentence: String</span>
<span class="sd">    :param vocab_to_int: Dictionary to go from the words to an id</span>
<span class="sd">    :return: List of word ids</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">unknown_id</span> <span class="o">=</span> <span class="n">vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;UNK&gt;&#39;</span><span class="p">]</span>
    <span class="n">sentence_int</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">next_word_id</span> <span class="o">=</span> <span class="n">vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="n">next_word_id</span> <span class="o">=</span> <span class="n">unknown_id</span>
        <span class="n">sentence_int</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">next_word_id</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sentence_int</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_sentence_to_seq</span><span class="p">(</span><span class="n">sentence_to_seq</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Translate">Translate<a class="anchor-link" href="#Translate">&#182;</a></h2><p>This will translate <code>translate_sentence</code> from English to French.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">translate_sentence</span> <span class="o">=</span> <span class="s1">&#39;he saw a old yellow truck .&#39;</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">translate_sentence</span> <span class="o">=</span> <span class="n">sentence_to_seq</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">)</span>

<span class="n">loaded_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">loaded_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Load saved model</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">load_path</span> <span class="o">+</span> <span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
    <span class="n">loader</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">load_path</span><span class="p">)</span>

    <span class="n">input_data</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;input:0&#39;</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;predictions:0&#39;</span><span class="p">)</span>
    <span class="n">target_sequence_length</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;target_sequence_length:0&#39;</span><span class="p">)</span>
    <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;source_sequence_length:0&#39;</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;keep_prob:0&#39;</span><span class="p">)</span>

    <span class="n">translate_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="p">[</span><span class="n">translate_sentence</span><span class="p">]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">target_sequence_length</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">source_sequence_length</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">)]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  English Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">source_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Prediction&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_logits</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  French Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">target_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_logits</span><span class="p">])))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:tensorflow:Restoring parameters from checkpoints/dev
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Imperfect-Translation">Imperfect Translation<a class="anchor-link" href="#Imperfect-Translation">&#182;</a></h2><p>You might notice that some sentences translate better than others.  Since the dataset you're using only has a vocabulary of 227 English words of the thousands that you use, you're only going to see good results using these words.  For this project, you don't need a perfect translation. However, if you want to create a better translation model, you'll need better data.</p>
<p>You can train on the <a href="http://www.statmt.org/wmt10/training-giga-fren.tar">WMT10 French-English corpus</a>.  This dataset has more vocabulary and richer in topics discussed.  However, this will take you days to train, so make sure you've a GPU and the neural network is performing well on dataset we provided.  Just make sure you play with the WMT10 corpus after you've submitted this project.</p>
<h2 id="Submitting-This-Project">Submitting This Project<a class="anchor-link" href="#Submitting-This-Project">&#182;</a></h2><p>When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as "dlnd_language_translation.ipynb" and save it as a HTML file under "File" -&gt; "Download as". Include the "helper.py" and "problem_unittests.py" files in your submission.</p>

</div>
</div>
</div>
    </div>
  </div>
</body>

 


</html>
